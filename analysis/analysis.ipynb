{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project root 경로 설정\n",
    "\n",
    "import platform\n",
    "\n",
    "\n",
    "_ = '\\\\' if platform.system() == 'Windows' else '/'\n",
    "root_dir = '/home{_}gusdnd852{_}Github{_}strabismus-recognition{_}'.format(_=_)\n",
    "if root_dir[len(root_dir) - 1] != _: root_dir += _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file type에 따라 다른 데이터에 접근\n",
    "\n",
    "def load_data(classes, max_len, label, short:bool=False):\n",
    "    file_type = 'fixations' if short else 'all_gaze' \n",
    "    raw_data_dir = root_dir + 'data{_}{c}{_}'.format(_=_, c=classes)\n",
    "    listdir = [_ for _ in os.listdir(raw_data_dir) if file_type in _]\n",
    "    \n",
    "    dataset, existing_names = [], ['']\n",
    "    for filename in listdir:\n",
    "        file = pd.read_csv(raw_data_dir + filename)\n",
    "        MEDIA_ID = file['MEDIA_ID'].unique().tolist()\n",
    "\n",
    "        if len(MEDIA_ID) < 2:\n",
    "            # 적외선 필터 검사를 진행하지 않은 데이터\n",
    "            continue  # 데이터 목록에서 제외합니다.\n",
    "            \n",
    "        if filename[:3] in existing_names:\n",
    "            continue # 환자당 데이터 1개씩만 포함\n",
    "        \n",
    "        file = file[file['MEDIA_ID'] == MEDIA_ID[-1]]  \n",
    "        # 적외선 필터 데이터만 로드\n",
    "        \n",
    "        data = np.c_[file.LPCX,  file.RPCX, file.LPV, file.RPV]\n",
    "        columns = ['LPCX', 'RPCX', 'LPV', 'RPV']        \n",
    "        data = pd.DataFrame(data=data, columns=columns)\n",
    "        \n",
    "        # 데이터 전처리 작업 수행\n",
    "        label = np.array(label)\n",
    "        data_dict = {'data':data, 'label': label}\n",
    "        dataset.append(data_dict)\n",
    "        existing_names.append(filename[:3])\n",
    "        \n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = load_data('normal', max_len=1000, label=0)\n",
    "exotropia = load_data('exotropia', max_len=1000, label=1)\n",
    "# esotropia = load_data('esotropia', max_len=1000, label=2)\n",
    "# hypertropia = load_data('hypertropia', max_len=1000, label=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def preprocess(data, sampling_rate=10, outlier_threshold=0.025):\n",
    "    lpcx, rpcx = data['data']['LPCX'], data['data']['RPCX']\n",
    "    valid = data['data']['LPV'] + data['data']['RPV']\n",
    "    diff = (rpcx - lpcx).tolist()\n",
    "    mean = sum(diff) / len(diff)\n",
    "    \n",
    "    data_processed = []\n",
    "    for i, (d, v) in enumerate(zip(diff, valid)):\n",
    "        if d > mean + outlier_threshold:\n",
    "            continue\n",
    "        elif d < mean - outlier_threshold:\n",
    "            continue\n",
    "        elif v == 2:\n",
    "            data_processed.append(d)\n",
    "    \n",
    "    data_processed = np.array(data_processed)\n",
    "    mean = sum(data_processed) / (len(data_processed) + 1)\n",
    "    data_normalized = np.array([d - mean for d in data_processed])\n",
    "    \n",
    "    data_sampled, sampling = [], []\n",
    "    for i, d in enumerate(data_normalized):\n",
    "        sampling.append(d)\n",
    "        \n",
    "        if len(sampling) > sampling_rate:\n",
    "            del sampling[0]\n",
    "        \n",
    "        if i % sampling_rate == 0 and i > sampling_rate:\n",
    "               data_sampled.append((sum(sampling) / len(sampling)))\n",
    "    \n",
    "    data_sampled = np.array(data_sampled)\n",
    "    \n",
    "    return {\n",
    "        'data' : data_sampled,\n",
    "        'label' : data['label']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 전처리 전 정상환자 시각화\n",
    "outlier_threshold = 0.025\n",
    "for i in normal:\n",
    "    plt.plot(i['data']['RPCX'] - i['data']['LPCX'], c='r')\n",
    "    \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2dd5hdVdX/v3t6y0xm0iuZQBJKkBYgIEgvIogo0iUoyCvKTwSFF18sCPIKKGIDNCoCohRpBvBVIDTpCRAghEBCSCU9mWR6puzfH9+73OeeObefO/fO3PV5nvPcU/Y9Z5/23WuvvfY+xloLRVEUZfBTlOsMKIqiKP2DCr6iKEqBoIKvKIpSIKjgK4qiFAgq+IqiKAVCSa4zEIvhw4fbSZMm5TobiqIoA4rXX399k7V2RNC2vBX8SZMmYf78+bnOhqIoyoDCGLMi1jZ16SiKohQIKviKoigFggq+oihKgaCCryiKUiCo4CuKohQIKviKoigFggq+oihKgZC3cfiKomSJrVuBW28FOju5XFoK/Nd/ASNH5jZfStZRwVeUQuPxx4HvfS963fDhwEUX5SY/Sr+hLh1FKTS6uvi7fDmwaRPnu7tzlh2l/1DBV5RCo6eHv0VFgDGc7+3NXX6UfkMFX1EKDRH84mIn+Pqp04JABV9RCg2v4BdFJEAFvyBQwVeUQkPcN2rhFxwq+IpSaKgPv2BRwVeUQkN9+AWLCr6iFBrqwy9YVPAVpVDYsYPC7vXhS0y+Cn5BoD1tlfymtxdYs4bzJSVAbS3Q1sbljz8GJk8G2tu5rq0N2LjRTdYCq1cDzc20ajs7ObW3A+vXc11JCa1ca90EAGVlQGUlJ8BZxb29FMnOTgqo7HPHDnZe6ugAKircf7dt4zGMAWpqgM2bgQ0bgP33Z7rmZqClxQkvwHWdnUBVlctHby+PUVZGoa6udsLd1cVtkr/2dmD7dqYpK+O+urp4LSornRtn112BtWs5f8stwCOPACefDFx5ZfQ9WL8e+J//AYYMAT76CGhs5LlMm8b57dt5Tj09vAedncCllzKfb7wBtLYC9fU8n7FjgfJyl4eg+71pE+95SQmXV6zgdSwt5blt3sy8yHm1t7t5mbq73TGKitwwEm1tTF9VxTyNGcPrMGQI81lZyetmjJt6evhcGOPueVER81dXx/0NHerST5jA/eUhKvhK6jQ3AxMnAr/7HXDaaW69tcArr/DlrK/ny7HXXnz4rXXug3hYC/zkJ8CjjwJvveVe3nQpKeHxS0oofuXlFJHhw7mutJTL0oApIrFjB4Wsvd3tRygvd/saMsTNd3c7Aejo4O/EiRTDlhYKRUMD0NQELF3KazRkCDBqFPfb0kLhGDKEaeSYO3Ywf+XlrmBpbXU++NJSbqupYbqKClcw7tjBbcXFwLBhHEfnnXcoxIceCrz9NpfLy4EPPwTuvbev4D/0EHD77ald985OYNmy4P+NGQPsuScwejTzu3UrC5516/jrLfySRa6DTCUlrvAWA2HoUAp9RQWv39atfFbDRp653l4WJjfdBHzyk+EfJw1U8Ac6HR0UnK4uPrzG0PKtrqbgtLZShB9+GNh9d2DffblNhKO2llNnJ1+Mlha+qD09zprp6IieFiygIJ1+OgVOeP114Kqr+uaxooL/E4uzpgaYOpUvfHk5sGULxQ/gsZ97jvOzZvEl3Wkn7mPHDp7bsGHM+6JFLFCqqrjvykqmGz0aGDeOIjdqVHIFTSFx9dUU/D//mdexrAw47zxg/nxefz9Su3nxRWDnnXlPenuBd9/l/Rg50tVE2tqAGTM4Vk9pKcX9ppsogk1NFPQFC4D33gPef5/79lraY8dyGjeO97unh/ufOJHLtbV8lry1hoYGHisdPvyQ701LC58h2bfU9qTGVlzsjBZxhfX0uFpBWxu39/QATz/Nwquhgdd5+/Z071ToDD7Bb2+nuDU38wHbupXrRo8Gzj2XDxLgbqZUL71VzO5uZ101N3MfHR383bqVN7Wmhg9iRwcFy1v9r62lEHZ38zgrVtDF0NzMh3zdOm5rauLDYAzT9PQ4YWtvd9XvLVucBenFWlqPxcV8ARP5YZ9/PrlrWFLiLOKKiuhJqtnC8cf3/f9f/uJEYd48nnd1NV+OF18EXnuNQiFCUllJixsAVq3i73PPAZ/6VHL5VVKjtzfaZQE4l0XQMyTrpk519wmgsAfx8ssU4D335DOUz+y8c/j7PPPM8PcZEoNP8FtbgbPPdsulpc739sMfUvhFKMXvWVdHS6Gnh7+rVtHKaGigWyEbFBUB48fTWhX/ckWFq9JXVjKfpaVM09kZ/PLU1jJNWRlfxp4eYMQIWiDV1Tyfmhpg5kxu27jRVXHl/JubXYElftaSBI/Gjh3Am2868b/xRvqAAeDII3mdAeDEE2Pvo6fH+c/FCn/7bdYSYomJkjly3YHoOPxEgh/L7+5n5szM86hkhcEn+PX1wOLFFM36eoqoMWxsmj2bDVDWsqpfW8sCYtMmWs/FxSwIpk+nWK5bB3z3u7TkR4zg/oYO5XGWL6d1X1zMF0h8qNayirh9u3uxxo51rpMJE7i/7m5XI+gvSkt5/DAoKwMOPNAti8ADyQtDcXHf9J/4BP33Svbo6el77ZOx8JO9r0reMvgEv7iY0QN+GhvZGBgWBx+c2f/T9TnmK14x6C9h8EbeSPtCVxePL26u3l6mk1+Zr61ldb652bVDWMt2iM5O5+6Q2pBEf4jrTESwtNT5bv2UlDhXWFmZi/Dp7uYxpHZkjHPf+fMrv3J8qc1Jg21RkWuk9DZYym9RkZskfVMTf9eudW7CtWsZ/dLcDNx/P12f48fzV8718ceBv/41OrKps9PV0LyRTtu2sRYoea6sdIVMWPfeWtdgPnRodCN2Q0Pfe97T4669XP/eXq4T92t3t4t6kmvunxdjraiIRt64ccDcueGdWxYZfIKv5IZMBF9CLz/+mI1oH33ENo2VK52Ar1njwhVF3DMdw10s2j33pLh99BFrh4XC2LFu/ne/c/Onn+7mi4udUJ97Ln/32ccVAtIG1tPjCkkpXEaNoiB2dfF+hTV8g7VO3Lu6WCivXu0K485OtrVJ3v2TtE15CwiZLymhmNfVuQK0rCz6t7mZNfxdduGxB9CXwgaf4Hd00BKRCBPxU8uDIfG4tbXOX93e7h6AMWM49fTwxosLR5DG3tZWWjFiaVjrQvmKilzctPhKu7udReG3PHO13hheA68l5J3EmgH6NvIBztIsKWFjrPC//+vCFWtreX2bmpi2ooLLK1eyraS5mWK+fn30dR42jG0S9fW8tuPGuWid8nJnOcu8/HotbomokF/v/Pr1fGlLSoAXXmDbBsCG4quucve0qsqda0lJtCvEGD4HIgz+50Ti8iUuXq5lVRUjYiR8U6xLsVZLSoBJk5z1OGSIs9jF0pTnzltr8P7KvIig9/7fcw/v1803c9s3vgF84Qu8JitX0qW2YoW7Rv/+NxvRv/EN4IILgL33Tv59bG7mJHkqKWHhWlxMl+nmzbz+8+bx/tbUuLj+XXcFPv95YMkSGgIlJSxESkt5DauqWJuvrGS+336b98RvpcsvwP8efTTnn3ySz+CaNfxPWxufoZYW/qepydXcampYCBxyCD8Hme+N0TEwNk972M2YMcPOnz8/9T8uWxZuy3ttrYuQEcsyT69ZICJyXstLfnt7XScSmbyuAonW8VbVvefe3e0Kj85O93LE8gV7kcbo5maKppfRo4EHH8zcbZYN3nqL1uOOHfzdvJltQK2tFJ3t22kINDVxm9RIJJ4/HRoagClTaFFOmcIaiQidNPRLwZQM/+//MZJqyxYuFxezrWrJEp6fv5Zz003Ad77D86qtdeu7uiiyy5dHT1u28PxXr44dkjhkCO99GNx/P/CLXwAvvZT+PoYPp6CvX8/rOXQo792SJSygxo5lAbVyJd+NESNc296IEUwzYQKf3bo612ZXV8d91dT0m6vTGPO6tTYw6mHwCf769Yw1LyqiAElVUnogdnfz5rW0BD+MYrGKmGWCCGZVlbMAvaLp/RUrTKxA8ZOK/9ZrbQ9EamooTtu2uR6mVVUU/fp6uglKS3m+Dz7Il+OGG9iAniedVgAwvyKUXkpLKRpjxvAFr6vjOVdX83f4cM43NwPXX0+3yY9+xG3yvIlBsX0749S3bGGhsWIFO2otWUKLNOidramh8JSVuQJbeupKzUSex0WL6LM/8USuf+ABWtMtLSzEbr8d+OIXea++/nXGzS9aBHz6085QaGri+o4Ol4faWraVDRvG858wgUIokWQlJcBvfuN66e6xB6/LlCmsyQwd6grHujrgiSeYz6lTWdhJTVHClr0hwePHs0/GD37gQor97hhrGTL6z3/yuTrkEPbUHjIkWIx7ehhCvP/+zvD55z9ZsKxfz0l6da9eHX0t/JSXs3by7rs8/yySdcE3xhwP4JcAigH8wVp7fYx0XwDwAID9rbVx1TxtwY+HCKs0MH3wAR/k5ma+VFJF7+jgQ7JgAV+EY491vj/ANUBJHL+EM3q71IuLKEy8jZTeSVwGLS3BrhnANWT6p95eNy/PQmWlc42Iv9RbC5AagjQOAhSvu+/m/HPP0SoVS6empu+1iBf58cgjwCmnuOWTTkqtq/qXv+yq7WFjDC3s226jQA0bxueivt7VbLwNmR0drpdsaakruEWU/fsOQnoDyzO3cCFdHHLvm5qc+HR1OeOhtdW5dqTBsquLz3pTE0W3p4cWfUMDt7e08L/HHceay+uv02pdt44RVKWl7hnYe2/giCO4n0mT+ro/s01dXbTRdtllrI3kAmtZOK9fzzzJtG0bC1EpGG6/PeuWfjzBz9iHb4wpBnALgGMArAYwzxgzx1q7yJduCIBLALya6THTxuuDNoYPalBET75SXOx8l/FYv95FKrS3ux6K0s7Q0eG64YfVC3XYMDe/556u52wQTU30l4r/Way61lb+FhXREmxvp/j/+98Uprq66Pxu2dK31tPZCTz1FMXJ686KNZWVRUdhSMSGLG/dyv2KmBtDt8UFF3C9+OFlkjaibFBURFGdOpW9pmU64QRa08kKyVe/ynauhQu5XF7OdStXAs8+S6v67be5z3POoTV85ZX0+8ezTt94g/eqtTV6vBmvBe39FaPC7zpsa+M+xIDytpt4R/f0X+tly9j47G2rEoPFa9SIG3L7doq01KDl2aupcWMzbdrEwk46cNbU8NmaMIG1k+HDWbOS+YYGFzE0dCjPIY8Io9H2AABLrbXLAMAYcy+AkwEs8qW7FsANAC4P4ZixaW6mK8DvjvFHkYjFPmoUxUmqvH4LWKw0EaW2Nlell2NIoxsQXd32zouYiY+8rc0JRFMT9ynRDt6GNq/vXAaIEmutp4ednLzW89KlwKuRMlX6CAB8UNvbo3vkGsMHUgYRk2skVWD/VFTk+it4x3kBohtdzzrLVc/lHMXnLZZOKojYBvl8J06kAMpL/tprzrr1XstYU2enGxtHhKe0lO6XkhK6G6QRXsR+4kQKrYRT+nsjl5c7d1x5OfMp10Cuo59YNW0ppIuK+LtlCy3yxx+PHqfGGGC33dzzLOcjNbCuLteAunQpLc+rr+az19VFn/62bXwuq6oo+mvX8noKnZ3xBf+cc+iKyhWPPOI6/yVLRYUryCsrXaOxdFocNoxtgsOGcfuWLSwoX36Z8/E8JGVlbIz+xCcyO68QCUPwxwFY5VleDeBAbwJjzL4AJlhrHzfGxBR8Y8yFAC4EgIkTJ6aXm85OxtvH+riDzPe3P7yszEXEiHjU1fGBq6pyoWBe94nfGhVhKi5m/l97jQ+UnzPPdD7zkSP54n/8Mf9fXk4rRFxXO3a4/QEuusQb5SQWsAw54XUVlZf3FeNly7hOxK+ykvnedVcO2NXY6FwgEqNdUeHGw5Fl+R05ki/Z++9Hn2dFBfCZz0QXeHvsQeF74IFw75/w0EO0qG+8MTv7T4XNmymw775L//6SJVy3eHF0bUV6bNfU0Nrevp339kc/4n7kPZFa2axZLsIK4IBqixezQPDW5Py0tfHZu/VW3htxnba0cLu/zUpCbqX9QtxFMiidGFkSzinWueR3wQK29/z4x3xGpTbgf4e87k2vW3LIkMws8J4eZ8Rs2sRp61ZnjC1fzmc+j8h6WKYxpgjAzwGclyittXY2gNkAffhpHVCGF0h8MD5wy5e7CBO5Ud6ptzfaN+8VZqmGSgOrO+m+8/6QxsHGt78N/PznnJ83LzqaI12sBa65hhEYck+rqoBnnqGoB5FMhFAivCITlCcR0Vzfz2HD2PB4yCGp/e9LX2LD4+LFFKhJk4AzzqDr4qWXgF//Ojq9RO4keq9kLCi/L19qOalSXR1/e2NjdFtPttiyhcO1vPOOey4OP5yd0MSVM0AIQ/DXAPD21x8fWScMATAdwLOGL8hoAHOMMZ9N1HCbVcR/O3VqzrIwqMhGT9uXXqLbYd99gcMOo9vor3+lSyKR4EskSXOzE3B/QR5UMMydy7Hf43HzzW7MH2+Ya3s73SA77+wGmZPjeY2JsjJXo/JGg3mjtcQq94fTSjigjAaaDmLplpZyX16XVdA1EWPGWwhay/j1nh5eZ7HSN2wA5sxh2gMOiO7c5eeee7iP6mqei4w6WV7uhi2R/hxtbTyWt/FeviMg1yGoJh+0Tsbt7+lxfSi2bXPPSW+vax9qbeUzsXEjC5fhw1mzuOce3v899kj+uucBYQj+PABTjDGNoNCfAeAs2Wit3QbgP0WgMeZZAN/Jqdgr4ZOp4AdZzG+8wd/bbqMwLVhAwb/5ZuCOO1zDmrimenro1li8OHo89Gwwd25uu9Pvvjtw553Oyr3kEnaeise11/I/69YxjFFClQGKZ1sbBXTRIha2c+fSTfHvfzPNfvu5thvpyOjn8cc5CUuXuiADCSTo7uZxzzqr7/9zjbiCZbhncSl+73vAN7/JNPfdxxrR9OnAV77CGpL3g/AAl885h9c5j8hY8K213caYiwH8CwzLvN1a+64x5hoA8621czI9Rt7Q3s443GOPTVzdzCe8g2VliyDBt5YivXAhffe9vRSWTZtch6W1axnG+fLLzkdbXu5CG4HoQdoAunSSxTvGTFA3ef98Tw9F6fzzo6NAuruZr9NOY7+AV15x48TEQizjeJE706ezBrPLLpwmT+azJS5Hr9Uv18EYXr/996d7cds2Cuv48TzfmhrOV1UxbUcHa0d3302xly9xVVW5vM2e7fIkVmtZGWsScj8mTnSN/NJ439npwoE3bGDaqipa/b29PKdMGTHC1XYA5kE+XpJpX5nyctbyp02jv33KFE6TJ1Pog4yXz32O1v1118X/MMxjj7EXcR4x+DperV4NfPaztPikirpjR98qvTQISSeN3l4XqijXRKp3IhobN7LBSzqTSGOmdwwRoO9D4g3pC1oPRDciB6WLtZxovreX7RQ77cROQRKOJtVz/6BXQVEtgMu/f5vsR8b2B5zF09npPk+YLNK4OGoUq9OrVrGDjYxh8uyz7Nr+hS9QuP77v10Py8ZGis3EiWxcjRURkwnSK/Waa5i/ZPoHyLXr6eHz2dLC6/KPf7CwW7TIRTsB9IGPGEEfvXRYKinhUADCfvvxefz44/4LQJChMUTUZejtyZO5/v77KfCHHsr3YunS6Oiup59mI/vBBzP997/P9oeLL2YhV13tGm4BulWee479BsTlJEbDsGF8RryFtbipiovddSsrc/uWTnDDhjHtRx8Bf/sbgwGWLOF74i1Aqqv5LMugef53VPL5hz/07RV+ww3sBDZyJI/5ta8Bl2c3QNFlLYtx+HlHZyfHaU8Gv89SYq4TsXp16vlKRKbCFK/gtpYv39KlmR0jVmO0V/gBvjh+iospFHvsQTGTzmrS63LKFAp2Zyfz+alPUczvuQe48EJatEuWUPCbmmg5tbZynfjMly6lj3XHDkagSGcliQYaMcKNj2KtG/hLQhMBWsytrSxcpAesRC2JYfDkky5mG4gep0Z88iLSEjUiEVrekS7HjqVrQL5T8PHHruNOSwvXSaerIFEfPZr7WbGCy1OmuKiX7m73qUMJOnj+eXaWuvRS564oL2eP2xNOoItm3jy6LCSctqiIPYNffJECNmZMdGcu72QMI30mTOB+p09nvtraGEkEuC+zrVrF/6xdy3yJS8QbHl1SwtqWGCre2oRM0rlMPtAe9NxJfwAZOsRbQEibyGGHuXafzZv5u3Ej81pWxmgof09aydtdd/EcvCHLO3YwZLq9nc9knrh2Bp+F39LiLAa5qd6hcr1hkTLsgrg7xKf5l7/Q/7bvvm6/l13G3/335690KJGOOzLYmPSwlM8OdnQ4f3LQAGTexkMRTYmJl3TSM7O2lsf0DokrDW5esZEX3jtt3eosFRkR0BjX81NCMOXlkYZNb5f84mKKkoSzeQspr4XvbVAU0ayp4fUUN4Oc25YtDK3LtGqu9MXbsU7cL1LwejsgyfOVp1qQNxjDwqGhIbq/gbyDsfja14BjjuHwIY2N/ZDNQhpL55lnWLImi99dkqfXQ1GUAc6vfsWB6+Ih0U+dnWkPAllYLp0gd0I8VOAHJxJNIrWfeOPWeNsn/Nu968V1Ja4HWSfpJK24J7z7FbeS1CIzfe7UIh84lJZyKI7TTmMN2j9y6rx5wC23uO8xdHTwM5Evvxx6Vgaf4O+0U3b3L64iwDXEiStDGqjEreIPDQxqDA1CXDqxhmkQUfHi7YHo7WUs6WNV2weraPh93mF9fANw1zNVwhxnZ7Det4GGd2wfIDpqy+vCveMORvTEewY+8xk2Yu+6a9bG+Bp8gv/xx9ndv3/sdi/eSAvANQSmSjJiEiRg/raAWNvzCYkS8lrIYYqzomQT/7Pq14AgzjuPAwwCDAC5+WbOP/ZYqFkLYvAJ/qRJuc5BbojX2SkfhV7wjpMy0BlMbpZJk1J3j3rx9hD2GjBeizjMayWROOXlDBAoL2ett7rajdYpY0ZVVzMCZ8kShvdu3MhooU2bGHwQVk3M+zw0NzOPd9zBkUmlJvDGG07w+4HBJ/iFSlgvj9/3nI9IvwjJp3z6rqmJL22i/6Ybty7X5MADGTYq6yT0T0Rs2TKGNg4fzlqeDBXg/fQlEP+DGUHI/72joHrzJUi4aUNDcI23osIde9dd6Tf2dpYrKnJiX1oaPRrs8OFu6IFhw1wIojFcV13NWnB1tRtDZ/Nmd+y6OoZulpRQcIcPZ3jqtm3RH0f3DkMhfu+KCt7jbdu4H++QFeJm6+mJHsgvyBDyXqt77uFvcTELipEjXd6t5fEaGhghJ7XQZ591/5cQ1A8/ZHr50IrcE6nlyyijX/9633vajwy+KJ133uEYHkBswZKL3NXlYpTlm6PjxnGbNPbFchH5feRAdAyxWDjeTwd6f4uKWJ2zlg/Y+PF9v1Uq+7bWjeXtDdWUnp5i3Xg7Rsl/vWIg4iT76OpiPHRNDeOzJUZcOql5v5Pa0sIPxnh9lfJt0spKxllLnvfe2zVuSl7XreOL8fHHzOvRR9NfOXUq8MMf5nZY3bDwima6JArxSzU//ryUllIst2zhcaZNc6OQykio3tFTky34g/Itz1pQp8I81Z208IYZe/32EvYqQ1VXVbFvgozQWVVFA+X557n8jW+wcNlvP+DkkzPITiGFZT72GL+QpCjJImOn+HsQSw9RRQmTyZMp7DJA28qVXF9bS8Pz4ov7jliaAoUVljlhAi0Yb+ictwT2WslFRbROi4pogXZ0sHq5cWNsP159PS1VsYI2boy2bEaOdINFeWsBLS3Rwx1ItRhg6V9bGxxdI5aCN9/yKz06JW2QdR/UoUmuR2cne0GWlLghbcVF4u8gZgzjg2X/JSXspSi1gc2b3bb6+ugGZG/PzGStV7l3/dEhy9rg+52txmO5tlIL8rsdpLCR2qCsk2vt39eQIe6DLWvWuGd/yBDel4oKbmtpCba6E+XVH64aZCQGpQvy4cvYRQBdP+XlbmRR6UwoBa53BE9ZJyGt3tqz9/3w3jN/IIBXD2T/8ulJuS7ihurqYl7GjHHvg+xbBvUDOIxHYyPdTN3djLQ58EC+AxUV7mM8VVVsL1i/nt8XkA6cCxe6BlwZfyiL414NPsH/6CNe/HRJNGxCouEXNmxI/Zjd3cEfxu4vursT+76D/rN2bfA2/zUyhm4j+aiKCJy4v4J82YO5562/YA4SUBGkZPYl30/1IoUwEH19U72uyYbxBqULOpZ8OlKQ7zIDfePT45HM9fHnKSg/3uMHkeh9XrnSWeiA+2xkEMZQ+P3tL975LA9yOPgEv6Eh1zlQ/Fgb3ZAmL6L/5Q8iyOdbU+NqCzU1ruCwloVQWRkH8RIrs6zMfVHL296xdCnbDnbaid3e5YM4Mu7LMcfw83S9vcCf/kQLDGAPyAkTuH7ZMhoJ06Zxf96XeZ99gBkzWHuqr+fv++/zpR81isMVT53Kr0TJi750KaM2Dj6YFvnixX1D/YYNo/W+YQO3DRnihsZI1QXlbwD24/fNe2scMi6NWPKtrTzHpiY3BEFxsbuekncZlmPVKl6L2lpn9ctX2bz3TkZQLSvj/f3gA1rSpaW8Z7vswu8jyGc8pc1LRlz1ftu4uJiNrs88w+t37LHumQBogVdXM09y7l4XX3ExG+SFAw+ki6aqyh1jzBhGObW3uwZv+WZzSwu3C/Gi67LA4PPhb9kCXHSRW5YejvJA+RtPGxrYq+0Xv2BV7b77XOt6czN7yHmtp1mz+PDJp83mz3efcAPcQyoWSCxLJxkkn95JxrWRSRqEvONxixtFBksbMcK5mbzV5ZYWnpu4Z2T71q18WeTrRfLQeqMtvOcJJBd/HEQswRF3W28vLdR4DfDeF1qiYYYOjY74kMJFqv9yrv31/Afdy5YWPpvyTWW5v8uWsVAZPpzL4npbu5b3RiJIZPjkTCKq7r+fPUAFfxTTTjvR3SlW8GmnMc1f/8q2ssmTub6piWPtSyPw1Kl8pnbsiP4MZ30972tXF98fGcDN+1x6573LsRgzJvn+N62tLBiyGYV26KGuITYR773HbxsAoeUnng8f1tq8nPbbbz/br3z5y9aOH993/ahRXu+4tYsW9U0j2zsgFVQAACAASURBVO68M/b+d+ywtr3d2rY2azdvtnbtWmsbGvi/E06wdtUqa1eutHb1amubmqzt6srsfJqaXL4eeSQ4zZ13cvvMmdHrjzmG6888M3p9fb3b5wEHRG+rrXXburutbWnhOW/caO3zz1s7bVr0dfRPp59u7Zo11jY3c/nGG92+e3u5r8WLue2223iM3t7oPCxaxO277ZbcNbrpJqY//3zuq7ub1/2DD1y+9t/f2rq66Lz+939b+/bb1r76qrXnnst1c+ZY+8AD1p5yirUHHcR1J51k7U9/au3VV1t71VXWXnmltZdfbu1ll1l7ySXW1tTwunz1q9Z+5Svc1xFH8L8zZlh73HHWHnWUtYcdxt+ZM7nt8MOZduedmbfLLrP2u9/lcYYMsba6mtfg5puZ/owzrN1nH87/7GfWdnT0fa4Ba8eN4/8Ba43h77HHWjt0qEvz8MPWvvmmmxdWreK6n/yEv3/8o9vmPcaPf+zWG2Pt976X3L2y1tqeHmt/9Svu58MP+Yx99avWDhuW/D62bXPP77hxbr9dXbwura3Wbt9u7dat1m7aZO2GDXxXV6+2dsUKa5ctiz6fm2+2dsECa19/3drXXrP2lVesfeed5PMjzzSQ/H8SAH6HJFBXB59LJ13iNUbFW/YSz/8mQ7ICtHC86auqwh8+1ZvPWLG+sc4l1rj+yfwX4HnJB2KGD6fFs3gxxx4/7TRadL29DIG9917WsKZOZYO59GT23guppck+xRr2I/9JtrE1lv90yhQXq97a2nd/I0a4hrZHH+V/JTLsC1+gNV5dzQ+lfOc7sY//wANM4/34yGuv0U1w9dV0W3h54QVey//5H7qbzjmH463cdJNLM3s2repJk/gd1ksv5TFuuIHWugQdfPvbwBVX8PqfcYbL+5/+FH1McYkIp54KHHUU573XRWppiZ4d/2cSU3FpSK0ScC46ia5KFv9zJfv1unVSobER2Guv1P/nz0M/0b9R//lMshc+XrpUO1F4H7iwifVR9aDjx1ofL1/pPKh1dfytrmZBcMwxrs9EMoWMf9ySTIl3rOXLKfjvvst8xvqftbEHZkuUzyDBk/8E5c2/3yAjJajjnDfC5JprgCOOAH7/ey7/6lcuTdD+/Hk87TT3FaclS9z6ZAU/KL+p4H8GUu234O3fEsZ7l6lgq+DniGR9eulavUEkI3LpkoyFn2h9mIWb/z8iQn6BiyeWiYRU1idbIMQ7h1GjXIherHwA0R3M/PtNRvD9eYgn+EFi5z+GpPFuMwb4+985v2IF221km3dExqB3wC+m3/wmvxcB8Duvv/0t51MV/HjnGQ9vO1WsPMfDm1YFv4BJ1qUT7yFJtUroF7kw8bsrEqUJWh+2he8vhMR76T1WMoIfZk/UTP8Xz8JPlM+gwsJ/PeLt1x937l3nt/BlYK6LLwZef9190Eca6yWdX5CDCpQpUzg/cSIDJHbeGTjuuOh8x3p2MhV8b5SQLKdr4Yfx3mW6j34eWkF9+EIuLPxsCr73QepvH34y//F+qStof/1h4Ych+PHG2k/HpRPregTtN8jC9z5TXlGVvinyIXTJc22tizUPOqY/j+L6AfjJwyVLnGvn0EMZhhprX968xzvPePhrObm28DPdRz9b+Cr4XjIV/Hzy4Sdj4ScqCFKx8JN5cP15iufSCSJsH3661z1fXDqxLHzZb5Dg+wtz70fYk3HpeAW/vBz48Y+jt3/wQez8e/MeryYTD38tJ6jQi4e/J26mePexfHnqo/UG5aGzM7Y7MUNU8IVkXTphCn42ffiZNNpmK1/+Wke6Lp10LfwtWxjjPn06Y9qlp/DWrfF7SEqHK2HBAmDOHOZ5zRque+EFNkZ3drphKlasYN8Oa93HsDs7+f+RI9kZZ+lSjtjY1MRG4mXL+N8nn2Sc+qZNwKJFzLP0xl60iH1Etmzhf554gufwzDP0z3d0cL+/+Q3TP/EEOxR5r6Ff8K0Fnn469lAcgkS0xLrOsm7ePB7T34P8wQd53eW4r77KdgBjGEsvA7v19LD2UV8fPUlP+J/9DGhs5H+6u4F//5vrd+xgFNyaNYyw2rYtOqZf+tSsXcvrdO21XN/Wxkk+rp4sxvCYBxwAvPUW10kHP/movHzbescORpsZ4zr/eTseDh3K/NbWAi+9BOyxR/L5SJLBJ/hdXexJJx06qqr4AFRVcbmzkxdbRseUYVHlA99dXXxxPvyQ+/N/8CSeqHd0UDjq6thJScbPCZq6u11npaYmvqBDh7oHXTqjWMsHsbaW/5HR94KQj493dUWnKSqiSLz9NjB6NDuqlJW5ruw7dnCU0fXreT2kir98OcMO5Wta3odz82ZuW7mSVp33Ol14IX+3bOG1bmzkcaXq397O6YEH+GADfOnvvNN1EJs9223znh8A3HYbz+W22+KHZ/q55BLg7rv7rn/oIU7J8qc/9Q1fPPTQvun++EdO8XjySU5+fvrT2P+54oroZfGfe1m40BVi3nPz+9inTHGdhN58s+9+/B2I9tvPzZ91FkM/AUZdvf++u/a//GVw3tetAx5/3BWijz0W/OGPRMNY33Zb9LIMV50sUlD/4AfR6ysqXEeoZHjnHYYbi9jvsQfdZp2dfP6NcV/Cq6hgwTxkCN8XeZ+kVvTZz/KdmDaNQQNZYPD1tN2wIWsXCwAbqryDi1VW8qaHjdet0tPjfN5FRcCXvsSXc/NmWj1STf3oo+DxSKQLen8h46RXVLCw2rgxOF1VFV+u+fNZKEycyPXPPcd+CVVV0S6H7m6+WMOH0/JduDDaCnr7bcZE77yz62Xs5cgj+aKfeiqv44YNLFiOOKLvOOVevvjF6OVLL+W6lhb20H72WeCRR9xHLlpbGSP/xS8Cn/88C++GBhZYRUWMh+/poTCceCKjXcrKaCi89BJf/L/8heI6ZAhFor2d1u0ppwDnnsuhBP72N4rFT37C+zt8OHDVVRTTww7j+j33pKXf2Mi4/vvuY2jl7bcD55/PZ6axkfk6/3wWZF6hnTCBz1lbG5fl4x233sohfD/xCd6Hhx9mX4veXieYd98dPWxEcTELq//9XxpHlZXAd7/LD3tby2uwZQt775aU8Jy3bo2ennmGQ088/DCv/0MPscCYM4f7X7SIjdJf/Sqfw9Gjo3tir1vHQm6ffbj/hQu5rb2d1vWQIW7s+ljEqvm+9x6/L5AKq1fzGgOhuSoLa7TMoUNZvevocJNU1zo6KEJdXXy55OMOra20Lt96C9h3X+DFF/kCz5zJsd3XrXP732svZ4UWFfGhE8E/+2yKSns7H7TaWq4XX7V36unhQ7lhA3D44cCXv8wXq7iYeW1u5v+6u6NH8Lv/fuZVaGig37Cyki/frru64QquvpppPv95jjeyzz7ctnkz8/7UU+wi39gI3Hgj19XV0S/77LMUniuu4H/Ky5lPqRJPn05xqKmhUMtHLIC+A7H19rphKE48kfdoxAgK2u9/z5fsoouAyy/n+ZaWspbw/e9H76epiQXcrFnsbDR9uvsO6JlnunSxXpytW2k9XXcdl3//ewp+YyMLgViccALwj3+45SlTgIMO4vxjj1Gk/bH6X/oSjyWdmoIwhqLkFQkRm7Fj3XdNx47lr0SBnXIK8LnP0WW0ejUjb4Rrr+WvjFED8NmQwjSeu07GvvELvgztAPBYVVUU/C98ged5330UYP+AZuLa8J6v3+1WWxs9tszw4W6+spKTnD/gapLTprHQW7SI9+D447nefx/8yLtkTHQHvqoq916nwuc/zwJ7jz1i17zjoY22GVJWRgFIlYULaS298AJdG1JL8LsMbr21b69YuWnnnsvBmJLl0ksp+I2N/G8yXHcdX0Dv+ECxEMG/6CJafH7q6yn4o0ZFC570/Bw/nr00Be+1qK93ERmJKCriMerr3bJ8aCWVRlvZNmoUz+njj+kmevxxWoryAfuWFrqaROSEpibXQzbZYwLugxX+/wHBUTqSJpHFlq2wTP82f8SOd/9BHa38efTvP6g/gKSNFwXjzUemUTrxrkE8vAVOGMESRx5JQypdBmJYpjHmeAC/BFAM4A/W2ut92y8DcAGAbgAbAXzFWrsijGOHhvdhjOcSCjM2PZ2wTBk0LRVS7XiVrXDReFE6qTTaFhWx4BUWLmSD4z330OrdsIHiv/vubpgEgAWEFDpeUq1KJ4rSkTzmKiwzXk9b/3X2R60kKgC8UTr+ffqFN57gZxqHH+8axCNoaIVMyHR03oFm4RtjigHcAuAYAKsBzDPGzLHWLvIkexPADGttmzHmIgA3Ajg902OHShhROv0h+OmQbpRO2NaHP9rD2r4CF0/wY1ml06dz+tSnaG2NGkX30FNPMepFGnt33pmfVgzzPGJZislYntkKy5S0QbHq8a5zMmGZ4gv3/tcr+P577M9b2GGZqVr4YQ+tkGl74UATfAAHAFhqrV0GAMaYewGcDOA/gm+tfcaT/hUA54Rw3HBJpgou6dLZFkS2hDXWcfwkKgiyHZYZZOEL6YRlChUVHBzs299OLl/pFtRAbJdOMpZnPJdOPAs/3rACyVr4QYVnshZ+PJdOIsH3Cm6s84xHUE9b2V8y+wrbws/0gyX9LPhhKM04AKs8y6sj62JxPoD/C9pgjLnQGDPfGDN/Y6zIjmwRhuCna63kysJP5OpJ5XySOYcgl04sCz/e/8P+9GCmLp10ffhBIpWMDz8Zl06yFn4il068jldBLp14PnxvnsJy6SRrBAj5NnhaP/vw+/VoxphzAMwAEBhkbK2dba2dYa2dMcI7xkf/ZC45l06uffjpkKpLpz98+H4LP5bwBf0/3Y5X8fKTCn6XTixrPB2XTjwffjIuHRHVZH34ktbfpiJs2ND3Az+xXDrejnTe9UIYPvxYhU2y9zzsRttM35EB6NJZA2CCZ3l8ZF0UxpijAVwF4DBrbZyPSOaIXLh0+kvwU3XpxLLww3y4Y/W0lXSp+PDTJd395ItLJ5aF798WZOH7r2VPD3uv+vfn/8az18IPw4efqUvHe02Sca9kc2iFXPw/RcKw8OcBmGKMaTTGlAE4A8AcbwJjzD4Afgfgs9baNL7y3Q8ka+GH6dLpLx9+qi6dWAVRpkLr97fmevC0dOkPl048wU/UaJtqlI58WnG33foec7fdouPgE/nwg75/68+bpI11nvGIdWy18JMi4zO21nYDuBjAvwC8B+B+a+27xphrjDGfjST7KYAaAH8zxiwwxsyJsbvcEesFjWVBxdpHqsdM53+pEpaFnynJunQSuZqScZVkg6BOS5m6dFLx4Qe5dGI9n95tfmvf+yvCV1HBDl1+/CHAXpdOqj78bFv4yRC2hZ/pOzIQ4/Cttf8A8A/fuh945kOIhcsyYVj4+Sr4+ebDFysxVZdOshZ+tgnLpZOqDz9IaOONlhkUuhgUpRPvfsdrtPWLdjKNtplG6agPPyP6t3jJZ5IV/DAbbYMsxmyQaser/vDhx3PpZOrDzyTqJh5B9ytbPW2TdekkY+H7rX1vOu/1DzqmvxaSyIefqoWfrhs0UwtfBV/JWVhmrnz4qVr4YfrwM4nDj/Vyp+vDTzWqJ1cunSCh9edd1vndOH6BTNfCLyoKx4cfVlhmuhZ+OscOItN9DOawzLwm2Rs3EF06+erDtzY1Cz+RS0fIh0bbRC6dWMKeaVhmqhZ+IgEMqkHk0ocfVDPxLicibAs/032ohZ8jCtGHn2qUTjrHiLVfEatUGm1lW9g+/FQLe+91S9elE0vwwgjLjBel47+3iaJlsu3SSdfCz9SHn86xg1CXzgAlGZ8rEL9ET9cfmSvBT7Q+ng8/HXH1W/ixXDrx7kUy9ylbLp0wo3QyEfxYFn5bm/taU6w4/EwbbRO5dJIV/LDCMtO18GMV1KkywAR/8A2PnC7JCn42LPxs+/FSdelk24cv8/IFr1SOFU9IU/Xhp/uyZdOlk2pYppe99uJgcRI6mYyF358unXyK0gnKXzqoD3+Aoi6d1Lank2e/ayBbFn6ypLqfMKN0YhV0qYZlAu44S5cGu3u8gp9qlE4yYZm5aLQNw4evLp0CJhcWfq7DMhMdN972sFw6sRptYxHPck43SidV8smlA/Q9jt+HH9TxKlmXTlAUUJg+/HTdoJlG6WijbYGTCx9+ri38RGQzDt/f8cov+P3hw89nl05Q3lIRu1Qt/FjHDHLpxMtHfzfapmvhB+UvHdTCH6Dk0qWTKx9+IrLpw8/EpRPW8Mj56NKJZ/kGuWG8y959+P32foHNhQ8/DMGPdQ3SsfDzwaWjPvwckeyNG0w+/ERkOw4/1cHTJF2uXDpB9ytsl04yPnz/f2MZKvEs/KAG4FiC779v8VxL8WoM3lpHplE6QYVNMhR4lI4KvpCspZDIv5wKufbhJyLsfKXi0olFIlcJMLBcOqn48DNx6cSy8BO5dIIabdMNywwjSidWpFI6UTphPN/9bKFnysDKbTaJ9eD0h0tnoFj4YVozYnX6LTXZ1h9hmanWBILuV6Ydr1Lx4afq0knGhx/UaOuvwfjzkE8unXQt/LAabfvZQs8UjcMXcin42bYSwrBkw8Afhx+vp21/NNqmSixBjGXhxxOhTHz4YVj48Vw6QcLs3W+sfPR3T9uODmDJEi5fcQWwaRMwbBg/Wr9jB7BtG7BlC7BuHXDddcDXvhZ+lI4K/gAlluCnIh75auGn+2DHsj6B1ArCoDR+l068Y/nzlMiHnyxh3K+gES8lTTounXR8+JlY+EEuHX+B5r/v8QQ/1Tj8VJ9N+arVmWdS1IUnngAaG4GPPgK2buVHW0aMAHbZBVi0CPjmN4Hzzsu/OPx+RgVfSNbCj0e++MrD2n+8/6VjRcdz6STrw8+lhe/Ng9CfLp1U/Nd+wU8lSieRSyddH34YFv6uuwKXX06xHzGCn2D87W+B+fMp+EH89a/A2WezNqAWvgIg9cafePtINf1AsfDD9OFn4tIJe3jkZAlqZM+FSycZ/7W3JuTNS6wonaDjBO3b69JJZ2iFTAW/pAS48Ua3fNddFPx417q6mr9XXw188Yuc7+4uyEZbFXw//Sn4mf4v2/vPtg8/lksnUx9+tsmmSyeZRtswLXxv/pMxQBK5dBJZ+N6wyETHSoZkDDX5TONDD3ECgDVr+FnHTFELf4AShoUfliUdNvnS8SpZl068Y+VyaIWgRnZrnV/ZnzYdl048IUw1LNO7r3hROt48+48dFJYZ6xz6YywdP8lE6ZSWuvmaGqClhY28F12U2bEBFfwBSy5cOpn+L1/2nyx+l866dcD117tlb7p4Fn5LC9DeDmzYwHQiNCtXMk1PD/Duu259UxNQXs7hg1taOBUVAW++yfQbN0Yfo6uLIt7ayv+2t0fn8aKLgNGjKR5vvAEccEDffGbq0oln4SczrMCf/ww89hjnr7gC6OyM/k8qHa+8eF1CufDh+0nFwgeAiRPZiHvKKcCkSZkd23v8AYIKvjCYBT+sGkSYPvzddwfuuw948MG+2+IdZ8gQ+m3vuit2mtZWYPr05PP16KPA3/4G7LYbf2+9lfsQoRdEOKqqGBK4YQMwbhwbD3/yE17n4mL+bt0aHUXiJ5FLJ9WwTL/od3W5/Le3A3V1wEknATvtFL2voKiVRI228puLOHw/8Wo5glfwpTYW1juhPvwBymAW/HyxQrz5+P73KZRSrU620fbppzk9/DAwYwYttqIiTu+/D/z4x/TN3nWXa2CsrOT+qqtZYFRXc/kvf2F6ADjtNHeMsWOBffdlSN8nPgHMnk1Lfu1abl+8ODpP77/PwsvPqlWxr0UYLh2vaMuHT4QLLwQOPhg46igWYIcdFr09qD0gVcEPakvIlYUfrzblFfywAyXy5d1KEhV8IZct9vna8cpPmD58gEIsJBuHv9NOwJe/zMnP889TwIuLXTRGPMTaPekk4NxzXT6OPhqorXXpnniCgn/ppcDNNwO/+Q1wxBEssBoaKLYiur29wPbtwPjxtLJjEaZL57zzov3Usi2VEE9vuniCn8ilE8+HHxSlk+mzn6qFHytv6aKCP0AZzBZ+f1Q70zkHr+Ana+EnQ6r/HTECOPXUxOnq6/k7dSpdUoK/0VbOq7s7cR4zidKZOZO1nI8/7mvhHnqocyklU3h413mfl23b2FbhT5OuSyfTsXT8JGPhewvDsI7rP/4AYWA5oLLJYBb8fH24Y1n4mR4n2XuYrfslFqXfzeIlDB/+PvsA8+YBb70FvPBCdNpPfSq1wiNWOiC6thPk0knHhx9WWKZa+CkRioVvjDkewC8BFAP4g7X2et/2cgB3AdgPwGYAp1trl4dx7NDIZVjmYLDw0yFsC1/+093NxtdEzJ/P348+ip9+9Wr+LlzYN6+xKCpKzsLPxIfvJahwSdal09PDMWekQ1Nbm0t34ols9H3vvdj3KB+idJL14Ydt4efruxWDjAXfGFMM4BYAxwBYDWCeMWaOtXaRJ9n5ALZaa3cxxpwB4AYAp2d67FAJQ/CD4rGTYaD48MMmWy6drq7oRthEPPMMp0Tcfz9/hw1LnLY/wjK9eAV/4sTofSXqtVtWRlH3W98AcOCBwdcmyIc/dy6wYgXnhw/nfv3HzHWUjv9/mZKv71YMwrDwDwCw1Fq7DACMMfcCOBmAV/BPBnB1ZP4BAL8xxhhrc91l0kMYgj9yZGbHzhb9YYUMGwZs3hzt701EOo228ZD//OlPwP77J07/4IPAD3/ImOxrr42d7lvfAp56ig22p5ziGnvjUVLCqJ4zz+Tyxo2sSdTUANOmuZDJVATfn8aLCP7ee7uaRbIunV12YT+F885jdM/w4Rx5EgCefJJRSP7jev3xIqhz5rj7/3//19cACmNohVjnkayF7/9fphSg4I8D4I0/Ww3gwFhprLXdxphtAIYB2ORNZIy5EMCFADBRrJT+Ipbg7703sHRp/P8+8QTjtjM9draItf9dduHvf/1X9PqzzqK74/DDo9fvtx8FYP/9gauuit72xz8y1NK/Ph5Dh7r5WNZ+OkyaBOyxR+J0xlDwzz8/fvrJk/k7bVpyYg+wY1ZzM/Dqq8D69dFukrffZmjo7rvTD+8lUfRKcXG0xb14MfDii4z7l3NKxk8uDZnf+hZdVkcdBRx5JEM5X3rJpXv+eTd/7LFu3nucmhre/8pKnucFF0T7/U8/nWGrxcUsOKdPdyIcloU/bx4bmIPwdqxraYn+X6akYuDkAXkVpWOtnQ1gNgDMmDGjf63/WIJ/2GHAAw/wAT7uuOD/HnNMesc8/njg9dfZ4Seb+EP2hBEjgq3Fgw8GXnml7/oHHqAf++CD+2475JDEbpGGBuCyy1wIZGMjOz11d0db5Jn68JNl992T+8/Pfw7stRfvV7LU1gLLl7PWAwBnnAFcfDHwgx+wh/GSJfSbV1XR2n/ySbqi3nqL6WMJ4QknsAftmDFcXrcuentlpetVG8+KnjqVPvvXXmPI6aGHAjvvzMbf555jX4cnnmDv5bVrea3uucf9v6sL+MUvgO99j7W7r3yF6+++u+8x772X0+OPA3//O2sPW7bwOdpzz6QuZ0yGDOFvssMkLF8e/b90eP114IMPgE9/mvdvABGG4K8BMMGzPD6yLijNamNMCYA6sPE2f4gl+GeeCfz617RIxIcbFldcwSlbPPOM6/0ZBrW1wWKfLMYAN90UvXziicHp8sjbh+pq4OtfT+0/Rx1FoTzkELqBvvQlrp87l7+XXkrBnDqVvm5vr9zqarpYgrjlFvroJca/ooLP6Lhx3M/FFztrP57gFxdzmGE/xrBmd/jhwDXXcF1HB40G73N01FEU8MmTow2Kjg63fz+f+QynMDn0UBZSXV2xrfamJuDkkzm/777AnXcCEyYEp02GffflFBZFRc4IyjJhCP48AFOMMY2gsJ8B4CxfmjkAZgF4GcCpAJ7OK/89EFvwhw1jVT5er8l8xe+SGUhkYuHng1/15z/nFItrr3W9eFev5tC9MibPyJF9GzyFCRPY8SsW2WgYDRpV8tFHgZ/9zDXSehkxIpxxapKhqAj45Cfjp2lqcvP19akNu9EfxAvfDZmMBT/ik78YwL/AsMzbrbXvGmOuATDfWjsHwB8B/NkYsxTAFrBQyC/iNdp6xxlRsk8hXOuamtg9hjMhGw2jQRgTXEPIR4IabQuUUK6EtfYfAP7hW/cDz3wHgCT6uucBsQRf6T8y9eEXQoERi2z0Zh3oeN1jBX4tBlavgWyiFn7+kG8+/IFENlw6A53SUoaMAmzrKGC0riOo4OcXauGnR5DgD7DeoFnhpJMYQSSNtwWKCr6ggp8/qIWfPmrhx+bss3Odg5yjRb+ggp8/pHutVeCyM0CZMmhQwRdU8PMHtfDTp7+idJQBiQq+oIKfP2Qq+IV8r4qK2Jv08cfZgxYo7OuhRKE+fEEFP7/oj6EVBiOHHQbccUd0D+a6upxlR8kvVPAFFfz8IawRFAuRWbM44J8M1VBfz88tKgpU8B2JRKKQRaS/6a/B0wYjxlDwFSUA9eELauHnD+rDV5SsoIIvqODnF2rhK0roqOALKvj5g15rRckKKviCCn7+oIOnKUpWUMEXVPDzB+14pShZQQVfUMHPL9TCV5TQUcH3o4Kfe9TCV5SsoIIvJLLwlf5DB09TlKyggi+oSyd/UAtfUbKC9rQVRNB//WugoYFDy8rwsitWALvumru8FSLqw1eU0FHBFyZPBsrKgFtuoWAUFfFXxOP003Obv0JCLXxFyQoq+MLMmUB7e7TIK7lBB09TlKyggu9Fv/2ZH+jgaYqSFVThlPxDB09TlKyggq/kJ2rhK0roqOAr+Yf68BUlK6jgK/mH+vAVJStkJPjGmAZjzJPGmCWR3/qANHsbY142xrxrjHnbGKPxjUp8NCxTUbJCphb+lQDmWmunAJgbWfbTBuBca+0eAI4H8AtjzNAMj6sMdrTjlaKETqaCfzKAOyPzdwL4nD+BtfYDa+2SyPzHADYAGJHhcZXBI0CVgQAAC5pJREFUjAq2omSFTAV/lLV2bWR+HYBR8RIbYw4AUAbgwxjbLzTGzDfGzN+4cWOGWVMGLPoBFEXJCgk7XhljngIwOmDTVd4Fa601xsR8S40xYwD8GcAsa21vUBpr7WwAswFgxowZ6sQtVNSHryhZIaHgW2uPjrXNGLPeGDPGWrs2IugbYqSrBfA4gKusta+knVulcFALX1FCJ1OXzhwAsyLzswD83Z/AGFMG4GEAd1lrH8jweEohoBa+omSFTAX/egDHGGOWADg6sgxjzAxjzB8iaU4D8CkA5xljFkSmvTM8rjKY0Q+gKEpWyGjwNGvtZgBHBayfD+CCyPzdAO7O5DhKgWEMMH8+cPzxXD73XOCss3KbJ0UZBGhPWyX/OO00YJddgKYm4IUXgD//ObX/q4WvKIGo4Cv5x6WXAq+8wmmPPZL356vfX1HiooKv5DdFRakLuVr4ihKICr6S3xjjvi2cCLXwFSUuKvhKfpNOiKZa+IoSiAq+kt+k4tJRC19R4qKCr+Q3qbh0FEWJiwq+kt+k4tLRjleKEhcVfCW/SSdKR1GUQFTwlfwmnSgdtfAVJRAVfCW/UQtfUUJDBV/Jb9TCV5TQUMFX8hsdKllRQkMFX8lv0onDVwtfUQJRwVfyG43DV5TQUMFX8hsdWkFRQkMFX8lvdGgFRQkNFXwlv0nHpaMWvqIEooKv5Ddq4StKaKjgK/mNWviKEhoq+Ep+k87gaYqiBKKCr+Q3OrSCooSGCr6S3+jQCooSGir4Sn6jQysoSmio4Cv5jQ6toCihkZHgG2MajDFPGmOWRH7r46StNcasNsb8JpNjKgWGDq2gKKGRqYV/JYC51topAOZGlmNxLYDnMzyeUmioha8ooZGp4J8M4M7I/J0APheUyBizH4BRAJ7I8HhKoaEWvqKERqaCP8pauzYyvw4U9SiMMUUAbgLwnQyPpRQi+hFzRQmNkkQJjDFPARgdsOkq74K11hpjgt7MrwP4h7V2tUnwIhpjLgRwIQBMnDgxUdaUQkDj8BUlNBIKvrX26FjbjDHrjTFjrLVrjTFjAGwISHYQgEONMV8HUAOgzBjTYq3t4++31s4GMBsAZsyYoW+5okMrKEqIJBT8BMwBMAvA9ZHfv/sTWGvPlnljzHkAZgSJvaIEokMrKEpoZOrDvx7AMcaYJQCOjizDGDPDGPOHTDOnKGm5dNTCV5RAMrLwrbWbARwVsH4+gAsC1t8B4I5MjqkUGOkMraAoSiDa01bJb9TCV5TQUMFX8hu18BUlNFTwlfxGB09TlNBQwVfyGx1aQVFCQwVfyW90aAVFCQ0VfCW/0aEVFCU0VPCV/EaHVlCU0FDBV/Ib/cShooSGCr6S36iFryihoYKv5Ddq4StKaKjgK/mNxuErSmio4Cv5jQ6toCihoYKv5Dc6tIKihIYKvpLfpOPSUQtfUQJRwVfym3SGVlAUJRAVfCW/0U8cKkpoqOAr+Y1a+IoSGir4Sn6jg6cpSmio4Cv5jQ6epiihoYKv5Dc6tIKihIYKvpLfiLWejOirha8ocSnJdQYUJS4i3medBVRVATU1wJlnAjNn5jZfijIAUQtfyW8OOwzYay9g/nzgX/8CZs8GDjoI+O1v+6ZVC19R4qIWvpLfHH44sGCBW25qAk44AbjkEmCffYADD8xZ1hRloKEWvjKwGDoUePBBoLoauOACoLPTbVMLX1HiooKvDDzGjAG+/W1g4UJgzpxc50ZRBgwZCb4xpsEY86QxZknktz5GuonGmCeMMe8ZYxYZYyZlclxFweWXA8XFwE039d2mFr6iBJKphX8lgLnW2ikA5kaWg7gLwE+ttbsBOADAhgyPqxQ6ZWXAuecCr74KPPQQ12m8vqLEJVPBPxnAnZH5OwF8zp/AGLM7gBJr7ZMAYK1tsda2ZXhcRQGuu46/p54KrFvn1quFryiBZBqlM8pauzYyvw7AqIA0UwE0GWMeAtAI4CkAV1pre/wJjTEXArgQACZOnJhh1pRBz5gxwKOPAiedxFDN9vZc50hR8pqEgm+MeQrA6IBNV3kXrLXWGBNUpy4BcCiAfQCsBHAfgPMA/NGf0Fo7G8BsAJgxY4bWz5XEHHcccNFFwMaNXN5pJ6CuLrd5UpQ8JaHgW2uPjrXNGLPeGDPGWrvWGDMGwb751QAWWGuXRf7zCICZCBB8RUmZ0lLg1ltznQtFGRBk6sOfA2BWZH4WgL8HpJkHYKgxZkRk+UgAizI8rqIoipIimQr+9QCOMcYsAXB0ZBnGmBnGmD8AQMRX/x0Ac40x7wAwAH6f4XEVRVGUFMmo0dZauxnAUQHr5wO4wLP8JIBPZHIsRVEUJTO0p62iKEqBoIKvKIpSIKjgK4qiFAgq+IqiKAWCCr6iKEqBYGyeDjhljNkIYEUGuxgOYFNI2cl3CulcAT3fwU4hnW82znUna+2IoA15K/iZYoyZb62dket89AeFdK6Anu9gp5DOt7/PVV06iqIoBYIKvqIoSoEwmAV/dq4z0I8U0rkCer6DnUI6334910Hrw1cURVGiGcwWvqIoiuJBBV9RFKVAGHSCb4w53hjzvjFmqTEm1kfVBxTGmAnGmGeMMYuMMe8aYy6JrG8wxjxpjFkS+a2PrDfGmF9FrsHbxph9c3sGqWOMKTbGvGmMeSyy3GiMeTVyTvcZY8oi68sjy0sj2yflMt/pYIwZaox5wBiz2BjznjHmoEF+by+NPMcLjTH3GGMqBtP9NcbcbozZYIxZ6FmX8v00xsyKpF9ijJkVdKxUGVSCb4wpBnALgE8D2B3AmZGPqA90ugF821q7O/i1sG9EzutKAHOttVMAzI0sAzz/KZHpQgC39X+WM+YSAO95lm8AcLO1dhcAWwGcH1l/PoCtkfU3R9INNH4J4J/W2l0B7AWe96C8t8aYcQC+CWCGtXY6gGIAZ2Bw3d87ABzvW5fS/TTGNAD4IYADARwA4IdSSGSEtXbQTAAOAvAvz/J3AXw31/nKwnn+HcAxAN4HMCaybgyA9yPzvwNwpif9f9INhAnA+MhLcSSAx8CP5mwCUOK/zwD+BeCgyHxJJJ3J9TmkcK51AD7y53kQ39txAFYBaIjcr8cAHDfY7i+ASQAWpns/AZwJ4Hee9VHp0p0GlYUP9zAJqyPrBg2RKu0+AF4FMMpauzayaR2AUZH5gX4dfgHgCgC9keVhAJqstd2RZe/5/OdcI9u3RdIPFBoBbATwp4gL6w/GmGoM0ntrrV0D4GcAVgJYC96v1zF476+Q6v3Myn0ebII/qDHG1AB4EMC3rLXbvdsszYABH2NrjDkRwAZr7eu5zks/UQJgXwC3WWv3AdAKV90HMHjuLQBE3BIngwXdWADV6Ov+GNTk8n4ONsFfA2CCZ3l8ZN2AxxhTCor9X6y1D0VWrzfGjIlsHwNgQ2T9QL4OnwTwWWPMcgD3gm6dXwIYaoyRT3J6z+c/5xrZXgdgc39mOENWA1htrX01svwAWAAMxnsL8NvXH1lrN1pruwA8BN7zwXp/hVTvZ1bu82AT/HkApkRa/MvAxqA5Oc5TxhhjDIA/AnjPWvtzz6Y5AKT1fhbo25f150YiAGYC2OapTuY11trvWmvHW2sngffvaWvt2QCeAXBqJJn/XOUanBpJP2CsYWvtOgCrjDHTIquOArAIg/DeRlgJYKYxpiryXMv5Dsr76yHV+/kvAMcaY+ojtaJjI+syI9eNG1loLDkBwAcAPgRwVa7zE9I5HQJWAd8GsCAynQD6MucCWALgKQANkfQGjFb6EMA7YEREzs8jjfM+HMBjkfnJAF4DsBTA3wCUR9ZXRJaXRrZPznW+0zjPvQHMj9zfRwDUD+Z7C+BHABYDWAjgzwDKB9P9BXAP2D7RBdbgzk/nfgL4SuS8lwL4chh506EVFEVRCoTB5tJRFEVRYqCCryiKUiCo4CuKohQIKviKoigFggq+oihKgaCCryiKUiCo4CuKohQI/x8Ocz7lI7xhqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 전처리 전 정상환자 시각화\n",
    "outlier_threshold = 0.025\n",
    "for i in exotropia:\n",
    "    plt.plot(i['data']['RPCX'] - i['data']['LPCX'], c='r')\n",
    "    \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_normal = [preprocess(i) for i in normal if len(preprocess(i)['data']) != 0]\n",
    "perp_exotropia = [preprocess(i) for i in exotropia if len(preprocess(i)['data']) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 30)"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prep_normal), len(perp_exotropia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 전 처리 정상환자 시각화\n",
    "outlier_threshold = 0.025\n",
    "for i in prep_normal:\n",
    "    plt.plot(i['data'], c='r')\n",
    "    \n",
    "plt.ylim(-outlier_threshold, outlier_threshold)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 전처리 후 정상환자 시각화\n",
    "outlier_threshold = 0.025\n",
    "for i in perp_exotropia:\n",
    "    plt.plot(i['data'], c='r')\n",
    "    \n",
    "plt.ylim(-outlier_threshold, outlier_threshold)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prep_normal + perp_exotropia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(dataset):\n",
    "    data = [data['data'] for data in dataset]\n",
    "    max_len = len(max(data, key=len))\n",
    "    \n",
    "    result_arr = []\n",
    "    for data in dataset:\n",
    "        label = data['label']\n",
    "        data = data['data']\n",
    "        \n",
    "        zeros = np.zeros(max_len)\n",
    "        zeros[:len(data)] = data\n",
    "        result_arr.append({'data':zeros, 'label':label})\n",
    "    \n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequence(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset, ratio, unsqueeze=False):\n",
    "    split_point = int(ratio * len(dataset))\n",
    "    train_dataset = dataset[:split_point]\n",
    "    test_dataset = dataset[split_point:]\n",
    "\n",
    "    train_feature, train_label = [], []\n",
    "    test_feature, test_label = [], []\n",
    "    \n",
    "    for dataset in train_dataset:\n",
    "        data = np.expand_dims(dataset['data'], axis=0)\n",
    "        if unsqueeze:\n",
    "            data = np.expand_dims(data, axis=0)\n",
    "        label = np.expand_dims(dataset['label'], axis=0)\n",
    "        train_feature.append(data)\n",
    "        train_label.append(label)\n",
    "    \n",
    "    for dataset in test_dataset:\n",
    "        data = np.expand_dims(dataset['data'], axis=0)\n",
    "        if unsqueeze:\n",
    "            data = np.expand_dims(data, axis=0)\n",
    "        label = np.expand_dims(dataset['label'], axis=0)\n",
    "        test_feature.append(data)\n",
    "        test_label.append(label)\n",
    "    \n",
    "    train_feature = np.concatenate(train_feature, axis=0)\n",
    "    train_label = np.concatenate(train_label, axis=0)\n",
    "    test_feature = np.concatenate(test_feature, axis=0)\n",
    "    test_label = np.concatenate(test_label, axis=0)\n",
    "    \n",
    "    return train_feature, train_label, test_feature, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1] (37, 1, 99)\n",
      "[0 1 1 0 1 1 1 0 1 1] (10, 1, 99)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(padded)\n",
    "\n",
    "train_feature, train_label, test_feature, test_label = \\\n",
    "    make_dataset(padded, ratio=0.8, unsqueeze=True)\n",
    "\n",
    "print(train_label, train_feature.shape)\n",
    "print(test_label, test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Bidirectional, LSTM, Dropout, Add\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(x):\n",
    "    return BatchNormalization()(Add()([x, Conv1D(1024, kernel_size=1)(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(train_feature.shape[1:]))\n",
    "x = Conv1D(1024, kernel_size=1)(inputs)\n",
    "\n",
    "for i in range(10):\n",
    "    x = add_layer(x)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid')(inputs)\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6934 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0053s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.6936 - accuracy: 0.4324 - val_loss: 0.6925 - val_accuracy: 0.7000\n",
      "Epoch 2/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6922 - accuracy: 0.6216 - val_loss: 0.6914 - val_accuracy: 0.7000\n",
      "Epoch 3/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6912 - accuracy: 0.6216 - val_loss: 0.6902 - val_accuracy: 0.7000\n",
      "Epoch 4/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6904 - accuracy: 0.6216 - val_loss: 0.6892 - val_accuracy: 0.7000\n",
      "Epoch 5/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6895 - accuracy: 0.6216 - val_loss: 0.6882 - val_accuracy: 0.7000\n",
      "Epoch 6/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6886 - accuracy: 0.6216 - val_loss: 0.6868 - val_accuracy: 0.7000\n",
      "Epoch 7/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6876 - accuracy: 0.6216 - val_loss: 0.6858 - val_accuracy: 0.7000\n",
      "Epoch 8/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6868 - accuracy: 0.6216 - val_loss: 0.6845 - val_accuracy: 0.7000\n",
      "Epoch 9/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.6216 - val_loss: 0.6836 - val_accuracy: 0.7000\n",
      "Epoch 10/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6849 - accuracy: 0.6216 - val_loss: 0.6826 - val_accuracy: 0.7000\n",
      "Epoch 11/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6840 - accuracy: 0.6216 - val_loss: 0.6814 - val_accuracy: 0.7000\n",
      "Epoch 12/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6833 - accuracy: 0.6216 - val_loss: 0.6802 - val_accuracy: 0.7000\n",
      "Epoch 13/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6824 - accuracy: 0.6216 - val_loss: 0.6793 - val_accuracy: 0.7000\n",
      "Epoch 14/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6816 - accuracy: 0.6216 - val_loss: 0.6782 - val_accuracy: 0.7000\n",
      "Epoch 15/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6807 - accuracy: 0.6216 - val_loss: 0.6772 - val_accuracy: 0.7000\n",
      "Epoch 16/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6799 - accuracy: 0.6216 - val_loss: 0.6762 - val_accuracy: 0.7000\n",
      "Epoch 17/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.6216 - val_loss: 0.6750 - val_accuracy: 0.7000\n",
      "Epoch 18/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6782 - accuracy: 0.6216 - val_loss: 0.6742 - val_accuracy: 0.7000\n",
      "Epoch 19/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.6216 - val_loss: 0.6734 - val_accuracy: 0.7000\n",
      "Epoch 20/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.6216 - val_loss: 0.6723 - val_accuracy: 0.7000\n",
      "Epoch 21/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6759 - accuracy: 0.6216 - val_loss: 0.6715 - val_accuracy: 0.7000\n",
      "Epoch 22/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6753 - accuracy: 0.6216 - val_loss: 0.6704 - val_accuracy: 0.7000\n",
      "Epoch 23/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6746 - accuracy: 0.6216 - val_loss: 0.6694 - val_accuracy: 0.7000\n",
      "Epoch 24/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6738 - accuracy: 0.6216 - val_loss: 0.6685 - val_accuracy: 0.7000\n",
      "Epoch 25/5000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6730 - accuracy: 0.6216 - val_loss: 0.6676 - val_accuracy: 0.7000\n",
      "Epoch 26/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6724 - accuracy: 0.6216 - val_loss: 0.6668 - val_accuracy: 0.7000\n",
      "Epoch 27/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6717 - accuracy: 0.6216 - val_loss: 0.6661 - val_accuracy: 0.7000\n",
      "Epoch 28/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6711 - accuracy: 0.6216 - val_loss: 0.6655 - val_accuracy: 0.7000\n",
      "Epoch 29/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6705 - accuracy: 0.6216 - val_loss: 0.6646 - val_accuracy: 0.7000\n",
      "Epoch 30/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6697 - accuracy: 0.6216 - val_loss: 0.6636 - val_accuracy: 0.7000\n",
      "Epoch 31/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6691 - accuracy: 0.6216 - val_loss: 0.6630 - val_accuracy: 0.7000\n",
      "Epoch 32/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6684 - accuracy: 0.6216 - val_loss: 0.6623 - val_accuracy: 0.7000\n",
      "Epoch 33/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6678 - accuracy: 0.6216 - val_loss: 0.6614 - val_accuracy: 0.7000\n",
      "Epoch 34/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6672 - accuracy: 0.6216 - val_loss: 0.6604 - val_accuracy: 0.7000\n",
      "Epoch 35/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6664 - accuracy: 0.6216 - val_loss: 0.6595 - val_accuracy: 0.7000\n",
      "Epoch 36/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6657 - accuracy: 0.6216 - val_loss: 0.6591 - val_accuracy: 0.7000\n",
      "Epoch 37/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6653 - accuracy: 0.6216 - val_loss: 0.6584 - val_accuracy: 0.7000\n",
      "Epoch 38/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6647 - accuracy: 0.6216 - val_loss: 0.6575 - val_accuracy: 0.7000\n",
      "Epoch 39/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6640 - accuracy: 0.6216 - val_loss: 0.6566 - val_accuracy: 0.7000\n",
      "Epoch 40/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6634 - accuracy: 0.6216 - val_loss: 0.6558 - val_accuracy: 0.7000\n",
      "Epoch 41/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6628 - accuracy: 0.6216 - val_loss: 0.6551 - val_accuracy: 0.7000\n",
      "Epoch 42/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6622 - accuracy: 0.6216 - val_loss: 0.6546 - val_accuracy: 0.7000\n",
      "Epoch 43/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6617 - accuracy: 0.6216 - val_loss: 0.6538 - val_accuracy: 0.7000\n",
      "Epoch 44/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6611 - accuracy: 0.6216 - val_loss: 0.6531 - val_accuracy: 0.7000\n",
      "Epoch 45/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6606 - accuracy: 0.6216 - val_loss: 0.6527 - val_accuracy: 0.7000\n",
      "Epoch 46/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6601 - accuracy: 0.6216 - val_loss: 0.6521 - val_accuracy: 0.7000\n",
      "Epoch 47/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6597 - accuracy: 0.6216 - val_loss: 0.6516 - val_accuracy: 0.7000\n",
      "Epoch 48/5000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6592 - accuracy: 0.6216 - val_loss: 0.6508 - val_accuracy: 0.7000\n",
      "Epoch 49/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6586 - accuracy: 0.6216 - val_loss: 0.6502 - val_accuracy: 0.7000\n",
      "Epoch 50/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6580 - accuracy: 0.6216 - val_loss: 0.6494 - val_accuracy: 0.7000\n",
      "Epoch 51/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6575 - accuracy: 0.6216 - val_loss: 0.6490 - val_accuracy: 0.7000\n",
      "Epoch 52/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6570 - accuracy: 0.6216 - val_loss: 0.6485 - val_accuracy: 0.7000\n",
      "Epoch 53/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6567 - accuracy: 0.6216 - val_loss: 0.6480 - val_accuracy: 0.7000\n",
      "Epoch 54/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6562 - accuracy: 0.6216 - val_loss: 0.6475 - val_accuracy: 0.7000\n",
      "Epoch 55/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6557 - accuracy: 0.6216 - val_loss: 0.6468 - val_accuracy: 0.7000\n",
      "Epoch 56/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6552 - accuracy: 0.6216 - val_loss: 0.6461 - val_accuracy: 0.7000\n",
      "Epoch 57/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.6216 - val_loss: 0.6454 - val_accuracy: 0.7000\n",
      "Epoch 58/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6540 - accuracy: 0.6216 - val_loss: 0.6449 - val_accuracy: 0.7000\n",
      "Epoch 59/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6536 - accuracy: 0.6216 - val_loss: 0.6443 - val_accuracy: 0.7000\n",
      "Epoch 60/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6532 - accuracy: 0.6216 - val_loss: 0.6437 - val_accuracy: 0.7000\n",
      "Epoch 61/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6527 - accuracy: 0.6216 - val_loss: 0.6430 - val_accuracy: 0.7000\n",
      "Epoch 62/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.6216 - val_loss: 0.6423 - val_accuracy: 0.7000\n",
      "Epoch 63/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6516 - accuracy: 0.6216 - val_loss: 0.6418 - val_accuracy: 0.7000\n",
      "Epoch 64/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6512 - accuracy: 0.6216 - val_loss: 0.6413 - val_accuracy: 0.7000\n",
      "Epoch 65/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6508 - accuracy: 0.6216 - val_loss: 0.6406 - val_accuracy: 0.7000\n",
      "Epoch 66/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6502 - accuracy: 0.6216 - val_loss: 0.6402 - val_accuracy: 0.7000\n",
      "Epoch 67/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6498 - accuracy: 0.6216 - val_loss: 0.6397 - val_accuracy: 0.7000\n",
      "Epoch 68/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6494 - accuracy: 0.6216 - val_loss: 0.6394 - val_accuracy: 0.7000\n",
      "Epoch 69/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6490 - accuracy: 0.6216 - val_loss: 0.6389 - val_accuracy: 0.7000\n",
      "Epoch 70/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6486 - accuracy: 0.6216 - val_loss: 0.6383 - val_accuracy: 0.7000\n",
      "Epoch 71/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6481 - accuracy: 0.6216 - val_loss: 0.6376 - val_accuracy: 0.7000\n",
      "Epoch 72/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6477 - accuracy: 0.6216 - val_loss: 0.6371 - val_accuracy: 0.7000\n",
      "Epoch 73/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6471 - accuracy: 0.6216 - val_loss: 0.6365 - val_accuracy: 0.7000\n",
      "Epoch 74/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6467 - accuracy: 0.6216 - val_loss: 0.6361 - val_accuracy: 0.7000\n",
      "Epoch 75/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6464 - accuracy: 0.6216 - val_loss: 0.6357 - val_accuracy: 0.7000\n",
      "Epoch 76/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6459 - accuracy: 0.6216 - val_loss: 0.6353 - val_accuracy: 0.7000\n",
      "Epoch 77/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6216 - val_loss: 0.6346 - val_accuracy: 0.7000\n",
      "Epoch 78/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.6216 - val_loss: 0.6342 - val_accuracy: 0.7000\n",
      "Epoch 79/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6448 - accuracy: 0.6216 - val_loss: 0.6338 - val_accuracy: 0.7000\n",
      "Epoch 80/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6444 - accuracy: 0.6216 - val_loss: 0.6335 - val_accuracy: 0.7000\n",
      "Epoch 81/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.6216 - val_loss: 0.6330 - val_accuracy: 0.7000\n",
      "Epoch 82/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6437 - accuracy: 0.6216 - val_loss: 0.6327 - val_accuracy: 0.7000\n",
      "Epoch 83/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6433 - accuracy: 0.6216 - val_loss: 0.6321 - val_accuracy: 0.7000\n",
      "Epoch 84/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6429 - accuracy: 0.6216 - val_loss: 0.6316 - val_accuracy: 0.7000\n",
      "Epoch 85/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6425 - accuracy: 0.6216 - val_loss: 0.6311 - val_accuracy: 0.7000\n",
      "Epoch 86/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.6216 - val_loss: 0.6307 - val_accuracy: 0.7000\n",
      "Epoch 87/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6417 - accuracy: 0.6216 - val_loss: 0.6303 - val_accuracy: 0.7000\n",
      "Epoch 88/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6414 - accuracy: 0.6216 - val_loss: 0.6300 - val_accuracy: 0.7000\n",
      "Epoch 89/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6411 - accuracy: 0.6216 - val_loss: 0.6296 - val_accuracy: 0.7000\n",
      "Epoch 90/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6408 - accuracy: 0.6216 - val_loss: 0.6292 - val_accuracy: 0.7000\n",
      "Epoch 91/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6403 - accuracy: 0.6216 - val_loss: 0.6287 - val_accuracy: 0.7000\n",
      "Epoch 92/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6399 - accuracy: 0.6216 - val_loss: 0.6282 - val_accuracy: 0.7000\n",
      "Epoch 93/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6395 - accuracy: 0.6216 - val_loss: 0.6277 - val_accuracy: 0.7000\n",
      "Epoch 94/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6391 - accuracy: 0.6216 - val_loss: 0.6274 - val_accuracy: 0.7000\n",
      "Epoch 95/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6389 - accuracy: 0.6216 - val_loss: 0.6269 - val_accuracy: 0.7000\n",
      "Epoch 96/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6384 - accuracy: 0.6216 - val_loss: 0.6266 - val_accuracy: 0.7000\n",
      "Epoch 97/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6381 - accuracy: 0.6216 - val_loss: 0.6262 - val_accuracy: 0.7000\n",
      "Epoch 98/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6378 - accuracy: 0.6216 - val_loss: 0.6257 - val_accuracy: 0.7000\n",
      "Epoch 99/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6373 - accuracy: 0.6216 - val_loss: 0.6252 - val_accuracy: 0.7000\n",
      "Epoch 100/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6370 - accuracy: 0.6216 - val_loss: 0.6247 - val_accuracy: 0.7000\n",
      "Epoch 101/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6366 - accuracy: 0.6216 - val_loss: 0.6245 - val_accuracy: 0.7000\n",
      "Epoch 102/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6363 - accuracy: 0.6216 - val_loss: 0.6242 - val_accuracy: 0.7000\n",
      "Epoch 103/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6361 - accuracy: 0.6216 - val_loss: 0.6238 - val_accuracy: 0.7000\n",
      "Epoch 104/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6357 - accuracy: 0.6216 - val_loss: 0.6234 - val_accuracy: 0.7000\n",
      "Epoch 105/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6354 - accuracy: 0.6216 - val_loss: 0.6233 - val_accuracy: 0.7000\n",
      "Epoch 106/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6352 - accuracy: 0.6216 - val_loss: 0.6230 - val_accuracy: 0.7000\n",
      "Epoch 107/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6348 - accuracy: 0.6216 - val_loss: 0.6227 - val_accuracy: 0.7000\n",
      "Epoch 108/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6344 - accuracy: 0.6216 - val_loss: 0.6224 - val_accuracy: 0.7000\n",
      "Epoch 109/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6342 - accuracy: 0.6216 - val_loss: 0.6221 - val_accuracy: 0.7000\n",
      "Epoch 110/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6339 - accuracy: 0.6216 - val_loss: 0.6216 - val_accuracy: 0.7000\n",
      "Epoch 111/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6335 - accuracy: 0.6216 - val_loss: 0.6214 - val_accuracy: 0.7000\n",
      "Epoch 112/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6331 - accuracy: 0.6216 - val_loss: 0.6212 - val_accuracy: 0.7000\n",
      "Epoch 113/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6329 - accuracy: 0.6216 - val_loss: 0.6207 - val_accuracy: 0.7000\n",
      "Epoch 114/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6325 - accuracy: 0.6216 - val_loss: 0.6203 - val_accuracy: 0.7000\n",
      "Epoch 115/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6323 - accuracy: 0.6216 - val_loss: 0.6200 - val_accuracy: 0.7000\n",
      "Epoch 116/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6319 - accuracy: 0.6216 - val_loss: 0.6198 - val_accuracy: 0.7000\n",
      "Epoch 117/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6316 - accuracy: 0.6216 - val_loss: 0.6195 - val_accuracy: 0.7000\n",
      "Epoch 118/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6314 - accuracy: 0.6216 - val_loss: 0.6192 - val_accuracy: 0.7000\n",
      "Epoch 119/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6311 - accuracy: 0.6216 - val_loss: 0.6187 - val_accuracy: 0.7000\n",
      "Epoch 120/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6308 - accuracy: 0.6216 - val_loss: 0.6185 - val_accuracy: 0.7000\n",
      "Epoch 121/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6304 - accuracy: 0.6216 - val_loss: 0.6181 - val_accuracy: 0.7000\n",
      "Epoch 122/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6301 - accuracy: 0.6216 - val_loss: 0.6178 - val_accuracy: 0.7000\n",
      "Epoch 123/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6299 - accuracy: 0.6216 - val_loss: 0.6176 - val_accuracy: 0.7000\n",
      "Epoch 124/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6295 - accuracy: 0.6216 - val_loss: 0.6171 - val_accuracy: 0.7000\n",
      "Epoch 125/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6291 - accuracy: 0.6216 - val_loss: 0.6167 - val_accuracy: 0.7000\n",
      "Epoch 126/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6288 - accuracy: 0.6216 - val_loss: 0.6165 - val_accuracy: 0.7000\n",
      "Epoch 127/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6287 - accuracy: 0.6216 - val_loss: 0.6163 - val_accuracy: 0.7000\n",
      "Epoch 128/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6283 - accuracy: 0.6216 - val_loss: 0.6161 - val_accuracy: 0.7000\n",
      "Epoch 129/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6280 - accuracy: 0.6216 - val_loss: 0.6159 - val_accuracy: 0.7000\n",
      "Epoch 130/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6278 - accuracy: 0.6216 - val_loss: 0.6154 - val_accuracy: 0.7000\n",
      "Epoch 131/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6275 - accuracy: 0.6216 - val_loss: 0.6152 - val_accuracy: 0.7000\n",
      "Epoch 132/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6273 - accuracy: 0.6216 - val_loss: 0.6150 - val_accuracy: 0.7000\n",
      "Epoch 133/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6270 - accuracy: 0.6216 - val_loss: 0.6146 - val_accuracy: 0.7000\n",
      "Epoch 134/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6266 - accuracy: 0.6216 - val_loss: 0.6144 - val_accuracy: 0.7000\n",
      "Epoch 135/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6265 - accuracy: 0.6216 - val_loss: 0.6141 - val_accuracy: 0.7000\n",
      "Epoch 136/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6261 - accuracy: 0.6216 - val_loss: 0.6139 - val_accuracy: 0.7000\n",
      "Epoch 137/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6259 - accuracy: 0.6216 - val_loss: 0.6135 - val_accuracy: 0.7000\n",
      "Epoch 138/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6256 - accuracy: 0.6216 - val_loss: 0.6134 - val_accuracy: 0.7000\n",
      "Epoch 139/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6253 - accuracy: 0.6216 - val_loss: 0.6131 - val_accuracy: 0.7000\n",
      "Epoch 140/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6251 - accuracy: 0.6216 - val_loss: 0.6127 - val_accuracy: 0.7000\n",
      "Epoch 141/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6247 - accuracy: 0.6216 - val_loss: 0.6126 - val_accuracy: 0.7000\n",
      "Epoch 142/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6245 - accuracy: 0.6216 - val_loss: 0.6122 - val_accuracy: 0.7000\n",
      "Epoch 143/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6242 - accuracy: 0.6216 - val_loss: 0.6120 - val_accuracy: 0.7000\n",
      "Epoch 144/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.6216 - val_loss: 0.6118 - val_accuracy: 0.7000\n",
      "Epoch 145/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6237 - accuracy: 0.6216 - val_loss: 0.6117 - val_accuracy: 0.7000\n",
      "Epoch 146/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6235 - accuracy: 0.6216 - val_loss: 0.6116 - val_accuracy: 0.7000\n",
      "Epoch 147/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6232 - accuracy: 0.6216 - val_loss: 0.6114 - val_accuracy: 0.7000\n",
      "Epoch 148/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6230 - accuracy: 0.6216 - val_loss: 0.6110 - val_accuracy: 0.7000\n",
      "Epoch 149/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6227 - accuracy: 0.6216 - val_loss: 0.6107 - val_accuracy: 0.7000\n",
      "Epoch 150/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6224 - accuracy: 0.6216 - val_loss: 0.6104 - val_accuracy: 0.7000\n",
      "Epoch 151/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6222 - accuracy: 0.6216 - val_loss: 0.6101 - val_accuracy: 0.7000\n",
      "Epoch 152/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6220 - accuracy: 0.6216 - val_loss: 0.6099 - val_accuracy: 0.7000\n",
      "Epoch 153/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6217 - accuracy: 0.6216 - val_loss: 0.6096 - val_accuracy: 0.7000\n",
      "Epoch 154/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6213 - accuracy: 0.6216 - val_loss: 0.6094 - val_accuracy: 0.7000\n",
      "Epoch 155/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6211 - accuracy: 0.6216 - val_loss: 0.6093 - val_accuracy: 0.7000\n",
      "Epoch 156/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6209 - accuracy: 0.6216 - val_loss: 0.6090 - val_accuracy: 0.7000\n",
      "Epoch 157/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6207 - accuracy: 0.6216 - val_loss: 0.6087 - val_accuracy: 0.7000\n",
      "Epoch 158/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6204 - accuracy: 0.6216 - val_loss: 0.6084 - val_accuracy: 0.7000\n",
      "Epoch 159/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6202 - accuracy: 0.6216 - val_loss: 0.6083 - val_accuracy: 0.7000\n",
      "Epoch 160/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6200 - accuracy: 0.6216 - val_loss: 0.6082 - val_accuracy: 0.7000\n",
      "Epoch 161/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6197 - accuracy: 0.6216 - val_loss: 0.6079 - val_accuracy: 0.7000\n",
      "Epoch 162/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6195 - accuracy: 0.6216 - val_loss: 0.6078 - val_accuracy: 0.7000\n",
      "Epoch 163/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6192 - accuracy: 0.6216 - val_loss: 0.6076 - val_accuracy: 0.7000\n",
      "Epoch 164/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6190 - accuracy: 0.6216 - val_loss: 0.6074 - val_accuracy: 0.7000\n",
      "Epoch 165/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6188 - accuracy: 0.6216 - val_loss: 0.6071 - val_accuracy: 0.7000\n",
      "Epoch 166/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6185 - accuracy: 0.6216 - val_loss: 0.6068 - val_accuracy: 0.7000\n",
      "Epoch 167/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6183 - accuracy: 0.6216 - val_loss: 0.6067 - val_accuracy: 0.7000\n",
      "Epoch 168/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6180 - accuracy: 0.6216 - val_loss: 0.6064 - val_accuracy: 0.7000\n",
      "Epoch 169/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6177 - accuracy: 0.6216 - val_loss: 0.6062 - val_accuracy: 0.7000\n",
      "Epoch 170/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6175 - accuracy: 0.6216 - val_loss: 0.6061 - val_accuracy: 0.7000\n",
      "Epoch 171/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6173 - accuracy: 0.6216 - val_loss: 0.6059 - val_accuracy: 0.7000\n",
      "Epoch 172/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6170 - accuracy: 0.6216 - val_loss: 0.6057 - val_accuracy: 0.7000\n",
      "Epoch 173/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6168 - accuracy: 0.6216 - val_loss: 0.6054 - val_accuracy: 0.7000\n",
      "Epoch 174/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6165 - accuracy: 0.6216 - val_loss: 0.6053 - val_accuracy: 0.7000\n",
      "Epoch 175/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6162 - accuracy: 0.6216 - val_loss: 0.6051 - val_accuracy: 0.7000\n",
      "Epoch 176/5000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.6163 - accuracy: 0.6216 - val_loss: 0.6048 - val_accuracy: 0.7000\n",
      "Epoch 177/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6158 - accuracy: 0.6216 - val_loss: 0.6045 - val_accuracy: 0.7000\n",
      "Epoch 178/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6155 - accuracy: 0.6216 - val_loss: 0.6044 - val_accuracy: 0.7000\n",
      "Epoch 179/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6154 - accuracy: 0.6216 - val_loss: 0.6042 - val_accuracy: 0.7000\n",
      "Epoch 180/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6151 - accuracy: 0.6216 - val_loss: 0.6040 - val_accuracy: 0.7000\n",
      "Epoch 181/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6150 - accuracy: 0.6216 - val_loss: 0.6037 - val_accuracy: 0.7000\n",
      "Epoch 182/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6147 - accuracy: 0.6216 - val_loss: 0.6036 - val_accuracy: 0.7000\n",
      "Epoch 183/5000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.6144 - accuracy: 0.6216 - val_loss: 0.6034 - val_accuracy: 0.7000\n",
      "Epoch 184/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6142 - accuracy: 0.6216 - val_loss: 0.6033 - val_accuracy: 0.7000\n",
      "Epoch 185/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6140 - accuracy: 0.6216 - val_loss: 0.6030 - val_accuracy: 0.7000\n",
      "Epoch 186/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6138 - accuracy: 0.6216 - val_loss: 0.6029 - val_accuracy: 0.7000\n",
      "Epoch 187/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6135 - accuracy: 0.6216 - val_loss: 0.6027 - val_accuracy: 0.7000\n",
      "Epoch 188/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6133 - accuracy: 0.6216 - val_loss: 0.6024 - val_accuracy: 0.7000\n",
      "Epoch 189/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6131 - accuracy: 0.6216 - val_loss: 0.6022 - val_accuracy: 0.7000\n",
      "Epoch 190/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6129 - accuracy: 0.6216 - val_loss: 0.6020 - val_accuracy: 0.7000\n",
      "Epoch 191/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6127 - accuracy: 0.6216 - val_loss: 0.6017 - val_accuracy: 0.7000\n",
      "Epoch 192/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6124 - accuracy: 0.6216 - val_loss: 0.6016 - val_accuracy: 0.7000\n",
      "Epoch 193/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6122 - accuracy: 0.6216 - val_loss: 0.6014 - val_accuracy: 0.7000\n",
      "Epoch 194/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6120 - accuracy: 0.6216 - val_loss: 0.6012 - val_accuracy: 0.7000\n",
      "Epoch 195/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6117 - accuracy: 0.6216 - val_loss: 0.6011 - val_accuracy: 0.7000\n",
      "Epoch 196/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6115 - accuracy: 0.6216 - val_loss: 0.6009 - val_accuracy: 0.7000\n",
      "Epoch 197/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6113 - accuracy: 0.6216 - val_loss: 0.6008 - val_accuracy: 0.7000\n",
      "Epoch 198/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6110 - accuracy: 0.6216 - val_loss: 0.6007 - val_accuracy: 0.7000\n",
      "Epoch 199/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6109 - accuracy: 0.6216 - val_loss: 0.6005 - val_accuracy: 0.7000\n",
      "Epoch 200/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6106 - accuracy: 0.6216 - val_loss: 0.6004 - val_accuracy: 0.7000\n",
      "Epoch 201/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6104 - accuracy: 0.6216 - val_loss: 0.6003 - val_accuracy: 0.7000\n",
      "Epoch 202/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6101 - accuracy: 0.6216 - val_loss: 0.6002 - val_accuracy: 0.7000\n",
      "Epoch 203/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6100 - accuracy: 0.6216 - val_loss: 0.6001 - val_accuracy: 0.7000\n",
      "Epoch 204/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6097 - accuracy: 0.6216 - val_loss: 0.5998 - val_accuracy: 0.7000\n",
      "Epoch 205/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6095 - accuracy: 0.6216 - val_loss: 0.5996 - val_accuracy: 0.7000\n",
      "Epoch 206/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6093 - accuracy: 0.6216 - val_loss: 0.5994 - val_accuracy: 0.7000\n",
      "Epoch 207/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6091 - accuracy: 0.6216 - val_loss: 0.5993 - val_accuracy: 0.7000\n",
      "Epoch 208/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6089 - accuracy: 0.6216 - val_loss: 0.5991 - val_accuracy: 0.7000\n",
      "Epoch 209/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6086 - accuracy: 0.6216 - val_loss: 0.5989 - val_accuracy: 0.7000\n",
      "Epoch 210/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6083 - accuracy: 0.6216 - val_loss: 0.5988 - val_accuracy: 0.7000\n",
      "Epoch 211/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6081 - accuracy: 0.6216 - val_loss: 0.5987 - val_accuracy: 0.7000\n",
      "Epoch 212/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6080 - accuracy: 0.6216 - val_loss: 0.5986 - val_accuracy: 0.7000\n",
      "Epoch 213/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6077 - accuracy: 0.6216 - val_loss: 0.5985 - val_accuracy: 0.7000\n",
      "Epoch 214/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6075 - accuracy: 0.6216 - val_loss: 0.5983 - val_accuracy: 0.7000\n",
      "Epoch 215/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6074 - accuracy: 0.6216 - val_loss: 0.5983 - val_accuracy: 0.7000\n",
      "Epoch 216/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6071 - accuracy: 0.6216 - val_loss: 0.5981 - val_accuracy: 0.7000\n",
      "Epoch 217/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6068 - accuracy: 0.6216 - val_loss: 0.5978 - val_accuracy: 0.7000\n",
      "Epoch 218/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6066 - accuracy: 0.6216 - val_loss: 0.5977 - val_accuracy: 0.7000\n",
      "Epoch 219/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6064 - accuracy: 0.6216 - val_loss: 0.5977 - val_accuracy: 0.7000\n",
      "Epoch 220/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6062 - accuracy: 0.6216 - val_loss: 0.5976 - val_accuracy: 0.7000\n",
      "Epoch 221/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6061 - accuracy: 0.6216 - val_loss: 0.5974 - val_accuracy: 0.7000\n",
      "Epoch 222/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6058 - accuracy: 0.6216 - val_loss: 0.5972 - val_accuracy: 0.7000\n",
      "Epoch 223/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6056 - accuracy: 0.6216 - val_loss: 0.5970 - val_accuracy: 0.7000\n",
      "Epoch 224/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6053 - accuracy: 0.6216 - val_loss: 0.5968 - val_accuracy: 0.7000\n",
      "Epoch 225/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6051 - accuracy: 0.6216 - val_loss: 0.5966 - val_accuracy: 0.7000\n",
      "Epoch 226/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6049 - accuracy: 0.6216 - val_loss: 0.5963 - val_accuracy: 0.7000\n",
      "Epoch 227/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6047 - accuracy: 0.6216 - val_loss: 0.5963 - val_accuracy: 0.7000\n",
      "Epoch 228/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6045 - accuracy: 0.6216 - val_loss: 0.5961 - val_accuracy: 0.7000\n",
      "Epoch 229/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6042 - accuracy: 0.6216 - val_loss: 0.5960 - val_accuracy: 0.7000\n",
      "Epoch 230/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6041 - accuracy: 0.6216 - val_loss: 0.5960 - val_accuracy: 0.7000\n",
      "Epoch 231/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6039 - accuracy: 0.6216 - val_loss: 0.5958 - val_accuracy: 0.7000\n",
      "Epoch 232/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6036 - accuracy: 0.6216 - val_loss: 0.5958 - val_accuracy: 0.7000\n",
      "Epoch 233/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6034 - accuracy: 0.6216 - val_loss: 0.5957 - val_accuracy: 0.7000\n",
      "Epoch 234/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6031 - accuracy: 0.6216 - val_loss: 0.5956 - val_accuracy: 0.7000\n",
      "Epoch 235/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6030 - accuracy: 0.6216 - val_loss: 0.5955 - val_accuracy: 0.7000\n",
      "Epoch 236/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.6216 - val_loss: 0.5952 - val_accuracy: 0.7000\n",
      "Epoch 237/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6025 - accuracy: 0.6216 - val_loss: 0.5951 - val_accuracy: 0.7000\n",
      "Epoch 238/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6023 - accuracy: 0.6216 - val_loss: 0.5951 - val_accuracy: 0.7000\n",
      "Epoch 239/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6020 - accuracy: 0.6216 - val_loss: 0.5949 - val_accuracy: 0.7000\n",
      "Epoch 240/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6018 - accuracy: 0.6216 - val_loss: 0.5948 - val_accuracy: 0.7000\n",
      "Epoch 241/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6016 - accuracy: 0.6216 - val_loss: 0.5946 - val_accuracy: 0.7000\n",
      "Epoch 242/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6014 - accuracy: 0.6216 - val_loss: 0.5944 - val_accuracy: 0.7000\n",
      "Epoch 243/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.6216 - val_loss: 0.5943 - val_accuracy: 0.7000\n",
      "Epoch 244/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6010 - accuracy: 0.6216 - val_loss: 0.5942 - val_accuracy: 0.7000\n",
      "Epoch 245/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6008 - accuracy: 0.6216 - val_loss: 0.5940 - val_accuracy: 0.7000\n",
      "Epoch 246/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6006 - accuracy: 0.6216 - val_loss: 0.5938 - val_accuracy: 0.7000\n",
      "Epoch 247/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6004 - accuracy: 0.6216 - val_loss: 0.5938 - val_accuracy: 0.7000\n",
      "Epoch 248/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6002 - accuracy: 0.6216 - val_loss: 0.5937 - val_accuracy: 0.7000\n",
      "Epoch 249/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6000 - accuracy: 0.6216 - val_loss: 0.5936 - val_accuracy: 0.7000\n",
      "Epoch 250/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5998 - accuracy: 0.6216 - val_loss: 0.5935 - val_accuracy: 0.7000\n",
      "Epoch 251/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5996 - accuracy: 0.6216 - val_loss: 0.5935 - val_accuracy: 0.7000\n",
      "Epoch 252/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5995 - accuracy: 0.6216 - val_loss: 0.5933 - val_accuracy: 0.7000\n",
      "Epoch 253/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5992 - accuracy: 0.6216 - val_loss: 0.5932 - val_accuracy: 0.7000\n",
      "Epoch 254/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5990 - accuracy: 0.6216 - val_loss: 0.5931 - val_accuracy: 0.7000\n",
      "Epoch 255/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5988 - accuracy: 0.6216 - val_loss: 0.5930 - val_accuracy: 0.7000\n",
      "Epoch 256/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5986 - accuracy: 0.6216 - val_loss: 0.5928 - val_accuracy: 0.7000\n",
      "Epoch 257/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.6216 - val_loss: 0.5927 - val_accuracy: 0.7000\n",
      "Epoch 258/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5983 - accuracy: 0.6216 - val_loss: 0.5926 - val_accuracy: 0.7000\n",
      "Epoch 259/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5980 - accuracy: 0.6216 - val_loss: 0.5924 - val_accuracy: 0.7000\n",
      "Epoch 260/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5978 - accuracy: 0.6216 - val_loss: 0.5922 - val_accuracy: 0.7000\n",
      "Epoch 261/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5977 - accuracy: 0.6216 - val_loss: 0.5920 - val_accuracy: 0.7000\n",
      "Epoch 262/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5975 - accuracy: 0.6216 - val_loss: 0.5920 - val_accuracy: 0.7000\n",
      "Epoch 263/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5972 - accuracy: 0.6216 - val_loss: 0.5920 - val_accuracy: 0.7000\n",
      "Epoch 264/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5970 - accuracy: 0.6216 - val_loss: 0.5919 - val_accuracy: 0.7000\n",
      "Epoch 265/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5969 - accuracy: 0.6216 - val_loss: 0.5918 - val_accuracy: 0.7000\n",
      "Epoch 266/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5966 - accuracy: 0.6216 - val_loss: 0.5916 - val_accuracy: 0.7000\n",
      "Epoch 267/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5964 - accuracy: 0.6216 - val_loss: 0.5914 - val_accuracy: 0.7000\n",
      "Epoch 268/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5963 - accuracy: 0.6216 - val_loss: 0.5914 - val_accuracy: 0.7000\n",
      "Epoch 269/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5961 - accuracy: 0.6216 - val_loss: 0.5912 - val_accuracy: 0.7000\n",
      "Epoch 270/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5958 - accuracy: 0.6216 - val_loss: 0.5911 - val_accuracy: 0.7000\n",
      "Epoch 271/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5956 - accuracy: 0.6216 - val_loss: 0.5910 - val_accuracy: 0.7000\n",
      "Epoch 272/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5955 - accuracy: 0.6216 - val_loss: 0.5909 - val_accuracy: 0.7000\n",
      "Epoch 273/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5954 - accuracy: 0.6216 - val_loss: 0.5909 - val_accuracy: 0.7000\n",
      "Epoch 274/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5951 - accuracy: 0.6216 - val_loss: 0.5907 - val_accuracy: 0.7000\n",
      "Epoch 275/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5949 - accuracy: 0.6216 - val_loss: 0.5905 - val_accuracy: 0.7000\n",
      "Epoch 276/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5947 - accuracy: 0.6216 - val_loss: 0.5904 - val_accuracy: 0.7000\n",
      "Epoch 277/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5945 - accuracy: 0.6216 - val_loss: 0.5903 - val_accuracy: 0.7000\n",
      "Epoch 278/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5944 - accuracy: 0.6216 - val_loss: 0.5902 - val_accuracy: 0.7000\n",
      "Epoch 279/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5942 - accuracy: 0.6216 - val_loss: 0.5900 - val_accuracy: 0.7000\n",
      "Epoch 280/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5939 - accuracy: 0.6216 - val_loss: 0.5900 - val_accuracy: 0.7000\n",
      "Epoch 281/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.6216 - val_loss: 0.5898 - val_accuracy: 0.7000\n",
      "Epoch 282/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5936 - accuracy: 0.6216 - val_loss: 0.5896 - val_accuracy: 0.7000\n",
      "Epoch 283/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5933 - accuracy: 0.6216 - val_loss: 0.5895 - val_accuracy: 0.7000\n",
      "Epoch 284/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5931 - accuracy: 0.6216 - val_loss: 0.5895 - val_accuracy: 0.7000\n",
      "Epoch 285/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5931 - accuracy: 0.6216 - val_loss: 0.5895 - val_accuracy: 0.7000\n",
      "Epoch 286/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5928 - accuracy: 0.6216 - val_loss: 0.5894 - val_accuracy: 0.7000\n",
      "Epoch 287/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5926 - accuracy: 0.6216 - val_loss: 0.5893 - val_accuracy: 0.7000\n",
      "Epoch 288/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5923 - accuracy: 0.6216 - val_loss: 0.5891 - val_accuracy: 0.7000\n",
      "Epoch 289/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5921 - accuracy: 0.6216 - val_loss: 0.5890 - val_accuracy: 0.7000\n",
      "Epoch 290/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5920 - accuracy: 0.6216 - val_loss: 0.5889 - val_accuracy: 0.7000\n",
      "Epoch 291/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5918 - accuracy: 0.6216 - val_loss: 0.5889 - val_accuracy: 0.7000\n",
      "Epoch 292/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5916 - accuracy: 0.6216 - val_loss: 0.5888 - val_accuracy: 0.7000\n",
      "Epoch 293/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5913 - accuracy: 0.6216 - val_loss: 0.5886 - val_accuracy: 0.7000\n",
      "Epoch 294/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5912 - accuracy: 0.6216 - val_loss: 0.5885 - val_accuracy: 0.7000\n",
      "Epoch 295/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5910 - accuracy: 0.6216 - val_loss: 0.5885 - val_accuracy: 0.7000\n",
      "Epoch 296/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5908 - accuracy: 0.6216 - val_loss: 0.5885 - val_accuracy: 0.7000\n",
      "Epoch 297/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5906 - accuracy: 0.6216 - val_loss: 0.5883 - val_accuracy: 0.7000\n",
      "Epoch 298/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5904 - accuracy: 0.6216 - val_loss: 0.5882 - val_accuracy: 0.7000\n",
      "Epoch 299/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5902 - accuracy: 0.6216 - val_loss: 0.5882 - val_accuracy: 0.7000\n",
      "Epoch 300/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5900 - accuracy: 0.6216 - val_loss: 0.5880 - val_accuracy: 0.7000\n",
      "Epoch 301/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5898 - accuracy: 0.6216 - val_loss: 0.5880 - val_accuracy: 0.7000\n",
      "Epoch 302/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5897 - accuracy: 0.6216 - val_loss: 0.5879 - val_accuracy: 0.7000\n",
      "Epoch 303/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5894 - accuracy: 0.6216 - val_loss: 0.5878 - val_accuracy: 0.7000\n",
      "Epoch 304/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5893 - accuracy: 0.6216 - val_loss: 0.5878 - val_accuracy: 0.7000\n",
      "Epoch 305/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5891 - accuracy: 0.6216 - val_loss: 0.5878 - val_accuracy: 0.7000\n",
      "Epoch 306/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5888 - accuracy: 0.6216 - val_loss: 0.5877 - val_accuracy: 0.7000\n",
      "Epoch 307/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5887 - accuracy: 0.6216 - val_loss: 0.5876 - val_accuracy: 0.7000\n",
      "Epoch 308/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5884 - accuracy: 0.6216 - val_loss: 0.5876 - val_accuracy: 0.7000\n",
      "Epoch 309/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5882 - accuracy: 0.6216 - val_loss: 0.5875 - val_accuracy: 0.7000\n",
      "Epoch 310/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5880 - accuracy: 0.6216 - val_loss: 0.5874 - val_accuracy: 0.7000\n",
      "Epoch 311/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5879 - accuracy: 0.6216 - val_loss: 0.5873 - val_accuracy: 0.7000\n",
      "Epoch 312/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5876 - accuracy: 0.6216 - val_loss: 0.5872 - val_accuracy: 0.7000\n",
      "Epoch 313/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5875 - accuracy: 0.6216 - val_loss: 0.5870 - val_accuracy: 0.7000\n",
      "Epoch 314/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5872 - accuracy: 0.6216 - val_loss: 0.5869 - val_accuracy: 0.7000\n",
      "Epoch 315/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5871 - accuracy: 0.6216 - val_loss: 0.5868 - val_accuracy: 0.7000\n",
      "Epoch 316/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5869 - accuracy: 0.6216 - val_loss: 0.5866 - val_accuracy: 0.7000\n",
      "Epoch 317/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5867 - accuracy: 0.6216 - val_loss: 0.5864 - val_accuracy: 0.7000\n",
      "Epoch 318/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5866 - accuracy: 0.6216 - val_loss: 0.5864 - val_accuracy: 0.7000\n",
      "Epoch 319/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5864 - accuracy: 0.6216 - val_loss: 0.5862 - val_accuracy: 0.7000\n",
      "Epoch 320/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5862 - accuracy: 0.6216 - val_loss: 0.5862 - val_accuracy: 0.7000\n",
      "Epoch 321/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5860 - accuracy: 0.6216 - val_loss: 0.5861 - val_accuracy: 0.7000\n",
      "Epoch 322/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5858 - accuracy: 0.6216 - val_loss: 0.5859 - val_accuracy: 0.7000\n",
      "Epoch 323/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5856 - accuracy: 0.6216 - val_loss: 0.5859 - val_accuracy: 0.7000\n",
      "Epoch 324/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5855 - accuracy: 0.6216 - val_loss: 0.5858 - val_accuracy: 0.7000\n",
      "Epoch 325/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5853 - accuracy: 0.6216 - val_loss: 0.5857 - val_accuracy: 0.7000\n",
      "Epoch 326/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5851 - accuracy: 0.6216 - val_loss: 0.5856 - val_accuracy: 0.7000\n",
      "Epoch 327/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5850 - accuracy: 0.6216 - val_loss: 0.5854 - val_accuracy: 0.7000\n",
      "Epoch 328/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5847 - accuracy: 0.6216 - val_loss: 0.5854 - val_accuracy: 0.7000\n",
      "Epoch 329/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5845 - accuracy: 0.6216 - val_loss: 0.5854 - val_accuracy: 0.7000\n",
      "Epoch 330/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5843 - accuracy: 0.6216 - val_loss: 0.5852 - val_accuracy: 0.7000\n",
      "Epoch 331/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5842 - accuracy: 0.6216 - val_loss: 0.5851 - val_accuracy: 0.7000\n",
      "Epoch 332/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5839 - accuracy: 0.6216 - val_loss: 0.5850 - val_accuracy: 0.7000\n",
      "Epoch 333/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5838 - accuracy: 0.6216 - val_loss: 0.5849 - val_accuracy: 0.7000\n",
      "Epoch 334/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5836 - accuracy: 0.6216 - val_loss: 0.5849 - val_accuracy: 0.7000\n",
      "Epoch 335/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5833 - accuracy: 0.6216 - val_loss: 0.5848 - val_accuracy: 0.7000\n",
      "Epoch 336/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5833 - accuracy: 0.6216 - val_loss: 0.5847 - val_accuracy: 0.7000\n",
      "Epoch 337/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5830 - accuracy: 0.6216 - val_loss: 0.5845 - val_accuracy: 0.7000\n",
      "Epoch 338/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5829 - accuracy: 0.6216 - val_loss: 0.5844 - val_accuracy: 0.7000\n",
      "Epoch 339/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5827 - accuracy: 0.6216 - val_loss: 0.5843 - val_accuracy: 0.7000\n",
      "Epoch 340/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5825 - accuracy: 0.6216 - val_loss: 0.5841 - val_accuracy: 0.7000\n",
      "Epoch 341/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5823 - accuracy: 0.6216 - val_loss: 0.5841 - val_accuracy: 0.7000\n",
      "Epoch 342/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5822 - accuracy: 0.6216 - val_loss: 0.5840 - val_accuracy: 0.7000\n",
      "Epoch 343/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5819 - accuracy: 0.6216 - val_loss: 0.5839 - val_accuracy: 0.7000\n",
      "Epoch 344/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5817 - accuracy: 0.6216 - val_loss: 0.5839 - val_accuracy: 0.7000\n",
      "Epoch 345/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5816 - accuracy: 0.6216 - val_loss: 0.5838 - val_accuracy: 0.7000\n",
      "Epoch 346/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5813 - accuracy: 0.6216 - val_loss: 0.5836 - val_accuracy: 0.7000\n",
      "Epoch 347/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5812 - accuracy: 0.6216 - val_loss: 0.5835 - val_accuracy: 0.7000\n",
      "Epoch 348/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5810 - accuracy: 0.6216 - val_loss: 0.5833 - val_accuracy: 0.7000\n",
      "Epoch 349/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.6216 - val_loss: 0.5832 - val_accuracy: 0.7000\n",
      "Epoch 350/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5806 - accuracy: 0.6216 - val_loss: 0.5831 - val_accuracy: 0.7000\n",
      "Epoch 351/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5805 - accuracy: 0.6216 - val_loss: 0.5831 - val_accuracy: 0.7000\n",
      "Epoch 352/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5803 - accuracy: 0.6216 - val_loss: 0.5831 - val_accuracy: 0.7000\n",
      "Epoch 353/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5802 - accuracy: 0.6216 - val_loss: 0.5830 - val_accuracy: 0.7000\n",
      "Epoch 354/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5799 - accuracy: 0.6216 - val_loss: 0.5828 - val_accuracy: 0.7000\n",
      "Epoch 355/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5797 - accuracy: 0.6216 - val_loss: 0.5828 - val_accuracy: 0.7000\n",
      "Epoch 356/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5795 - accuracy: 0.6216 - val_loss: 0.5827 - val_accuracy: 0.7000\n",
      "Epoch 357/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5793 - accuracy: 0.6216 - val_loss: 0.5826 - val_accuracy: 0.7000\n",
      "Epoch 358/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5792 - accuracy: 0.6216 - val_loss: 0.5825 - val_accuracy: 0.7000\n",
      "Epoch 359/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5790 - accuracy: 0.6216 - val_loss: 0.5823 - val_accuracy: 0.7000\n",
      "Epoch 360/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5788 - accuracy: 0.6216 - val_loss: 0.5823 - val_accuracy: 0.7000\n",
      "Epoch 361/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5787 - accuracy: 0.6216 - val_loss: 0.5821 - val_accuracy: 0.7000\n",
      "Epoch 362/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5785 - accuracy: 0.6216 - val_loss: 0.5819 - val_accuracy: 0.7000\n",
      "Epoch 363/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5784 - accuracy: 0.6216 - val_loss: 0.5819 - val_accuracy: 0.7000\n",
      "Epoch 364/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5782 - accuracy: 0.6216 - val_loss: 0.5818 - val_accuracy: 0.7000\n",
      "Epoch 365/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5780 - accuracy: 0.6216 - val_loss: 0.5818 - val_accuracy: 0.7000\n",
      "Epoch 366/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5778 - accuracy: 0.6216 - val_loss: 0.5816 - val_accuracy: 0.7000\n",
      "Epoch 367/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5776 - accuracy: 0.6216 - val_loss: 0.5816 - val_accuracy: 0.7000\n",
      "Epoch 368/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5774 - accuracy: 0.6216 - val_loss: 0.5815 - val_accuracy: 0.7000\n",
      "Epoch 369/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5773 - accuracy: 0.6216 - val_loss: 0.5815 - val_accuracy: 0.7000\n",
      "Epoch 370/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5770 - accuracy: 0.6216 - val_loss: 0.5814 - val_accuracy: 0.7000\n",
      "Epoch 371/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5769 - accuracy: 0.6216 - val_loss: 0.5813 - val_accuracy: 0.7000\n",
      "Epoch 372/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5767 - accuracy: 0.6216 - val_loss: 0.5811 - val_accuracy: 0.7000\n",
      "Epoch 373/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5765 - accuracy: 0.6216 - val_loss: 0.5811 - val_accuracy: 0.7000\n",
      "Epoch 374/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5764 - accuracy: 0.6216 - val_loss: 0.5811 - val_accuracy: 0.7000\n",
      "Epoch 375/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5761 - accuracy: 0.6216 - val_loss: 0.5810 - val_accuracy: 0.7000\n",
      "Epoch 376/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5759 - accuracy: 0.6216 - val_loss: 0.5810 - val_accuracy: 0.7000\n",
      "Epoch 377/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5758 - accuracy: 0.6216 - val_loss: 0.5810 - val_accuracy: 0.7000\n",
      "Epoch 378/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5756 - accuracy: 0.6216 - val_loss: 0.5810 - val_accuracy: 0.7000\n",
      "Epoch 379/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5753 - accuracy: 0.6216 - val_loss: 0.5808 - val_accuracy: 0.7000\n",
      "Epoch 380/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5752 - accuracy: 0.6216 - val_loss: 0.5808 - val_accuracy: 0.7000\n",
      "Epoch 381/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5751 - accuracy: 0.6216 - val_loss: 0.5807 - val_accuracy: 0.7000\n",
      "Epoch 382/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5749 - accuracy: 0.6216 - val_loss: 0.5806 - val_accuracy: 0.7000\n",
      "Epoch 383/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5746 - accuracy: 0.6216 - val_loss: 0.5806 - val_accuracy: 0.7000\n",
      "Epoch 384/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5745 - accuracy: 0.6216 - val_loss: 0.5805 - val_accuracy: 0.6000\n",
      "Epoch 385/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5743 - accuracy: 0.6216 - val_loss: 0.5804 - val_accuracy: 0.6000\n",
      "Epoch 386/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5741 - accuracy: 0.6216 - val_loss: 0.5803 - val_accuracy: 0.6000\n",
      "Epoch 387/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5739 - accuracy: 0.6216 - val_loss: 0.5802 - val_accuracy: 0.6000\n",
      "Epoch 388/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5737 - accuracy: 0.6216 - val_loss: 0.5801 - val_accuracy: 0.6000\n",
      "Epoch 389/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5735 - accuracy: 0.6216 - val_loss: 0.5801 - val_accuracy: 0.6000\n",
      "Epoch 390/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5735 - accuracy: 0.6216 - val_loss: 0.5801 - val_accuracy: 0.6000\n",
      "Epoch 391/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5732 - accuracy: 0.6216 - val_loss: 0.5801 - val_accuracy: 0.6000\n",
      "Epoch 392/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5731 - accuracy: 0.6216 - val_loss: 0.5800 - val_accuracy: 0.6000\n",
      "Epoch 393/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5729 - accuracy: 0.6216 - val_loss: 0.5799 - val_accuracy: 0.6000\n",
      "Epoch 394/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5727 - accuracy: 0.6216 - val_loss: 0.5798 - val_accuracy: 0.6000\n",
      "Epoch 395/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.6216 - val_loss: 0.5799 - val_accuracy: 0.6000\n",
      "Epoch 396/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5723 - accuracy: 0.6216 - val_loss: 0.5799 - val_accuracy: 0.6000\n",
      "Epoch 397/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5722 - accuracy: 0.6216 - val_loss: 0.5797 - val_accuracy: 0.6000\n",
      "Epoch 398/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5720 - accuracy: 0.6216 - val_loss: 0.5796 - val_accuracy: 0.6000\n",
      "Epoch 399/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5719 - accuracy: 0.6216 - val_loss: 0.5795 - val_accuracy: 0.6000\n",
      "Epoch 400/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5717 - accuracy: 0.6216 - val_loss: 0.5795 - val_accuracy: 0.6000\n",
      "Epoch 401/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5715 - accuracy: 0.6216 - val_loss: 0.5794 - val_accuracy: 0.6000\n",
      "Epoch 402/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5714 - accuracy: 0.6216 - val_loss: 0.5793 - val_accuracy: 0.6000\n",
      "Epoch 403/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5712 - accuracy: 0.6216 - val_loss: 0.5791 - val_accuracy: 0.6000\n",
      "Epoch 404/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5710 - accuracy: 0.6216 - val_loss: 0.5791 - val_accuracy: 0.6000\n",
      "Epoch 405/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5709 - accuracy: 0.6216 - val_loss: 0.5789 - val_accuracy: 0.6000\n",
      "Epoch 406/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5707 - accuracy: 0.6216 - val_loss: 0.5788 - val_accuracy: 0.6000\n",
      "Epoch 407/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5706 - accuracy: 0.6216 - val_loss: 0.5787 - val_accuracy: 0.6000\n",
      "Epoch 408/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5704 - accuracy: 0.6216 - val_loss: 0.5785 - val_accuracy: 0.6000\n",
      "Epoch 409/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5703 - accuracy: 0.6216 - val_loss: 0.5785 - val_accuracy: 0.6000\n",
      "Epoch 410/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5701 - accuracy: 0.6216 - val_loss: 0.5785 - val_accuracy: 0.6000\n",
      "Epoch 411/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5699 - accuracy: 0.6216 - val_loss: 0.5784 - val_accuracy: 0.6000\n",
      "Epoch 412/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5698 - accuracy: 0.6216 - val_loss: 0.5784 - val_accuracy: 0.6000\n",
      "Epoch 413/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5696 - accuracy: 0.6216 - val_loss: 0.5784 - val_accuracy: 0.6000\n",
      "Epoch 414/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5694 - accuracy: 0.6216 - val_loss: 0.5782 - val_accuracy: 0.6000\n",
      "Epoch 415/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5692 - accuracy: 0.6216 - val_loss: 0.5782 - val_accuracy: 0.6000\n",
      "Epoch 416/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5692 - accuracy: 0.6216 - val_loss: 0.5781 - val_accuracy: 0.6000\n",
      "Epoch 417/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5689 - accuracy: 0.6216 - val_loss: 0.5780 - val_accuracy: 0.6000\n",
      "Epoch 418/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5687 - accuracy: 0.6216 - val_loss: 0.5779 - val_accuracy: 0.6000\n",
      "Epoch 419/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5685 - accuracy: 0.6216 - val_loss: 0.5778 - val_accuracy: 0.6000\n",
      "Epoch 420/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5684 - accuracy: 0.6216 - val_loss: 0.5778 - val_accuracy: 0.6000\n",
      "Epoch 421/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5682 - accuracy: 0.6216 - val_loss: 0.5778 - val_accuracy: 0.6000\n",
      "Epoch 422/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5679 - accuracy: 0.6216 - val_loss: 0.5776 - val_accuracy: 0.6000\n",
      "Epoch 423/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5678 - accuracy: 0.6216 - val_loss: 0.5774 - val_accuracy: 0.6000\n",
      "Epoch 424/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5677 - accuracy: 0.6216 - val_loss: 0.5774 - val_accuracy: 0.6000\n",
      "Epoch 425/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5676 - accuracy: 0.6216 - val_loss: 0.5774 - val_accuracy: 0.6000\n",
      "Epoch 426/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5673 - accuracy: 0.6216 - val_loss: 0.5774 - val_accuracy: 0.6000\n",
      "Epoch 427/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5671 - accuracy: 0.6216 - val_loss: 0.5773 - val_accuracy: 0.6000\n",
      "Epoch 428/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5670 - accuracy: 0.6216 - val_loss: 0.5771 - val_accuracy: 0.6000\n",
      "Epoch 429/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5669 - accuracy: 0.6216 - val_loss: 0.5770 - val_accuracy: 0.6000\n",
      "Epoch 430/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5667 - accuracy: 0.6216 - val_loss: 0.5769 - val_accuracy: 0.6000\n",
      "Epoch 431/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5665 - accuracy: 0.6216 - val_loss: 0.5768 - val_accuracy: 0.6000\n",
      "Epoch 432/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5664 - accuracy: 0.6216 - val_loss: 0.5767 - val_accuracy: 0.6000\n",
      "Epoch 433/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5663 - accuracy: 0.6216 - val_loss: 0.5768 - val_accuracy: 0.6000\n",
      "Epoch 434/5000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5661 - accuracy: 0.6216 - val_loss: 0.5767 - val_accuracy: 0.6000\n",
      "Epoch 435/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5659 - accuracy: 0.6216 - val_loss: 0.5767 - val_accuracy: 0.6000\n",
      "Epoch 436/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5657 - accuracy: 0.6216 - val_loss: 0.5766 - val_accuracy: 0.6000\n",
      "Epoch 437/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5656 - accuracy: 0.6216 - val_loss: 0.5766 - val_accuracy: 0.6000\n",
      "Epoch 438/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5654 - accuracy: 0.6216 - val_loss: 0.5764 - val_accuracy: 0.6000\n",
      "Epoch 439/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5653 - accuracy: 0.6216 - val_loss: 0.5763 - val_accuracy: 0.6000\n",
      "Epoch 440/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5651 - accuracy: 0.6216 - val_loss: 0.5761 - val_accuracy: 0.6000\n",
      "Epoch 441/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5651 - accuracy: 0.6216 - val_loss: 0.5761 - val_accuracy: 0.6000\n",
      "Epoch 442/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5648 - accuracy: 0.6216 - val_loss: 0.5761 - val_accuracy: 0.6000\n",
      "Epoch 443/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5647 - accuracy: 0.6216 - val_loss: 0.5760 - val_accuracy: 0.6000\n",
      "Epoch 444/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5646 - accuracy: 0.6216 - val_loss: 0.5759 - val_accuracy: 0.6000\n",
      "Epoch 445/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5644 - accuracy: 0.6216 - val_loss: 0.5758 - val_accuracy: 0.6000\n",
      "Epoch 446/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5643 - accuracy: 0.6216 - val_loss: 0.5757 - val_accuracy: 0.6000\n",
      "Epoch 447/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5640 - accuracy: 0.6216 - val_loss: 0.5757 - val_accuracy: 0.6000\n",
      "Epoch 448/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5639 - accuracy: 0.6216 - val_loss: 0.5757 - val_accuracy: 0.6000\n",
      "Epoch 449/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5637 - accuracy: 0.6216 - val_loss: 0.5756 - val_accuracy: 0.6000\n",
      "Epoch 450/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5635 - accuracy: 0.6216 - val_loss: 0.5756 - val_accuracy: 0.6000\n",
      "Epoch 451/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5634 - accuracy: 0.6216 - val_loss: 0.5755 - val_accuracy: 0.6000\n",
      "Epoch 452/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5631 - accuracy: 0.6216 - val_loss: 0.5756 - val_accuracy: 0.6000\n",
      "Epoch 453/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5630 - accuracy: 0.6216 - val_loss: 0.5755 - val_accuracy: 0.6000\n",
      "Epoch 454/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5628 - accuracy: 0.6216 - val_loss: 0.5756 - val_accuracy: 0.6000\n",
      "Epoch 455/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5626 - accuracy: 0.6216 - val_loss: 0.5755 - val_accuracy: 0.6000\n",
      "Epoch 456/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5625 - accuracy: 0.6216 - val_loss: 0.5754 - val_accuracy: 0.6000\n",
      "Epoch 457/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5623 - accuracy: 0.6216 - val_loss: 0.5753 - val_accuracy: 0.6000\n",
      "Epoch 458/5000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5621 - accuracy: 0.6216 - val_loss: 0.5753 - val_accuracy: 0.6000\n",
      "Epoch 459/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.6216 - val_loss: 0.5752 - val_accuracy: 0.6000\n",
      "Epoch 460/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5619 - accuracy: 0.6216 - val_loss: 0.5751 - val_accuracy: 0.6000\n",
      "Epoch 461/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5617 - accuracy: 0.6216 - val_loss: 0.5751 - val_accuracy: 0.6000\n",
      "Epoch 462/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5616 - accuracy: 0.6216 - val_loss: 0.5751 - val_accuracy: 0.6000\n",
      "Epoch 463/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5614 - accuracy: 0.6216 - val_loss: 0.5751 - val_accuracy: 0.6000\n",
      "Epoch 464/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5612 - accuracy: 0.6216 - val_loss: 0.5749 - val_accuracy: 0.6000\n",
      "Epoch 465/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5611 - accuracy: 0.6216 - val_loss: 0.5749 - val_accuracy: 0.6000\n",
      "Epoch 466/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5609 - accuracy: 0.6216 - val_loss: 0.5748 - val_accuracy: 0.6000\n",
      "Epoch 467/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5608 - accuracy: 0.6486 - val_loss: 0.5746 - val_accuracy: 0.6000\n",
      "Epoch 468/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5606 - accuracy: 0.6486 - val_loss: 0.5745 - val_accuracy: 0.6000\n",
      "Epoch 469/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5604 - accuracy: 0.6486 - val_loss: 0.5745 - val_accuracy: 0.6000\n",
      "Epoch 470/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.6486 - val_loss: 0.5744 - val_accuracy: 0.6000\n",
      "Epoch 471/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5601 - accuracy: 0.6486 - val_loss: 0.5743 - val_accuracy: 0.6000\n",
      "Epoch 472/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5600 - accuracy: 0.6486 - val_loss: 0.5743 - val_accuracy: 0.6000\n",
      "Epoch 473/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5598 - accuracy: 0.6486 - val_loss: 0.5743 - val_accuracy: 0.6000\n",
      "Epoch 474/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5596 - accuracy: 0.6486 - val_loss: 0.5743 - val_accuracy: 0.6000\n",
      "Epoch 475/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5595 - accuracy: 0.6486 - val_loss: 0.5742 - val_accuracy: 0.6000\n",
      "Epoch 476/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5593 - accuracy: 0.6486 - val_loss: 0.5742 - val_accuracy: 0.6000\n",
      "Epoch 477/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.6486 - val_loss: 0.5742 - val_accuracy: 0.6000\n",
      "Epoch 478/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5589 - accuracy: 0.6486 - val_loss: 0.5741 - val_accuracy: 0.6000\n",
      "Epoch 479/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5588 - accuracy: 0.6486 - val_loss: 0.5742 - val_accuracy: 0.6000\n",
      "Epoch 480/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5587 - accuracy: 0.6486 - val_loss: 0.5741 - val_accuracy: 0.6000\n",
      "Epoch 481/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5585 - accuracy: 0.6486 - val_loss: 0.5740 - val_accuracy: 0.6000\n",
      "Epoch 482/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5584 - accuracy: 0.6486 - val_loss: 0.5739 - val_accuracy: 0.6000\n",
      "Epoch 483/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5582 - accuracy: 0.6486 - val_loss: 0.5739 - val_accuracy: 0.6000\n",
      "Epoch 484/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5581 - accuracy: 0.6486 - val_loss: 0.5737 - val_accuracy: 0.6000\n",
      "Epoch 485/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5579 - accuracy: 0.6486 - val_loss: 0.5737 - val_accuracy: 0.6000\n",
      "Epoch 486/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5578 - accuracy: 0.6486 - val_loss: 0.5736 - val_accuracy: 0.6000\n",
      "Epoch 487/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5576 - accuracy: 0.6486 - val_loss: 0.5736 - val_accuracy: 0.6000\n",
      "Epoch 488/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5575 - accuracy: 0.6486 - val_loss: 0.5736 - val_accuracy: 0.6000\n",
      "Epoch 489/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5573 - accuracy: 0.6486 - val_loss: 0.5736 - val_accuracy: 0.6000\n",
      "Epoch 490/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5571 - accuracy: 0.6486 - val_loss: 0.5734 - val_accuracy: 0.6000\n",
      "Epoch 491/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5570 - accuracy: 0.6486 - val_loss: 0.5734 - val_accuracy: 0.6000\n",
      "Epoch 492/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5568 - accuracy: 0.6486 - val_loss: 0.5733 - val_accuracy: 0.6000\n",
      "Epoch 493/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5567 - accuracy: 0.6486 - val_loss: 0.5732 - val_accuracy: 0.6000\n",
      "Epoch 494/5000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5565 - accuracy: 0.6486 - val_loss: 0.5731 - val_accuracy: 0.6000\n",
      "Epoch 495/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5564 - accuracy: 0.6486 - val_loss: 0.5731 - val_accuracy: 0.6000\n",
      "Epoch 496/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5563 - accuracy: 0.6486 - val_loss: 0.5731 - val_accuracy: 0.6000\n",
      "Epoch 497/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5561 - accuracy: 0.6486 - val_loss: 0.5730 - val_accuracy: 0.6000\n",
      "Epoch 498/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5559 - accuracy: 0.6486 - val_loss: 0.5730 - val_accuracy: 0.6000\n",
      "Epoch 499/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5557 - accuracy: 0.6486 - val_loss: 0.5730 - val_accuracy: 0.6000\n",
      "Epoch 500/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5556 - accuracy: 0.6486 - val_loss: 0.5729 - val_accuracy: 0.6000\n",
      "Epoch 501/5000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5554 - accuracy: 0.6486 - val_loss: 0.5728 - val_accuracy: 0.6000\n",
      "Epoch 502/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5553 - accuracy: 0.6486 - val_loss: 0.5728 - val_accuracy: 0.6000\n",
      "Epoch 503/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5552 - accuracy: 0.6486 - val_loss: 0.5728 - val_accuracy: 0.6000\n",
      "Epoch 504/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5550 - accuracy: 0.6486 - val_loss: 0.5726 - val_accuracy: 0.6000\n",
      "Epoch 505/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5548 - accuracy: 0.6486 - val_loss: 0.5725 - val_accuracy: 0.6000\n",
      "Epoch 506/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5547 - accuracy: 0.6486 - val_loss: 0.5725 - val_accuracy: 0.6000\n",
      "Epoch 507/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5545 - accuracy: 0.6486 - val_loss: 0.5725 - val_accuracy: 0.6000\n",
      "Epoch 508/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5544 - accuracy: 0.6486 - val_loss: 0.5724 - val_accuracy: 0.6000\n",
      "Epoch 509/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5543 - accuracy: 0.6486 - val_loss: 0.5722 - val_accuracy: 0.6000\n",
      "Epoch 510/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5542 - accuracy: 0.6486 - val_loss: 0.5722 - val_accuracy: 0.6000\n",
      "Epoch 511/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5539 - accuracy: 0.6486 - val_loss: 0.5722 - val_accuracy: 0.6000\n",
      "Epoch 512/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5539 - accuracy: 0.6486 - val_loss: 0.5721 - val_accuracy: 0.6000\n",
      "Epoch 513/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5537 - accuracy: 0.6486 - val_loss: 0.5720 - val_accuracy: 0.6000\n",
      "Epoch 514/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5536 - accuracy: 0.6486 - val_loss: 0.5720 - val_accuracy: 0.6000\n",
      "Epoch 515/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5534 - accuracy: 0.6486 - val_loss: 0.5718 - val_accuracy: 0.6000\n",
      "Epoch 516/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5532 - accuracy: 0.6486 - val_loss: 0.5717 - val_accuracy: 0.6000\n",
      "Epoch 517/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5531 - accuracy: 0.6486 - val_loss: 0.5718 - val_accuracy: 0.6000\n",
      "Epoch 518/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5530 - accuracy: 0.6486 - val_loss: 0.5718 - val_accuracy: 0.6000\n",
      "Epoch 519/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5528 - accuracy: 0.6486 - val_loss: 0.5718 - val_accuracy: 0.6000\n",
      "Epoch 520/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5526 - accuracy: 0.6486 - val_loss: 0.5717 - val_accuracy: 0.6000\n",
      "Epoch 521/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5526 - accuracy: 0.6486 - val_loss: 0.5717 - val_accuracy: 0.6000\n",
      "Epoch 522/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5524 - accuracy: 0.6486 - val_loss: 0.5716 - val_accuracy: 0.6000\n",
      "Epoch 523/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5523 - accuracy: 0.6486 - val_loss: 0.5716 - val_accuracy: 0.6000\n",
      "Epoch 524/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5521 - accuracy: 0.6486 - val_loss: 0.5715 - val_accuracy: 0.6000\n",
      "Epoch 525/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5520 - accuracy: 0.6486 - val_loss: 0.5714 - val_accuracy: 0.6000\n",
      "Epoch 526/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5519 - accuracy: 0.6486 - val_loss: 0.5713 - val_accuracy: 0.6000\n",
      "Epoch 527/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5518 - accuracy: 0.6486 - val_loss: 0.5712 - val_accuracy: 0.6000\n",
      "Epoch 528/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5516 - accuracy: 0.6486 - val_loss: 0.5712 - val_accuracy: 0.6000\n",
      "Epoch 529/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5515 - accuracy: 0.6486 - val_loss: 0.5712 - val_accuracy: 0.6000\n",
      "Epoch 530/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5513 - accuracy: 0.6486 - val_loss: 0.5711 - val_accuracy: 0.6000\n",
      "Epoch 531/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5512 - accuracy: 0.6486 - val_loss: 0.5711 - val_accuracy: 0.6000\n",
      "Epoch 532/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5510 - accuracy: 0.6486 - val_loss: 0.5711 - val_accuracy: 0.6000\n",
      "Epoch 533/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5508 - accuracy: 0.6486 - val_loss: 0.5710 - val_accuracy: 0.6000\n",
      "Epoch 534/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5507 - accuracy: 0.6486 - val_loss: 0.5709 - val_accuracy: 0.6000\n",
      "Epoch 535/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5506 - accuracy: 0.6486 - val_loss: 0.5709 - val_accuracy: 0.6000\n",
      "Epoch 536/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5504 - accuracy: 0.6486 - val_loss: 0.5709 - val_accuracy: 0.6000\n",
      "Epoch 537/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5503 - accuracy: 0.6486 - val_loss: 0.5709 - val_accuracy: 0.6000\n",
      "Epoch 538/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5501 - accuracy: 0.6486 - val_loss: 0.5708 - val_accuracy: 0.6000\n",
      "Epoch 539/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5500 - accuracy: 0.6486 - val_loss: 0.5707 - val_accuracy: 0.6000\n",
      "Epoch 540/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5498 - accuracy: 0.6486 - val_loss: 0.5707 - val_accuracy: 0.6000\n",
      "Epoch 541/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5497 - accuracy: 0.6486 - val_loss: 0.5706 - val_accuracy: 0.6000\n",
      "Epoch 542/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5495 - accuracy: 0.6486 - val_loss: 0.5706 - val_accuracy: 0.6000\n",
      "Epoch 543/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5494 - accuracy: 0.6486 - val_loss: 0.5706 - val_accuracy: 0.6000\n",
      "Epoch 544/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5493 - accuracy: 0.6486 - val_loss: 0.5705 - val_accuracy: 0.6000\n",
      "Epoch 545/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.6486 - val_loss: 0.5705 - val_accuracy: 0.6000\n",
      "Epoch 546/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5490 - accuracy: 0.6486 - val_loss: 0.5704 - val_accuracy: 0.6000\n",
      "Epoch 547/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5488 - accuracy: 0.6486 - val_loss: 0.5704 - val_accuracy: 0.6000\n",
      "Epoch 548/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5487 - accuracy: 0.6486 - val_loss: 0.5704 - val_accuracy: 0.6000\n",
      "Epoch 549/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5485 - accuracy: 0.6486 - val_loss: 0.5704 - val_accuracy: 0.6000\n",
      "Epoch 550/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5483 - accuracy: 0.6486 - val_loss: 0.5704 - val_accuracy: 0.6000\n",
      "Epoch 551/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5482 - accuracy: 0.6486 - val_loss: 0.5705 - val_accuracy: 0.6000\n",
      "Epoch 552/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5480 - accuracy: 0.6486 - val_loss: 0.5703 - val_accuracy: 0.6000\n",
      "Epoch 553/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5479 - accuracy: 0.6486 - val_loss: 0.5703 - val_accuracy: 0.6000\n",
      "Epoch 554/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.6486 - val_loss: 0.5703 - val_accuracy: 0.6000\n",
      "Epoch 555/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5477 - accuracy: 0.6486 - val_loss: 0.5701 - val_accuracy: 0.6000\n",
      "Epoch 556/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5475 - accuracy: 0.6486 - val_loss: 0.5701 - val_accuracy: 0.6000\n",
      "Epoch 557/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5473 - accuracy: 0.6486 - val_loss: 0.5701 - val_accuracy: 0.6000\n",
      "Epoch 558/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5472 - accuracy: 0.6486 - val_loss: 0.5699 - val_accuracy: 0.6000\n",
      "Epoch 559/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5471 - accuracy: 0.6486 - val_loss: 0.5698 - val_accuracy: 0.6000\n",
      "Epoch 560/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5469 - accuracy: 0.6486 - val_loss: 0.5698 - val_accuracy: 0.6000\n",
      "Epoch 561/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5468 - accuracy: 0.6486 - val_loss: 0.5698 - val_accuracy: 0.6000\n",
      "Epoch 562/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5466 - accuracy: 0.6486 - val_loss: 0.5697 - val_accuracy: 0.6000\n",
      "Epoch 563/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5465 - accuracy: 0.6486 - val_loss: 0.5697 - val_accuracy: 0.6000\n",
      "Epoch 564/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.6486 - val_loss: 0.5696 - val_accuracy: 0.6000\n",
      "Epoch 565/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5462 - accuracy: 0.6486 - val_loss: 0.5696 - val_accuracy: 0.6000\n",
      "Epoch 566/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5461 - accuracy: 0.6486 - val_loss: 0.5695 - val_accuracy: 0.6000\n",
      "Epoch 567/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5460 - accuracy: 0.6486 - val_loss: 0.5694 - val_accuracy: 0.6000\n",
      "Epoch 568/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5458 - accuracy: 0.6486 - val_loss: 0.5694 - val_accuracy: 0.6000\n",
      "Epoch 569/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5457 - accuracy: 0.6486 - val_loss: 0.5694 - val_accuracy: 0.6000\n",
      "Epoch 570/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5456 - accuracy: 0.6486 - val_loss: 0.5693 - val_accuracy: 0.6000\n",
      "Epoch 571/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5454 - accuracy: 0.6486 - val_loss: 0.5692 - val_accuracy: 0.6000\n",
      "Epoch 572/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5453 - accuracy: 0.6486 - val_loss: 0.5691 - val_accuracy: 0.6000\n",
      "Epoch 573/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5452 - accuracy: 0.6486 - val_loss: 0.5690 - val_accuracy: 0.6000\n",
      "Epoch 574/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5450 - accuracy: 0.6486 - val_loss: 0.5690 - val_accuracy: 0.6000\n",
      "Epoch 575/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5449 - accuracy: 0.6486 - val_loss: 0.5689 - val_accuracy: 0.6000\n",
      "Epoch 576/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5447 - accuracy: 0.6486 - val_loss: 0.5688 - val_accuracy: 0.6000\n",
      "Epoch 577/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5446 - accuracy: 0.6486 - val_loss: 0.5687 - val_accuracy: 0.6000\n",
      "Epoch 578/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5445 - accuracy: 0.6486 - val_loss: 0.5688 - val_accuracy: 0.6000\n",
      "Epoch 579/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.6486 - val_loss: 0.5688 - val_accuracy: 0.6000\n",
      "Epoch 580/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5442 - accuracy: 0.6486 - val_loss: 0.5688 - val_accuracy: 0.6000\n",
      "Epoch 581/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5441 - accuracy: 0.6486 - val_loss: 0.5688 - val_accuracy: 0.6000\n",
      "Epoch 582/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5439 - accuracy: 0.6486 - val_loss: 0.5687 - val_accuracy: 0.6000\n",
      "Epoch 583/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5438 - accuracy: 0.6486 - val_loss: 0.5687 - val_accuracy: 0.6000\n",
      "Epoch 584/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5437 - accuracy: 0.6486 - val_loss: 0.5686 - val_accuracy: 0.6000\n",
      "Epoch 585/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5435 - accuracy: 0.6216 - val_loss: 0.5686 - val_accuracy: 0.6000\n",
      "Epoch 586/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5434 - accuracy: 0.6216 - val_loss: 0.5687 - val_accuracy: 0.6000\n",
      "Epoch 587/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5433 - accuracy: 0.6216 - val_loss: 0.5687 - val_accuracy: 0.6000\n",
      "Epoch 588/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5432 - accuracy: 0.6216 - val_loss: 0.5686 - val_accuracy: 0.6000\n",
      "Epoch 589/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5430 - accuracy: 0.6216 - val_loss: 0.5686 - val_accuracy: 0.6000\n",
      "Epoch 590/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5429 - accuracy: 0.6216 - val_loss: 0.5685 - val_accuracy: 0.6000\n",
      "Epoch 591/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5428 - accuracy: 0.6486 - val_loss: 0.5684 - val_accuracy: 0.6000\n",
      "Epoch 592/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5426 - accuracy: 0.6216 - val_loss: 0.5683 - val_accuracy: 0.6000\n",
      "Epoch 593/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5425 - accuracy: 0.6216 - val_loss: 0.5683 - val_accuracy: 0.6000\n",
      "Epoch 594/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5424 - accuracy: 0.6486 - val_loss: 0.5683 - val_accuracy: 0.6000\n",
      "Epoch 595/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5422 - accuracy: 0.6216 - val_loss: 0.5683 - val_accuracy: 0.6000\n",
      "Epoch 596/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5421 - accuracy: 0.6216 - val_loss: 0.5684 - val_accuracy: 0.6000\n",
      "Epoch 597/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.6216 - val_loss: 0.5683 - val_accuracy: 0.6000\n",
      "Epoch 598/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5419 - accuracy: 0.6486 - val_loss: 0.5683 - val_accuracy: 0.6000\n",
      "Epoch 599/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.6486 - val_loss: 0.5683 - val_accuracy: 0.6000\n",
      "Epoch 600/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5416 - accuracy: 0.6486 - val_loss: 0.5682 - val_accuracy: 0.6000\n",
      "Epoch 601/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5414 - accuracy: 0.6486 - val_loss: 0.5682 - val_accuracy: 0.6000\n",
      "Epoch 602/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5413 - accuracy: 0.6486 - val_loss: 0.5681 - val_accuracy: 0.6000\n",
      "Epoch 603/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5412 - accuracy: 0.6486 - val_loss: 0.5680 - val_accuracy: 0.6000\n",
      "Epoch 604/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.6486 - val_loss: 0.5679 - val_accuracy: 0.6000\n",
      "Epoch 605/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.6486 - val_loss: 0.5679 - val_accuracy: 0.6000\n",
      "Epoch 606/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5408 - accuracy: 0.6486 - val_loss: 0.5679 - val_accuracy: 0.6000\n",
      "Epoch 607/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.6486 - val_loss: 0.5678 - val_accuracy: 0.6000\n",
      "Epoch 608/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5405 - accuracy: 0.6486 - val_loss: 0.5678 - val_accuracy: 0.6000\n",
      "Epoch 609/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.6486 - val_loss: 0.5678 - val_accuracy: 0.6000\n",
      "Epoch 610/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5402 - accuracy: 0.6486 - val_loss: 0.5678 - val_accuracy: 0.6000\n",
      "Epoch 611/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5401 - accuracy: 0.6486 - val_loss: 0.5677 - val_accuracy: 0.6000\n",
      "Epoch 612/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5399 - accuracy: 0.6486 - val_loss: 0.5676 - val_accuracy: 0.6000\n",
      "Epoch 613/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5399 - accuracy: 0.6486 - val_loss: 0.5675 - val_accuracy: 0.6000\n",
      "Epoch 614/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5398 - accuracy: 0.6486 - val_loss: 0.5674 - val_accuracy: 0.6000\n",
      "Epoch 615/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5396 - accuracy: 0.6486 - val_loss: 0.5674 - val_accuracy: 0.6000\n",
      "Epoch 616/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5394 - accuracy: 0.6486 - val_loss: 0.5673 - val_accuracy: 0.6000\n",
      "Epoch 617/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5393 - accuracy: 0.6486 - val_loss: 0.5672 - val_accuracy: 0.6000\n",
      "Epoch 618/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5392 - accuracy: 0.6486 - val_loss: 0.5672 - val_accuracy: 0.6000\n",
      "Epoch 619/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5391 - accuracy: 0.6486 - val_loss: 0.5672 - val_accuracy: 0.6000\n",
      "Epoch 620/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5389 - accuracy: 0.6486 - val_loss: 0.5671 - val_accuracy: 0.6000\n",
      "Epoch 621/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.6486 - val_loss: 0.5670 - val_accuracy: 0.6000\n",
      "Epoch 622/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5388 - accuracy: 0.6486 - val_loss: 0.5670 - val_accuracy: 0.6000\n",
      "Epoch 623/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5385 - accuracy: 0.6486 - val_loss: 0.5669 - val_accuracy: 0.6000\n",
      "Epoch 624/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5385 - accuracy: 0.6486 - val_loss: 0.5669 - val_accuracy: 0.6000\n",
      "Epoch 625/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5383 - accuracy: 0.6486 - val_loss: 0.5668 - val_accuracy: 0.6000\n",
      "Epoch 626/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5382 - accuracy: 0.6486 - val_loss: 0.5668 - val_accuracy: 0.6000\n",
      "Epoch 627/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5381 - accuracy: 0.6486 - val_loss: 0.5668 - val_accuracy: 0.6000\n",
      "Epoch 628/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5379 - accuracy: 0.6486 - val_loss: 0.5668 - val_accuracy: 0.6000\n",
      "Epoch 629/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5377 - accuracy: 0.6486 - val_loss: 0.5667 - val_accuracy: 0.6000\n",
      "Epoch 630/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5377 - accuracy: 0.6486 - val_loss: 0.5666 - val_accuracy: 0.6000\n",
      "Epoch 631/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5376 - accuracy: 0.6486 - val_loss: 0.5666 - val_accuracy: 0.6000\n",
      "Epoch 632/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5375 - accuracy: 0.6486 - val_loss: 0.5666 - val_accuracy: 0.6000\n",
      "Epoch 633/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5372 - accuracy: 0.6486 - val_loss: 0.5666 - val_accuracy: 0.6000\n",
      "Epoch 634/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5371 - accuracy: 0.6486 - val_loss: 0.5666 - val_accuracy: 0.6000\n",
      "Epoch 635/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5370 - accuracy: 0.6486 - val_loss: 0.5665 - val_accuracy: 0.6000\n",
      "Epoch 636/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5370 - accuracy: 0.6486 - val_loss: 0.5664 - val_accuracy: 0.6000\n",
      "Epoch 637/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5368 - accuracy: 0.6486 - val_loss: 0.5664 - val_accuracy: 0.6000\n",
      "Epoch 638/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5367 - accuracy: 0.6486 - val_loss: 0.5664 - val_accuracy: 0.6000\n",
      "Epoch 639/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5365 - accuracy: 0.6486 - val_loss: 0.5663 - val_accuracy: 0.6000\n",
      "Epoch 640/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5364 - accuracy: 0.6486 - val_loss: 0.5662 - val_accuracy: 0.6000\n",
      "Epoch 641/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5363 - accuracy: 0.6486 - val_loss: 0.5662 - val_accuracy: 0.6000\n",
      "Epoch 642/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5363 - accuracy: 0.6486 - val_loss: 0.5661 - val_accuracy: 0.6000\n",
      "Epoch 643/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5361 - accuracy: 0.6486 - val_loss: 0.5660 - val_accuracy: 0.6000\n",
      "Epoch 644/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5360 - accuracy: 0.6486 - val_loss: 0.5660 - val_accuracy: 0.6000\n",
      "Epoch 645/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5358 - accuracy: 0.6486 - val_loss: 0.5660 - val_accuracy: 0.6000\n",
      "Epoch 646/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5357 - accuracy: 0.6486 - val_loss: 0.5661 - val_accuracy: 0.6000\n",
      "Epoch 647/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5356 - accuracy: 0.6486 - val_loss: 0.5660 - val_accuracy: 0.6000\n",
      "Epoch 648/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5354 - accuracy: 0.6486 - val_loss: 0.5660 - val_accuracy: 0.6000\n",
      "Epoch 649/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5354 - accuracy: 0.6486 - val_loss: 0.5661 - val_accuracy: 0.6000\n",
      "Epoch 650/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5353 - accuracy: 0.6486 - val_loss: 0.5660 - val_accuracy: 0.6000\n",
      "Epoch 651/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5351 - accuracy: 0.6486 - val_loss: 0.5659 - val_accuracy: 0.6000\n",
      "Epoch 652/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5350 - accuracy: 0.6486 - val_loss: 0.5658 - val_accuracy: 0.6000\n",
      "Epoch 653/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.6486 - val_loss: 0.5658 - val_accuracy: 0.6000\n",
      "Epoch 654/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5347 - accuracy: 0.6486 - val_loss: 0.5657 - val_accuracy: 0.6000\n",
      "Epoch 655/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5347 - accuracy: 0.6486 - val_loss: 0.5656 - val_accuracy: 0.6000\n",
      "Epoch 656/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5346 - accuracy: 0.6486 - val_loss: 0.5657 - val_accuracy: 0.6000\n",
      "Epoch 657/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5344 - accuracy: 0.6486 - val_loss: 0.5656 - val_accuracy: 0.6000\n",
      "Epoch 658/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5343 - accuracy: 0.6486 - val_loss: 0.5655 - val_accuracy: 0.6000\n",
      "Epoch 659/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5342 - accuracy: 0.6486 - val_loss: 0.5654 - val_accuracy: 0.6000\n",
      "Epoch 660/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5341 - accuracy: 0.6486 - val_loss: 0.5655 - val_accuracy: 0.6000\n",
      "Epoch 661/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5339 - accuracy: 0.6486 - val_loss: 0.5654 - val_accuracy: 0.6000\n",
      "Epoch 662/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.6486 - val_loss: 0.5653 - val_accuracy: 0.6000\n",
      "Epoch 663/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5337 - accuracy: 0.6486 - val_loss: 0.5653 - val_accuracy: 0.6000\n",
      "Epoch 664/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5336 - accuracy: 0.6486 - val_loss: 0.5653 - val_accuracy: 0.6000\n",
      "Epoch 665/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5335 - accuracy: 0.6486 - val_loss: 0.5652 - val_accuracy: 0.6000\n",
      "Epoch 666/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5334 - accuracy: 0.6486 - val_loss: 0.5653 - val_accuracy: 0.6000\n",
      "Epoch 667/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5332 - accuracy: 0.6486 - val_loss: 0.5653 - val_accuracy: 0.6000\n",
      "Epoch 668/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.6486 - val_loss: 0.5652 - val_accuracy: 0.6000\n",
      "Epoch 669/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5330 - accuracy: 0.6486 - val_loss: 0.5651 - val_accuracy: 0.6000\n",
      "Epoch 670/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.6486 - val_loss: 0.5650 - val_accuracy: 0.6000\n",
      "Epoch 671/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.6486 - val_loss: 0.5650 - val_accuracy: 0.6000\n",
      "Epoch 672/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.6486 - val_loss: 0.5650 - val_accuracy: 0.6000\n",
      "Epoch 673/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5326 - accuracy: 0.6486 - val_loss: 0.5650 - val_accuracy: 0.6000\n",
      "Epoch 674/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5323 - accuracy: 0.6486 - val_loss: 0.5649 - val_accuracy: 0.6000\n",
      "Epoch 675/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5322 - accuracy: 0.6486 - val_loss: 0.5649 - val_accuracy: 0.6000\n",
      "Epoch 676/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5321 - accuracy: 0.6486 - val_loss: 0.5649 - val_accuracy: 0.6000\n",
      "Epoch 677/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5320 - accuracy: 0.6486 - val_loss: 0.5649 - val_accuracy: 0.6000\n",
      "Epoch 678/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5319 - accuracy: 0.6486 - val_loss: 0.5649 - val_accuracy: 0.6000\n",
      "Epoch 679/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5317 - accuracy: 0.6486 - val_loss: 0.5650 - val_accuracy: 0.6000\n",
      "Epoch 680/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5316 - accuracy: 0.6216 - val_loss: 0.5651 - val_accuracy: 0.6000\n",
      "Epoch 681/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5315 - accuracy: 0.6216 - val_loss: 0.5650 - val_accuracy: 0.6000\n",
      "Epoch 682/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5314 - accuracy: 0.6216 - val_loss: 0.5649 - val_accuracy: 0.6000\n",
      "Epoch 683/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5313 - accuracy: 0.6216 - val_loss: 0.5648 - val_accuracy: 0.6000\n",
      "Epoch 684/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5312 - accuracy: 0.6216 - val_loss: 0.5648 - val_accuracy: 0.6000\n",
      "Epoch 685/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5311 - accuracy: 0.6216 - val_loss: 0.5648 - val_accuracy: 0.6000\n",
      "Epoch 686/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5309 - accuracy: 0.6216 - val_loss: 0.5648 - val_accuracy: 0.6000\n",
      "Epoch 687/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5308 - accuracy: 0.6216 - val_loss: 0.5647 - val_accuracy: 0.6000\n",
      "Epoch 688/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5307 - accuracy: 0.6216 - val_loss: 0.5647 - val_accuracy: 0.6000\n",
      "Epoch 689/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5306 - accuracy: 0.6216 - val_loss: 0.5646 - val_accuracy: 0.6000\n",
      "Epoch 690/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.6216 - val_loss: 0.5645 - val_accuracy: 0.6000\n",
      "Epoch 691/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5303 - accuracy: 0.6216 - val_loss: 0.5645 - val_accuracy: 0.6000\n",
      "Epoch 692/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5303 - accuracy: 0.6216 - val_loss: 0.5645 - val_accuracy: 0.6000\n",
      "Epoch 693/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5300 - accuracy: 0.6216 - val_loss: 0.5644 - val_accuracy: 0.6000\n",
      "Epoch 694/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5300 - accuracy: 0.6216 - val_loss: 0.5645 - val_accuracy: 0.6000\n",
      "Epoch 695/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5298 - accuracy: 0.6216 - val_loss: 0.5644 - val_accuracy: 0.6000\n",
      "Epoch 696/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5297 - accuracy: 0.6216 - val_loss: 0.5643 - val_accuracy: 0.6000\n",
      "Epoch 697/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5297 - accuracy: 0.6216 - val_loss: 0.5643 - val_accuracy: 0.6000\n",
      "Epoch 698/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5294 - accuracy: 0.6216 - val_loss: 0.5642 - val_accuracy: 0.6000\n",
      "Epoch 699/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5294 - accuracy: 0.6216 - val_loss: 0.5641 - val_accuracy: 0.6000\n",
      "Epoch 700/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5292 - accuracy: 0.6216 - val_loss: 0.5640 - val_accuracy: 0.6000\n",
      "Epoch 701/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.6216 - val_loss: 0.5640 - val_accuracy: 0.6000\n",
      "Epoch 702/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.6216 - val_loss: 0.5640 - val_accuracy: 0.6000\n",
      "Epoch 703/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5290 - accuracy: 0.6216 - val_loss: 0.5639 - val_accuracy: 0.6000\n",
      "Epoch 704/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.6216 - val_loss: 0.5639 - val_accuracy: 0.6000\n",
      "Epoch 705/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5287 - accuracy: 0.6216 - val_loss: 0.5639 - val_accuracy: 0.6000\n",
      "Epoch 706/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5286 - accuracy: 0.6216 - val_loss: 0.5638 - val_accuracy: 0.6000\n",
      "Epoch 707/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5284 - accuracy: 0.6216 - val_loss: 0.5638 - val_accuracy: 0.6000\n",
      "Epoch 708/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5284 - accuracy: 0.6216 - val_loss: 0.5638 - val_accuracy: 0.6000\n",
      "Epoch 709/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5282 - accuracy: 0.6216 - val_loss: 0.5638 - val_accuracy: 0.6000\n",
      "Epoch 710/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5281 - accuracy: 0.6216 - val_loss: 0.5638 - val_accuracy: 0.6000\n",
      "Epoch 711/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5280 - accuracy: 0.6216 - val_loss: 0.5637 - val_accuracy: 0.6000\n",
      "Epoch 712/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5279 - accuracy: 0.6216 - val_loss: 0.5638 - val_accuracy: 0.6000\n",
      "Epoch 713/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5278 - accuracy: 0.6216 - val_loss: 0.5638 - val_accuracy: 0.6000\n",
      "Epoch 714/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5276 - accuracy: 0.6216 - val_loss: 0.5636 - val_accuracy: 0.6000\n",
      "Epoch 715/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5275 - accuracy: 0.6216 - val_loss: 0.5636 - val_accuracy: 0.6000\n",
      "Epoch 716/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5275 - accuracy: 0.6216 - val_loss: 0.5635 - val_accuracy: 0.6000\n",
      "Epoch 717/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5274 - accuracy: 0.6216 - val_loss: 0.5635 - val_accuracy: 0.7000\n",
      "Epoch 718/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5272 - accuracy: 0.6216 - val_loss: 0.5634 - val_accuracy: 0.6000\n",
      "Epoch 719/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5272 - accuracy: 0.6216 - val_loss: 0.5633 - val_accuracy: 0.6000\n",
      "Epoch 720/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5270 - accuracy: 0.6216 - val_loss: 0.5632 - val_accuracy: 0.6000\n",
      "Epoch 721/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5269 - accuracy: 0.6216 - val_loss: 0.5633 - val_accuracy: 0.7000\n",
      "Epoch 722/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5268 - accuracy: 0.6216 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 723/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 724/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5266 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 725/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5264 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 726/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5263 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 727/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5262 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 728/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 729/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5260 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 730/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5258 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 731/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5257 - accuracy: 0.6216 - val_loss: 0.5632 - val_accuracy: 0.7000\n",
      "Epoch 732/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5256 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 733/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5255 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 734/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5254 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 735/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5253 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 736/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5251 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 737/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5251 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 738/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5250 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 739/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5249 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 740/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5247 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 741/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5247 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 742/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5245 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 743/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5244 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 744/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5243 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 745/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5241 - accuracy: 0.6216 - val_loss: 0.5631 - val_accuracy: 0.7000\n",
      "Epoch 746/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5240 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 747/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5239 - accuracy: 0.6216 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 748/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5239 - accuracy: 0.6216 - val_loss: 0.5630 - val_accuracy: 0.7000\n",
      "Epoch 749/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5237 - accuracy: 0.6216 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 750/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5236 - accuracy: 0.6216 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 751/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5235 - accuracy: 0.6216 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 752/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5234 - accuracy: 0.6216 - val_loss: 0.5629 - val_accuracy: 0.7000\n",
      "Epoch 753/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5232 - accuracy: 0.6216 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 754/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5231 - accuracy: 0.6216 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 755/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5231 - accuracy: 0.6216 - val_loss: 0.5626 - val_accuracy: 0.7000\n",
      "Epoch 756/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5230 - accuracy: 0.6216 - val_loss: 0.5627 - val_accuracy: 0.7000\n",
      "Epoch 757/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5228 - accuracy: 0.6216 - val_loss: 0.5626 - val_accuracy: 0.7000\n",
      "Epoch 758/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5228 - accuracy: 0.6216 - val_loss: 0.5625 - val_accuracy: 0.7000\n",
      "Epoch 759/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5227 - accuracy: 0.6216 - val_loss: 0.5625 - val_accuracy: 0.7000\n",
      "Epoch 760/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5226 - accuracy: 0.6216 - val_loss: 0.5625 - val_accuracy: 0.7000\n",
      "Epoch 761/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5224 - accuracy: 0.6216 - val_loss: 0.5624 - val_accuracy: 0.7000\n",
      "Epoch 762/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.6216 - val_loss: 0.5624 - val_accuracy: 0.7000\n",
      "Epoch 763/5000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5223 - accuracy: 0.6216 - val_loss: 0.5623 - val_accuracy: 0.7000\n",
      "Epoch 764/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5222 - accuracy: 0.6216 - val_loss: 0.5622 - val_accuracy: 0.7000\n",
      "Epoch 765/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5220 - accuracy: 0.6216 - val_loss: 0.5621 - val_accuracy: 0.7000\n",
      "Epoch 766/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5220 - accuracy: 0.6216 - val_loss: 0.5620 - val_accuracy: 0.7000\n",
      "Epoch 767/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5218 - accuracy: 0.6216 - val_loss: 0.5620 - val_accuracy: 0.7000\n",
      "Epoch 768/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5218 - accuracy: 0.6216 - val_loss: 0.5621 - val_accuracy: 0.7000\n",
      "Epoch 769/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5217 - accuracy: 0.6216 - val_loss: 0.5620 - val_accuracy: 0.7000\n",
      "Epoch 770/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5216 - accuracy: 0.6216 - val_loss: 0.5620 - val_accuracy: 0.7000\n",
      "Epoch 771/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5215 - accuracy: 0.6216 - val_loss: 0.5619 - val_accuracy: 0.7000\n",
      "Epoch 772/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5214 - accuracy: 0.6216 - val_loss: 0.5619 - val_accuracy: 0.7000\n",
      "Epoch 773/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5212 - accuracy: 0.6216 - val_loss: 0.5618 - val_accuracy: 0.7000\n",
      "Epoch 774/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5212 - accuracy: 0.6216 - val_loss: 0.5617 - val_accuracy: 0.7000\n",
      "Epoch 775/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5210 - accuracy: 0.6216 - val_loss: 0.5617 - val_accuracy: 0.7000\n",
      "Epoch 776/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5209 - accuracy: 0.6216 - val_loss: 0.5617 - val_accuracy: 0.7000\n",
      "Epoch 777/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5208 - accuracy: 0.6216 - val_loss: 0.5616 - val_accuracy: 0.7000\n",
      "Epoch 778/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5207 - accuracy: 0.6216 - val_loss: 0.5615 - val_accuracy: 0.7000\n",
      "Epoch 779/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5206 - accuracy: 0.6216 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 780/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5205 - accuracy: 0.6216 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 781/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5204 - accuracy: 0.6216 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 782/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5203 - accuracy: 0.6216 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 783/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.6216 - val_loss: 0.5613 - val_accuracy: 0.7000\n",
      "Epoch 784/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5201 - accuracy: 0.6216 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 785/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5199 - accuracy: 0.6216 - val_loss: 0.5613 - val_accuracy: 0.7000\n",
      "Epoch 786/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5199 - accuracy: 0.6216 - val_loss: 0.5613 - val_accuracy: 0.7000\n",
      "Epoch 787/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5198 - accuracy: 0.6216 - val_loss: 0.5612 - val_accuracy: 0.7000\n",
      "Epoch 788/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5197 - accuracy: 0.6216 - val_loss: 0.5611 - val_accuracy: 0.7000\n",
      "Epoch 789/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5196 - accuracy: 0.6216 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 790/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5195 - accuracy: 0.6216 - val_loss: 0.5611 - val_accuracy: 0.7000\n",
      "Epoch 791/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5194 - accuracy: 0.6216 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 792/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5193 - accuracy: 0.6216 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 793/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5192 - accuracy: 0.6216 - val_loss: 0.5611 - val_accuracy: 0.7000\n",
      "Epoch 794/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5191 - accuracy: 0.6216 - val_loss: 0.5611 - val_accuracy: 0.7000\n",
      "Epoch 795/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5190 - accuracy: 0.6216 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 796/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5189 - accuracy: 0.6216 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 797/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5188 - accuracy: 0.6216 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
      "Epoch 798/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5187 - accuracy: 0.6216 - val_loss: 0.5609 - val_accuracy: 0.7000\n",
      "Epoch 799/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5186 - accuracy: 0.6216 - val_loss: 0.5609 - val_accuracy: 0.7000\n",
      "Epoch 800/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5185 - accuracy: 0.6216 - val_loss: 0.5609 - val_accuracy: 0.7000\n",
      "Epoch 801/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5184 - accuracy: 0.6216 - val_loss: 0.5608 - val_accuracy: 0.7000\n",
      "Epoch 802/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5184 - accuracy: 0.6216 - val_loss: 0.5607 - val_accuracy: 0.7000\n",
      "Epoch 803/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5183 - accuracy: 0.6216 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 804/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5181 - accuracy: 0.6216 - val_loss: 0.5606 - val_accuracy: 0.7000\n",
      "Epoch 805/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5181 - accuracy: 0.6216 - val_loss: 0.5605 - val_accuracy: 0.7000\n",
      "Epoch 806/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5179 - accuracy: 0.6216 - val_loss: 0.5605 - val_accuracy: 0.7000\n",
      "Epoch 807/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5179 - accuracy: 0.6216 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 808/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5179 - accuracy: 0.6216 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 809/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5176 - accuracy: 0.6216 - val_loss: 0.5605 - val_accuracy: 0.7000\n",
      "Epoch 810/5000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5176 - accuracy: 0.6216 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 811/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5175 - accuracy: 0.6216 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 812/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5174 - accuracy: 0.6216 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 813/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5173 - accuracy: 0.6216 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 814/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.6216 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 815/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.6216 - val_loss: 0.5605 - val_accuracy: 0.7000\n",
      "Epoch 816/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5170 - accuracy: 0.6216 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 817/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5169 - accuracy: 0.6216 - val_loss: 0.5603 - val_accuracy: 0.7000\n",
      "Epoch 818/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5168 - accuracy: 0.6216 - val_loss: 0.5603 - val_accuracy: 0.7000\n",
      "Epoch 819/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.6216 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 820/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5166 - accuracy: 0.6216 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 821/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5165 - accuracy: 0.6216 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 822/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5164 - accuracy: 0.6216 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 823/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5162 - accuracy: 0.6216 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 824/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5161 - accuracy: 0.6216 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 825/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5160 - accuracy: 0.6216 - val_loss: 0.5602 - val_accuracy: 0.7000\n",
      "Epoch 826/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5159 - accuracy: 0.6216 - val_loss: 0.5601 - val_accuracy: 0.7000\n",
      "Epoch 827/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5158 - accuracy: 0.6216 - val_loss: 0.5601 - val_accuracy: 0.7000\n",
      "Epoch 828/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5157 - accuracy: 0.6216 - val_loss: 0.5601 - val_accuracy: 0.7000\n",
      "Epoch 829/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5157 - accuracy: 0.6216 - val_loss: 0.5600 - val_accuracy: 0.7000\n",
      "Epoch 830/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5155 - accuracy: 0.6216 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
      "Epoch 831/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5154 - accuracy: 0.6216 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
      "Epoch 832/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5153 - accuracy: 0.6216 - val_loss: 0.5598 - val_accuracy: 0.7000\n",
      "Epoch 833/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5153 - accuracy: 0.6216 - val_loss: 0.5598 - val_accuracy: 0.7000\n",
      "Epoch 834/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5152 - accuracy: 0.6216 - val_loss: 0.5597 - val_accuracy: 0.7000\n",
      "Epoch 835/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5151 - accuracy: 0.6216 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 836/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5150 - accuracy: 0.6216 - val_loss: 0.5597 - val_accuracy: 0.7000\n",
      "Epoch 837/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5149 - accuracy: 0.6216 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 838/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5148 - accuracy: 0.6216 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 839/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5147 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 840/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5146 - accuracy: 0.6216 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 841/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5145 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 842/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 843/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5143 - accuracy: 0.6216 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 844/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5143 - accuracy: 0.6216 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 845/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5142 - accuracy: 0.6216 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
      "Epoch 846/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5141 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 847/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5139 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 848/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5138 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 849/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5137 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 850/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5136 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 851/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5135 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 852/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5134 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 853/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5133 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 854/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5132 - accuracy: 0.6216 - val_loss: 0.5595 - val_accuracy: 0.7000\n",
      "Epoch 855/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5131 - accuracy: 0.6216 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 856/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5130 - accuracy: 0.6216 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 857/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5129 - accuracy: 0.6216 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 858/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5128 - accuracy: 0.6216 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 859/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5127 - accuracy: 0.6216 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 860/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5126 - accuracy: 0.6216 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 861/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5126 - accuracy: 0.6216 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 862/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5125 - accuracy: 0.6216 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 863/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5124 - accuracy: 0.6216 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 864/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5122 - accuracy: 0.6486 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 865/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5121 - accuracy: 0.6486 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 866/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5121 - accuracy: 0.6216 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 867/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5119 - accuracy: 0.6216 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 868/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5118 - accuracy: 0.6486 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 869/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5117 - accuracy: 0.6486 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 870/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5116 - accuracy: 0.6486 - val_loss: 0.5594 - val_accuracy: 0.7000\n",
      "Epoch 871/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5115 - accuracy: 0.6486 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 872/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5115 - accuracy: 0.6486 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 873/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5114 - accuracy: 0.6486 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 874/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5114 - accuracy: 0.6486 - val_loss: 0.5590 - val_accuracy: 0.7000\n",
      "Epoch 875/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5112 - accuracy: 0.6486 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 876/5000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5111 - accuracy: 0.6486 - val_loss: 0.5590 - val_accuracy: 0.7000\n",
      "Epoch 877/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5110 - accuracy: 0.6486 - val_loss: 0.5590 - val_accuracy: 0.7000\n",
      "Epoch 878/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5109 - accuracy: 0.6486 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 879/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5108 - accuracy: 0.6486 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 880/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5107 - accuracy: 0.6486 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 881/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5106 - accuracy: 0.6486 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 882/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5105 - accuracy: 0.6486 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 883/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5104 - accuracy: 0.6486 - val_loss: 0.5592 - val_accuracy: 0.7000\n",
      "Epoch 884/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5103 - accuracy: 0.6486 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 885/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5102 - accuracy: 0.6486 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 886/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5102 - accuracy: 0.6486 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 887/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5101 - accuracy: 0.6486 - val_loss: 0.5591 - val_accuracy: 0.7000\n",
      "Epoch 888/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.6486 - val_loss: 0.5590 - val_accuracy: 0.7000\n",
      "Epoch 889/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5099 - accuracy: 0.6486 - val_loss: 0.5590 - val_accuracy: 0.7000\n",
      "Epoch 890/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5098 - accuracy: 0.6486 - val_loss: 0.5589 - val_accuracy: 0.7000\n",
      "Epoch 891/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5097 - accuracy: 0.6486 - val_loss: 0.5589 - val_accuracy: 0.7000\n",
      "Epoch 892/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5097 - accuracy: 0.6486 - val_loss: 0.5589 - val_accuracy: 0.7000\n",
      "Epoch 893/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5096 - accuracy: 0.6486 - val_loss: 0.5588 - val_accuracy: 0.7000\n",
      "Epoch 894/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5095 - accuracy: 0.6486 - val_loss: 0.5589 - val_accuracy: 0.7000\n",
      "Epoch 895/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5094 - accuracy: 0.6486 - val_loss: 0.5589 - val_accuracy: 0.7000\n",
      "Epoch 896/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5093 - accuracy: 0.6486 - val_loss: 0.5589 - val_accuracy: 0.7000\n",
      "Epoch 897/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5092 - accuracy: 0.6486 - val_loss: 0.5589 - val_accuracy: 0.7000\n",
      "Epoch 898/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5091 - accuracy: 0.6486 - val_loss: 0.5588 - val_accuracy: 0.7000\n",
      "Epoch 899/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5090 - accuracy: 0.6486 - val_loss: 0.5587 - val_accuracy: 0.7000\n",
      "Epoch 900/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5089 - accuracy: 0.6486 - val_loss: 0.5587 - val_accuracy: 0.7000\n",
      "Epoch 901/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5089 - accuracy: 0.6486 - val_loss: 0.5587 - val_accuracy: 0.7000\n",
      "Epoch 902/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5088 - accuracy: 0.6486 - val_loss: 0.5586 - val_accuracy: 0.7000\n",
      "Epoch 903/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5086 - accuracy: 0.6486 - val_loss: 0.5585 - val_accuracy: 0.7000\n",
      "Epoch 904/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5086 - accuracy: 0.6486 - val_loss: 0.5584 - val_accuracy: 0.7000\n",
      "Epoch 905/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5085 - accuracy: 0.6486 - val_loss: 0.5583 - val_accuracy: 0.7000\n",
      "Epoch 906/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5084 - accuracy: 0.6486 - val_loss: 0.5583 - val_accuracy: 0.7000\n",
      "Epoch 907/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5083 - accuracy: 0.6486 - val_loss: 0.5583 - val_accuracy: 0.7000\n",
      "Epoch 908/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5082 - accuracy: 0.6486 - val_loss: 0.5583 - val_accuracy: 0.7000\n",
      "Epoch 909/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5082 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 910/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5080 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 911/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5080 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 912/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5079 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 913/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5078 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 914/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5077 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 915/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5076 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 916/5000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5075 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 917/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5074 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 918/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5074 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 919/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5072 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 920/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5071 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 921/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5071 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 922/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5070 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 923/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5069 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 924/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5068 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 925/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5067 - accuracy: 0.6486 - val_loss: 0.5583 - val_accuracy: 0.7000\n",
      "Epoch 926/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5066 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 927/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5066 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 928/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5065 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 929/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5064 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 930/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5063 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 931/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5062 - accuracy: 0.6486 - val_loss: 0.5580 - val_accuracy: 0.7000\n",
      "Epoch 932/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5062 - accuracy: 0.6486 - val_loss: 0.5580 - val_accuracy: 0.7000\n",
      "Epoch 933/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5061 - accuracy: 0.6486 - val_loss: 0.5580 - val_accuracy: 0.7000\n",
      "Epoch 934/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5060 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 935/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5059 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 936/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5058 - accuracy: 0.6486 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 937/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5057 - accuracy: 0.6486 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
      "Epoch 938/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5056 - accuracy: 0.6486 - val_loss: 0.5580 - val_accuracy: 0.7000\n",
      "Epoch 939/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5055 - accuracy: 0.6486 - val_loss: 0.5579 - val_accuracy: 0.7000\n",
      "Epoch 940/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5055 - accuracy: 0.6486 - val_loss: 0.5579 - val_accuracy: 0.7000\n",
      "Epoch 941/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5053 - accuracy: 0.6486 - val_loss: 0.5579 - val_accuracy: 0.7000\n",
      "Epoch 942/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5053 - accuracy: 0.6486 - val_loss: 0.5579 - val_accuracy: 0.7000\n",
      "Epoch 943/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5052 - accuracy: 0.6486 - val_loss: 0.5579 - val_accuracy: 0.7000\n",
      "Epoch 944/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5052 - accuracy: 0.6486 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 945/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5050 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 946/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5050 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 947/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5048 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 948/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5048 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 949/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5046 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 950/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5046 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 951/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5044 - accuracy: 0.6486 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 952/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5044 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 953/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5043 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 954/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5043 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 955/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5041 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 956/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5040 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 957/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5039 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 958/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5039 - accuracy: 0.6486 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 959/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5037 - accuracy: 0.6486 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 960/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5037 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 961/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5036 - accuracy: 0.6486 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 962/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5035 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 963/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5035 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 964/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 965/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 966/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5032 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 967/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5031 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 968/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5031 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 969/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5029 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 970/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5028 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 971/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5028 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 972/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5027 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 973/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5026 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 974/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5025 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 975/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5024 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 976/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 977/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5023 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 978/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5021 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 979/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5020 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 980/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5020 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 981/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 982/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5018 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 983/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5018 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 984/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5017 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 985/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5016 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 986/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5015 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 987/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5014 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 988/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 989/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5012 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 990/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5012 - accuracy: 0.6486 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 991/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.6486 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 992/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5009 - accuracy: 0.6486 - val_loss: 0.5578 - val_accuracy: 0.7000\n",
      "Epoch 993/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5009 - accuracy: 0.6486 - val_loss: 0.5577 - val_accuracy: 0.7000\n",
      "Epoch 994/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5008 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 995/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5007 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 996/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.6486 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 997/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 998/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 999/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1000/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1001/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5003 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1002/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5002 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1003/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5001 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1004/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.6486 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1005/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4999 - accuracy: 0.6757 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1006/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4999 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1007/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4998 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1008/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4997 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1009/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4997 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1010/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4996 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1011/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4995 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1012/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4995 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1013/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4994 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1014/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4993 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1015/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4991 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1016/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4991 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1017/5000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4990 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1018/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4989 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1019/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1020/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4988 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1021/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4987 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1022/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4986 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1023/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4985 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1024/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4984 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1025/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4984 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1026/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4983 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1027/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4982 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1028/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1029/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4981 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1030/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4979 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1031/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4980 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1032/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4978 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1033/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4978 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1034/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4976 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1035/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4975 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1036/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4974 - accuracy: 0.6757 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1037/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1038/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4973 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1039/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4973 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1040/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4972 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1041/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4971 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1042/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4970 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1043/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4970 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1044/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4969 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1045/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4968 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1046/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4968 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1047/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4967 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1048/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4966 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1049/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4965 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1050/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4965 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1051/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1052/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4964 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1053/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4962 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1054/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4961 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1055/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4961 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1056/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4960 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1057/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4959 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1058/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4959 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1059/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4958 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1060/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4957 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1061/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4957 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1062/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4955 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1063/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4955 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1064/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1065/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4954 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1066/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4952 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1067/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4952 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1068/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4951 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1069/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4951 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1070/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1071/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4948 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1072/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4949 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1073/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4947 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1074/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1075/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4946 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1076/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1077/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1078/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4943 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1079/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4943 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1080/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4942 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1081/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4942 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1082/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4941 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1083/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4941 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1084/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4940 - accuracy: 0.6486 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1085/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4939 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1086/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4939 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1087/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4937 - accuracy: 0.6486 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1088/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4936 - accuracy: 0.6486 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1089/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1090/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1091/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4934 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1092/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4933 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1093/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1094/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4932 - accuracy: 0.6486 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1095/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4931 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1096/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4931 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1097/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1098/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4929 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1099/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4928 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1100/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4927 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1101/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4927 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1102/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1103/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1104/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1105/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1106/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4923 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1107/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4923 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1108/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4923 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1109/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4922 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1110/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4921 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1111/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4921 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1112/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4919 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1113/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4919 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1114/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4918 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1115/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4917 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1116/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1117/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4916 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1118/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4915 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1119/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4915 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1120/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4914 - accuracy: 0.6486 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1121/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4914 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1122/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1123/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4912 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1124/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.6486 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1125/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1126/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4910 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1127/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1128/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4909 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1129/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4907 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1130/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4907 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1131/5000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4906 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1132/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4905 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1133/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4905 - accuracy: 0.6486 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1134/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1135/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1136/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4903 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1137/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4903 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1138/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4902 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1139/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1140/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4900 - accuracy: 0.6486 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1141/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4900 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1142/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4899 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1143/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1144/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4897 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1145/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4897 - accuracy: 0.6486 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1146/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4896 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1147/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4896 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1148/5000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4895 - accuracy: 0.6757 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1149/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4894 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1150/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4893 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1151/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1152/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4893 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1153/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4891 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1154/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4891 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1155/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1156/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1157/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1158/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4889 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1159/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1160/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1161/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1162/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4886 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1163/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4885 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1164/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1165/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4884 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1166/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4884 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1167/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1168/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4881 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1169/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4881 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1170/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4881 - accuracy: 0.6757 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1171/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4880 - accuracy: 0.6757 - val_loss: 0.5576 - val_accuracy: 0.7000\n",
      "Epoch 1172/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4879 - accuracy: 0.6757 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1173/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4879 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1174/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4877 - accuracy: 0.6757 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1175/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1176/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4877 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1177/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4876 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1178/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4875 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1179/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4875 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1180/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4874 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1181/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4873 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1182/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4873 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1183/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1184/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4872 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1185/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1186/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4870 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1187/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4869 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1188/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4869 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1189/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4868 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1190/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4868 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1191/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4867 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1192/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4866 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1193/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4866 - accuracy: 0.6757 - val_loss: 0.5575 - val_accuracy: 0.7000\n",
      "Epoch 1194/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4864 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1195/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4864 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1196/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4863 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1197/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4863 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1198/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4863 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1199/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4862 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1200/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4861 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1201/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4861 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1202/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4860 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1203/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4859 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1204/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1205/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4859 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1206/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4857 - accuracy: 0.6757 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1207/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4857 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1208/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4855 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1209/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4856 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1210/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4855 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1211/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4854 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1212/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4854 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1213/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4853 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1214/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4852 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1215/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4852 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1216/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4851 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1217/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4851 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1218/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4849 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1219/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4849 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1220/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4848 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1221/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4849 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1222/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4847 - accuracy: 0.6757 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1223/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4847 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1224/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4846 - accuracy: 0.6757 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1225/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4846 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1226/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4845 - accuracy: 0.6757 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1227/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4845 - accuracy: 0.6757 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1228/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4844 - accuracy: 0.6757 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1229/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4843 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1230/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4843 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1231/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4842 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1232/5000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4842 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1233/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4841 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1234/5000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4841 - accuracy: 0.6757 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1235/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4840 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1236/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4840 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1237/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4839 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1238/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4839 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1239/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4838 - accuracy: 0.6757 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 1240/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.6757 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 1241/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.6757 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 1242/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4836 - accuracy: 0.6757 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 1243/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4835 - accuracy: 0.6757 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 1244/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4835 - accuracy: 0.6757 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 1245/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4835 - accuracy: 0.6757 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 1246/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.6757 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 1247/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1248/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4832 - accuracy: 0.6757 - val_loss: 0.5569 - val_accuracy: 0.7000\n",
      "Epoch 1249/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.6757 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1250/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4831 - accuracy: 0.6757 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 1251/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1252/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4829 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1253/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4829 - accuracy: 0.6757 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1254/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1255/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4827 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1256/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4827 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1257/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4826 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1258/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4825 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1259/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.6757 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1260/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4824 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1261/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4824 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1262/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4823 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1263/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4822 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1264/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4822 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1265/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4822 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1266/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4821 - accuracy: 0.6757 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1267/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4820 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1268/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4819 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1269/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4819 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1270/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4818 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1271/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4817 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1272/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4817 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1273/5000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.4816 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1274/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4816 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1275/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4815 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1276/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4816 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1277/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4814 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1278/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4814 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1279/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4813 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.7000\n",
      "Epoch 1280/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4812 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1281/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1282/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4811 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1283/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4810 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1284/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4810 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1285/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4809 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1286/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4809 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1287/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4808 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1288/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4808 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1289/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4807 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1290/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4806 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1291/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1292/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4805 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1293/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4805 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1294/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4803 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1295/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4803 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1296/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4803 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1297/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4802 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1298/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4801 - accuracy: 0.7027 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1299/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4801 - accuracy: 0.7027 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1300/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4801 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1301/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4799 - accuracy: 0.7027 - val_loss: 0.5571 - val_accuracy: 0.7000\n",
      "Epoch 1302/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4799 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1303/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4799 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1304/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4798 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1305/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4798 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1306/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4797 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1307/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4797 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1308/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4796 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1309/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4795 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1310/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4795 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1311/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1312/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4793 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.7000\n",
      "Epoch 1313/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4793 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1314/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1315/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4792 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1316/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4791 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1317/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4790 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1318/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1319/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.7000\n",
      "Epoch 1320/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4789 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1321/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4788 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1322/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4788 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1323/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4787 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1324/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4786 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1325/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4787 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1326/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4785 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1327/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4785 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1328/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4784 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1329/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4784 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1330/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4783 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1331/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4782 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1332/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4781 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1333/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4781 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1334/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4781 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1335/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4780 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1336/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1337/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4779 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1338/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4778 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1339/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1340/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4777 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1341/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1342/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1343/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4776 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1344/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4775 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1345/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1346/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1347/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4773 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1348/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4773 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1349/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4772 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1350/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4772 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1351/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4772 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1352/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4771 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1353/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1354/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4770 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1355/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1356/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4769 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1357/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4768 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1358/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4767 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1359/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1360/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4767 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1361/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4765 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1362/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4766 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1363/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4765 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1364/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1365/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1366/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4763 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1367/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4763 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1368/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1369/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4762 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1370/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1371/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4761 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1372/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4760 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1373/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4760 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1374/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4759 - accuracy: 0.7027 - val_loss: 0.5571 - val_accuracy: 0.8000\n",
      "Epoch 1375/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4758 - accuracy: 0.7027 - val_loss: 0.5571 - val_accuracy: 0.8000\n",
      "Epoch 1376/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1377/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4758 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1378/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4757 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1379/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4757 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1380/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4756 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1381/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4755 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1382/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4755 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1383/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4754 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1384/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4754 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1385/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4753 - accuracy: 0.7027 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 1386/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4753 - accuracy: 0.7027 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1387/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4752 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1388/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1389/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1390/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4751 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1391/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1392/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1393/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1394/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1395/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4748 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1396/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4747 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1397/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4747 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1398/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4746 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1399/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4745 - accuracy: 0.7027 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 1400/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1401/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1402/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4744 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1403/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1404/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.7027 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
      "Epoch 1405/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4743 - accuracy: 0.7027 - val_loss: 0.5576 - val_accuracy: 0.8000\n",
      "Epoch 1406/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4742 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1407/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4741 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1408/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4741 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1409/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1410/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4739 - accuracy: 0.7027 - val_loss: 0.5579 - val_accuracy: 0.8000\n",
      "Epoch 1411/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4739 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1412/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1413/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4739 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1414/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4738 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1415/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4737 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1416/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4737 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1417/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4736 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1418/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4735 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1419/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4735 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1420/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4735 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1421/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4734 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1422/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4733 - accuracy: 0.7027 - val_loss: 0.5579 - val_accuracy: 0.8000\n",
      "Epoch 1423/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4733 - accuracy: 0.7027 - val_loss: 0.5579 - val_accuracy: 0.8000\n",
      "Epoch 1424/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4732 - accuracy: 0.7027 - val_loss: 0.5579 - val_accuracy: 0.8000\n",
      "Epoch 1425/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4731 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1426/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4731 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1427/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4732 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1428/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4731 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1429/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4730 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1430/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1431/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4729 - accuracy: 0.7027 - val_loss: 0.5576 - val_accuracy: 0.8000\n",
      "Epoch 1432/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4729 - accuracy: 0.7027 - val_loss: 0.5576 - val_accuracy: 0.8000\n",
      "Epoch 1433/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4729 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1434/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4729 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1435/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4727 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1436/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4727 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1437/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4727 - accuracy: 0.7027 - val_loss: 0.5576 - val_accuracy: 0.8000\n",
      "Epoch 1438/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4725 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1439/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4725 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1440/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4725 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1441/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4725 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1442/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4724 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1443/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4723 - accuracy: 0.7027 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1444/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4723 - accuracy: 0.7027 - val_loss: 0.5578 - val_accuracy: 0.8000\n",
      "Epoch 1445/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4723 - accuracy: 0.7027 - val_loss: 0.5579 - val_accuracy: 0.8000\n",
      "Epoch 1446/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4721 - accuracy: 0.7027 - val_loss: 0.5579 - val_accuracy: 0.8000\n",
      "Epoch 1447/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4722 - accuracy: 0.7027 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 1448/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4721 - accuracy: 0.7027 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 1449/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4720 - accuracy: 0.7027 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
      "Epoch 1450/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4720 - accuracy: 0.7297 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 1451/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4719 - accuracy: 0.7027 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
      "Epoch 1452/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4719 - accuracy: 0.7297 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 1453/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4718 - accuracy: 0.7297 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 1454/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4718 - accuracy: 0.7297 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 1455/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4717 - accuracy: 0.7297 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
      "Epoch 1456/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4717 - accuracy: 0.7297 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
      "Epoch 1457/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.7297 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
      "Epoch 1458/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1459/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1460/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4715 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1461/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4714 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1462/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1463/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4714 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1464/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4713 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1465/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4712 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1466/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4712 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1467/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4711 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1468/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4710 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1469/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1470/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1471/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4709 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1472/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4710 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1473/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.7297 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1474/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1475/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1476/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1477/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1478/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4706 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1479/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4706 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1480/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4705 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1481/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1482/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4704 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1483/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4704 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1484/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1485/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1486/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4702 - accuracy: 0.7297 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1487/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4702 - accuracy: 0.7297 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1488/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4701 - accuracy: 0.7568 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1489/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1490/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4700 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1491/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4700 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1492/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4700 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1493/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1494/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4699 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1495/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4699 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1496/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4698 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1497/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1498/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4698 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1499/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4696 - accuracy: 0.7297 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1500/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4696 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1501/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1502/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1503/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1504/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1505/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4693 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1506/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4693 - accuracy: 0.7568 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1507/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.7297 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 1508/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1509/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1510/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4691 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1511/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1512/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1513/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4690 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1514/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4689 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1515/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4689 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1516/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4689 - accuracy: 0.7568 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1517/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4688 - accuracy: 0.7297 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
      "Epoch 1518/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4688 - accuracy: 0.7297 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1519/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4687 - accuracy: 0.7297 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1520/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.7838 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 1521/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4686 - accuracy: 0.7568 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1522/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.7568 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1523/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.7297 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1524/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4685 - accuracy: 0.7838 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1525/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.7838 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1526/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7838 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 1527/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4683 - accuracy: 0.7568 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1528/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1529/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4682 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1530/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4682 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1531/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1532/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1533/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1534/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1535/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1536/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4679 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1537/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1538/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4678 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1539/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4677 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1540/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4677 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1541/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4677 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1542/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4676 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1543/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4676 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1544/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4676 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1545/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4675 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1546/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4674 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1547/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1548/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1549/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1550/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1551/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4672 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1552/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4671 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1553/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4671 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1554/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4671 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1555/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4671 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1556/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4670 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1557/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4670 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1558/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4669 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1559/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4668 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1560/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4669 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1561/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4668 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1562/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4667 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1563/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4667 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1564/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4666 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1565/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4666 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1566/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4665 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1567/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4665 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1568/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4665 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1569/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4664 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1570/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1571/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4664 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1572/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4663 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1573/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4662 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1574/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4662 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1575/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4662 - accuracy: 0.7568 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1576/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4660 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1577/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4660 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1578/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4660 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1579/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4660 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1580/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4659 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1581/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4659 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1582/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4659 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1583/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4658 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1584/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4658 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1585/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4657 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1586/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4657 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1587/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4656 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1588/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4656 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1589/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4656 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1590/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4655 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1591/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4655 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1592/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4654 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1593/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4653 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1594/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4653 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1595/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4653 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1596/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4653 - accuracy: 0.7568 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1597/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4652 - accuracy: 0.7568 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1598/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4651 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1599/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4651 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1600/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4651 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1601/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4650 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1602/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4650 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1603/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4649 - accuracy: 0.7838 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1604/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4650 - accuracy: 0.7838 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1605/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4649 - accuracy: 0.7838 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 1606/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4648 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1607/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4648 - accuracy: 0.7838 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "Epoch 1608/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4647 - accuracy: 0.7568 - val_loss: 0.5591 - val_accuracy: 0.8000\n",
      "Epoch 1609/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4647 - accuracy: 0.7568 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
      "Epoch 1610/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.7568 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
      "Epoch 1611/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.7568 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
      "Epoch 1612/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4646 - accuracy: 0.7568 - val_loss: 0.5593 - val_accuracy: 0.8000\n",
      "Epoch 1613/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4645 - accuracy: 0.7568 - val_loss: 0.5593 - val_accuracy: 0.8000\n",
      "Epoch 1614/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4645 - accuracy: 0.7568 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
      "Epoch 1615/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4645 - accuracy: 0.7568 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
      "Epoch 1616/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4644 - accuracy: 0.7568 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
      "Epoch 1617/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.7568 - val_loss: 0.5593 - val_accuracy: 0.8000\n",
      "Epoch 1618/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4643 - accuracy: 0.7568 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 1619/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4643 - accuracy: 0.7568 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 1620/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4643 - accuracy: 0.7568 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 1621/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4642 - accuracy: 0.7568 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
      "Epoch 1622/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4642 - accuracy: 0.7568 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 1623/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4641 - accuracy: 0.7568 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
      "Epoch 1624/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.7568 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
      "Epoch 1625/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4640 - accuracy: 0.7568 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 1626/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4640 - accuracy: 0.7568 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
      "Epoch 1627/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4639 - accuracy: 0.7568 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
      "Epoch 1628/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4639 - accuracy: 0.7568 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 1629/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4639 - accuracy: 0.7568 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 1630/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4639 - accuracy: 0.7568 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
      "Epoch 1631/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4638 - accuracy: 0.7568 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 1632/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4637 - accuracy: 0.7568 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 1633/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4637 - accuracy: 0.7568 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 1634/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4637 - accuracy: 0.7568 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 1635/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4636 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1636/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4636 - accuracy: 0.7568 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 1637/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4636 - accuracy: 0.7568 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 1638/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4635 - accuracy: 0.7568 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 1639/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4634 - accuracy: 0.7568 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 1640/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4634 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1641/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4633 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1642/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4634 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1643/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4633 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1644/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4632 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1645/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4632 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1646/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4631 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1647/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4632 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1648/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4630 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1649/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1650/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4630 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1651/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4629 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1652/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4629 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1653/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4628 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1654/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4628 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1655/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4627 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1656/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4627 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1657/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4627 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1658/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4627 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1659/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4626 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1660/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4626 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1661/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1662/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4625 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1663/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4625 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1664/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4624 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1665/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4624 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1666/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4623 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1667/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1668/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4622 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1669/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4622 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1670/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4622 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1671/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4621 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1672/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4621 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1673/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4621 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1674/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4620 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1675/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4620 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1676/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4620 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1677/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4619 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1678/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1679/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4618 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8000\n",
      "Epoch 1680/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1681/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4617 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1682/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4617 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1683/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4616 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1684/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1685/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4616 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1686/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4615 - accuracy: 0.7568 - val_loss: 0.5602 - val_accuracy: 0.8000\n",
      "Epoch 1687/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4614 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1688/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4614 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1689/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4614 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1690/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4614 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1691/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4613 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1692/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1693/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1694/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.7568 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 1695/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4611 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1696/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1697/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4610 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1698/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4610 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1699/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.7568 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 1700/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4610 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1701/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.7568 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 1702/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4609 - accuracy: 0.7568 - val_loss: 0.5602 - val_accuracy: 0.8000\n",
      "Epoch 1703/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4609 - accuracy: 0.7568 - val_loss: 0.5603 - val_accuracy: 0.8000\n",
      "Epoch 1704/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7568 - val_loss: 0.5603 - val_accuracy: 0.8000\n",
      "Epoch 1705/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4608 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1706/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.7568 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
      "Epoch 1707/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1708/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1709/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4606 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1710/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4606 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1711/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1712/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4604 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1713/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4604 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1714/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4605 - accuracy: 0.7568 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
      "Epoch 1715/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4603 - accuracy: 0.7568 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
      "Epoch 1716/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4603 - accuracy: 0.7568 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
      "Epoch 1717/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4603 - accuracy: 0.7568 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
      "Epoch 1718/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4603 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1719/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4602 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1720/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4601 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1721/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4601 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1722/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4600 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1723/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4601 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1724/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4600 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1725/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4600 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1726/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4599 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1727/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4598 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1728/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4598 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1729/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4599 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1730/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4597 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1731/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4597 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1732/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.7568 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 1733/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4596 - accuracy: 0.7568 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
      "Epoch 1734/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4596 - accuracy: 0.7568 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 1735/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1736/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4595 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1737/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1738/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1739/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4594 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1740/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4594 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1741/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4593 - accuracy: 0.7568 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 1742/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.7568 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 1743/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4593 - accuracy: 0.7568 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 1744/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4592 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1745/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4591 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1746/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4592 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1747/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4591 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1748/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4591 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1749/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4590 - accuracy: 0.7568 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 1750/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4590 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1751/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4589 - accuracy: 0.7568 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 1752/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1753/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4589 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1754/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1755/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4588 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1756/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4588 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1757/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4587 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1758/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4587 - accuracy: 0.7568 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 1759/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4586 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1760/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4587 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1761/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4585 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1762/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1763/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4586 - accuracy: 0.7568 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 1764/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4585 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1765/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4584 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1766/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1767/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4584 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1768/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4583 - accuracy: 0.7568 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 1769/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4583 - accuracy: 0.7568 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1770/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4583 - accuracy: 0.7568 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 1771/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4582 - accuracy: 0.7568 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 1772/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4582 - accuracy: 0.7568 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 1773/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4582 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1774/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4581 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1775/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4580 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1776/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4581 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1777/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4580 - accuracy: 0.7568 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 1778/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4579 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1779/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4579 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1780/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4579 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1781/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4578 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1782/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4579 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1783/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4578 - accuracy: 0.7568 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1784/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4578 - accuracy: 0.7568 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 1785/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4577 - accuracy: 0.7568 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 1786/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.7568 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 1787/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4577 - accuracy: 0.7568 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 1788/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4576 - accuracy: 0.7568 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 1789/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4576 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1790/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4576 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1791/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4575 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1792/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4574 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1793/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4574 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1794/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4574 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1795/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4573 - accuracy: 0.7568 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 1796/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4573 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1797/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4573 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1798/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4573 - accuracy: 0.7568 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 1799/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4572 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1800/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4572 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1801/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4571 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1802/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4571 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1803/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4571 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1804/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4570 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1805/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4570 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1806/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4570 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1807/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4569 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1808/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4569 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1809/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4568 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1810/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4568 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1811/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4568 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1812/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4567 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1813/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4568 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1814/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4567 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1815/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.7568 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
      "Epoch 1816/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1817/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4566 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1818/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4566 - accuracy: 0.7568 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 1819/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4565 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1820/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4565 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 1821/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4565 - accuracy: 0.7568 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 1822/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4564 - accuracy: 0.7568 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 1823/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4564 - accuracy: 0.7568 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 1824/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4563 - accuracy: 0.7568 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 1825/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4563 - accuracy: 0.7568 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 1826/5000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4563 - accuracy: 0.7568 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 1827/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4563 - accuracy: 0.7568 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 1828/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4562 - accuracy: 0.7568 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 1829/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4561 - accuracy: 0.7568 - val_loss: 0.5617 - val_accuracy: 0.8000\n",
      "Epoch 1830/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4562 - accuracy: 0.7568 - val_loss: 0.5617 - val_accuracy: 0.8000\n",
      "Epoch 1831/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.7568 - val_loss: 0.5617 - val_accuracy: 0.8000\n",
      "Epoch 1832/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.7568 - val_loss: 0.5617 - val_accuracy: 0.8000\n",
      "Epoch 1833/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4560 - accuracy: 0.7568 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 1834/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.7568 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 1835/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4559 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1836/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4559 - accuracy: 0.7568 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 1837/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4558 - accuracy: 0.7568 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 1838/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4558 - accuracy: 0.7568 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 1839/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4557 - accuracy: 0.7568 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 1840/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4557 - accuracy: 0.7568 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 1841/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4557 - accuracy: 0.7568 - val_loss: 0.5618 - val_accuracy: 0.8000\n",
      "Epoch 1842/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4557 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1843/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4556 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1844/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4556 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1845/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4555 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1846/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4556 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1847/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1848/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4554 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1849/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4554 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1850/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1851/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4553 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1852/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4554 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1853/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4553 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1854/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1855/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4552 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1856/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4552 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1857/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4551 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1858/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4551 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1859/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4551 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1860/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1861/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1862/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4550 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1863/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4549 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1864/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4550 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1865/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4549 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1866/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4548 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1867/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4548 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1868/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4548 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1869/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4547 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1870/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4548 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1871/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4547 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1872/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4546 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1873/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4546 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1874/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4546 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1875/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4546 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1876/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4545 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1877/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4546 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1878/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4545 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1879/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4544 - accuracy: 0.7568 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 1880/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4544 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1881/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4544 - accuracy: 0.7568 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 1882/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4544 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1883/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4543 - accuracy: 0.7568 - val_loss: 0.5622 - val_accuracy: 0.8000\n",
      "Epoch 1884/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4543 - accuracy: 0.7568 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 1885/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4543 - accuracy: 0.7568 - val_loss: 0.5622 - val_accuracy: 0.8000\n",
      "Epoch 1886/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4542 - accuracy: 0.7568 - val_loss: 0.5623 - val_accuracy: 0.8000\n",
      "Epoch 1887/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4542 - accuracy: 0.7568 - val_loss: 0.5623 - val_accuracy: 0.8000\n",
      "Epoch 1888/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4541 - accuracy: 0.7568 - val_loss: 0.5624 - val_accuracy: 0.8000\n",
      "Epoch 1889/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4541 - accuracy: 0.7568 - val_loss: 0.5624 - val_accuracy: 0.8000\n",
      "Epoch 1890/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4541 - accuracy: 0.7568 - val_loss: 0.5625 - val_accuracy: 0.8000\n",
      "Epoch 1891/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4540 - accuracy: 0.7568 - val_loss: 0.5625 - val_accuracy: 0.8000\n",
      "Epoch 1892/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4540 - accuracy: 0.7568 - val_loss: 0.5626 - val_accuracy: 0.8000\n",
      "Epoch 1893/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4539 - accuracy: 0.7568 - val_loss: 0.5626 - val_accuracy: 0.8000\n",
      "Epoch 1894/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4539 - accuracy: 0.7568 - val_loss: 0.5626 - val_accuracy: 0.8000\n",
      "Epoch 1895/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.7568 - val_loss: 0.5626 - val_accuracy: 0.8000\n",
      "Epoch 1896/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4539 - accuracy: 0.7568 - val_loss: 0.5626 - val_accuracy: 0.8000\n",
      "Epoch 1897/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4538 - accuracy: 0.7568 - val_loss: 0.5627 - val_accuracy: 0.8000\n",
      "Epoch 1898/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4538 - accuracy: 0.7568 - val_loss: 0.5627 - val_accuracy: 0.8000\n",
      "Epoch 1899/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4537 - accuracy: 0.7568 - val_loss: 0.5627 - val_accuracy: 0.8000\n",
      "Epoch 1900/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4536 - accuracy: 0.7568 - val_loss: 0.5628 - val_accuracy: 0.8000\n",
      "Epoch 1901/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4536 - accuracy: 0.7568 - val_loss: 0.5629 - val_accuracy: 0.8000\n",
      "Epoch 1902/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4536 - accuracy: 0.7568 - val_loss: 0.5629 - val_accuracy: 0.8000\n",
      "Epoch 1903/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4536 - accuracy: 0.7568 - val_loss: 0.5629 - val_accuracy: 0.8000\n",
      "Epoch 1904/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4535 - accuracy: 0.7568 - val_loss: 0.5629 - val_accuracy: 0.8000\n",
      "Epoch 1905/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4535 - accuracy: 0.7568 - val_loss: 0.5630 - val_accuracy: 0.8000\n",
      "Epoch 1906/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4534 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1907/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4534 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1908/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7568 - val_loss: 0.5630 - val_accuracy: 0.8000\n",
      "Epoch 1909/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1910/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4533 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1911/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4533 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1912/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4533 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1913/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1914/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4532 - accuracy: 0.7568 - val_loss: 0.5630 - val_accuracy: 0.8000\n",
      "Epoch 1915/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4531 - accuracy: 0.7568 - val_loss: 0.5629 - val_accuracy: 0.8000\n",
      "Epoch 1916/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4532 - accuracy: 0.7568 - val_loss: 0.5630 - val_accuracy: 0.8000\n",
      "Epoch 1917/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4531 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1918/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4530 - accuracy: 0.7568 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 1919/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4531 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1920/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4530 - accuracy: 0.7568 - val_loss: 0.5633 - val_accuracy: 0.8000\n",
      "Epoch 1921/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4530 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1922/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4529 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1923/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4529 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1924/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4529 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1925/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4529 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1926/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4528 - accuracy: 0.7568 - val_loss: 0.5633 - val_accuracy: 0.8000\n",
      "Epoch 1927/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4528 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1928/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4528 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1929/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4527 - accuracy: 0.7568 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1930/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4527 - accuracy: 0.7568 - val_loss: 0.5633 - val_accuracy: 0.8000\n",
      "Epoch 1931/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.7568 - val_loss: 0.5633 - val_accuracy: 0.8000\n",
      "Epoch 1932/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4526 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1933/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4526 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1934/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4526 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1935/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4525 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1936/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4525 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1937/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4525 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1938/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4524 - accuracy: 0.7568 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 1939/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4524 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1940/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4524 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1941/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4523 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1942/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4523 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1943/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4524 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1944/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4522 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1945/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4523 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1946/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4522 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1947/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4521 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1948/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4521 - accuracy: 0.7568 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 1949/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4521 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1950/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4520 - accuracy: 0.7568 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 1951/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4520 - accuracy: 0.7568 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 1952/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4520 - accuracy: 0.7568 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 1953/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.7568 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 1954/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4519 - accuracy: 0.7568 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 1955/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.7568 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 1956/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4520 - accuracy: 0.7568 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 1957/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4518 - accuracy: 0.7568 - val_loss: 0.5637 - val_accuracy: 0.8000\n",
      "Epoch 1958/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4518 - accuracy: 0.7568 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 1959/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4518 - accuracy: 0.7568 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 1960/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4518 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1961/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4517 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1962/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4516 - accuracy: 0.7568 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 1963/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4516 - accuracy: 0.7568 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 1964/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4516 - accuracy: 0.7568 - val_loss: 0.5637 - val_accuracy: 0.8000\n",
      "Epoch 1965/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4516 - accuracy: 0.7568 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 1966/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4515 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1967/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4516 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1968/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4514 - accuracy: 0.7568 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 1969/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4514 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1970/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4514 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1971/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4515 - accuracy: 0.7568 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 1972/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1973/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4513 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1974/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1975/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4513 - accuracy: 0.7568 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 1976/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4512 - accuracy: 0.7568 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 1977/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4512 - accuracy: 0.7568 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 1978/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4511 - accuracy: 0.7568 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 1979/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4512 - accuracy: 0.7568 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 1980/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4511 - accuracy: 0.7568 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 1981/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4510 - accuracy: 0.7568 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 1982/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4510 - accuracy: 0.7568 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 1983/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4510 - accuracy: 0.7568 - val_loss: 0.5642 - val_accuracy: 0.8000\n",
      "Epoch 1984/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4509 - accuracy: 0.7568 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 1985/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4509 - accuracy: 0.7568 - val_loss: 0.5642 - val_accuracy: 0.8000\n",
      "Epoch 1986/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4509 - accuracy: 0.7568 - val_loss: 0.5642 - val_accuracy: 0.8000\n",
      "Epoch 1987/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4509 - accuracy: 0.7568 - val_loss: 0.5643 - val_accuracy: 0.8000\n",
      "Epoch 1988/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4508 - accuracy: 0.7568 - val_loss: 0.5643 - val_accuracy: 0.8000\n",
      "Epoch 1989/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4508 - accuracy: 0.7568 - val_loss: 0.5643 - val_accuracy: 0.8000\n",
      "Epoch 1990/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4509 - accuracy: 0.7568 - val_loss: 0.5643 - val_accuracy: 0.8000\n",
      "Epoch 1991/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4507 - accuracy: 0.7568 - val_loss: 0.5643 - val_accuracy: 0.8000\n",
      "Epoch 1992/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.7568 - val_loss: 0.5644 - val_accuracy: 0.8000\n",
      "Epoch 1993/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7568 - val_loss: 0.5644 - val_accuracy: 0.8000\n",
      "Epoch 1994/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4507 - accuracy: 0.7568 - val_loss: 0.5644 - val_accuracy: 0.8000\n",
      "Epoch 1995/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4506 - accuracy: 0.7568 - val_loss: 0.5645 - val_accuracy: 0.8000\n",
      "Epoch 1996/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.7568 - val_loss: 0.5646 - val_accuracy: 0.8000\n",
      "Epoch 1997/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4505 - accuracy: 0.7568 - val_loss: 0.5646 - val_accuracy: 0.8000\n",
      "Epoch 1998/5000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4505 - accuracy: 0.7838 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
      "Epoch 1999/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4505 - accuracy: 0.7568 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 2000/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7838 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 2001/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4504 - accuracy: 0.7838 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 2002/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4504 - accuracy: 0.7838 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 2003/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4503 - accuracy: 0.7838 - val_loss: 0.5649 - val_accuracy: 0.8000\n",
      "Epoch 2004/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4503 - accuracy: 0.7838 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 2005/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4503 - accuracy: 0.7838 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 2006/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4503 - accuracy: 0.7568 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 2007/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4502 - accuracy: 0.7568 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
      "Epoch 2008/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4501 - accuracy: 0.7568 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
      "Epoch 2009/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4502 - accuracy: 0.7568 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
      "Epoch 2010/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4501 - accuracy: 0.7568 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
      "Epoch 2011/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4501 - accuracy: 0.7568 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
      "Epoch 2012/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4501 - accuracy: 0.7568 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Epoch 2013/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4500 - accuracy: 0.7568 - val_loss: 0.5649 - val_accuracy: 0.8000\n",
      "Epoch 2014/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4500 - accuracy: 0.7838 - val_loss: 0.5649 - val_accuracy: 0.8000\n",
      "Epoch 2015/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4500 - accuracy: 0.7838 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 2016/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4499 - accuracy: 0.7838 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 2017/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2018/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4498 - accuracy: 0.7838 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 2019/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4498 - accuracy: 0.7838 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 2020/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4498 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2021/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4497 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2022/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4497 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2023/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4498 - accuracy: 0.7838 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 2024/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4496 - accuracy: 0.7838 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 2025/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4496 - accuracy: 0.7568 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2026/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4496 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2027/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4496 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2028/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4496 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2029/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4496 - accuracy: 0.7838 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "Epoch 2030/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4496 - accuracy: 0.7568 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2031/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4495 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2032/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4494 - accuracy: 0.7838 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "Epoch 2033/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4494 - accuracy: 0.7838 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2034/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7838 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 2035/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4493 - accuracy: 0.7838 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2036/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4493 - accuracy: 0.7838 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 2037/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4493 - accuracy: 0.7838 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2038/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7838 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2039/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4492 - accuracy: 0.7838 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2040/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4493 - accuracy: 0.7838 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2041/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4492 - accuracy: 0.7838 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2042/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4491 - accuracy: 0.7838 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "Epoch 2043/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7838 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "Epoch 2044/5000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4491 - accuracy: 0.7838 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 2045/5000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4490 - accuracy: 0.7568 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "Epoch 2046/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4490 - accuracy: 0.7838 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2047/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4490 - accuracy: 0.7568 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 2048/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7838 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 2049/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.7838 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 2050/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4489 - accuracy: 0.7838 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 2051/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4488 - accuracy: 0.7838 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
      "Epoch 2052/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4488 - accuracy: 0.7838 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 2053/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4488 - accuracy: 0.7568 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 2054/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4487 - accuracy: 0.7838 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
      "Epoch 2055/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4488 - accuracy: 0.7838 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
      "Epoch 2056/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4487 - accuracy: 0.7838 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
      "Epoch 2057/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4486 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2058/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4486 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2059/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4487 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2060/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4485 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2061/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4485 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2062/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4485 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2063/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4485 - accuracy: 0.7838 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 2064/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4485 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2065/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4484 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2066/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4484 - accuracy: 0.7838 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 2067/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.7838 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 2068/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4484 - accuracy: 0.7838 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 2069/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4483 - accuracy: 0.7838 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 2070/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7838 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 2071/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4483 - accuracy: 0.7838 - val_loss: 0.5658 - val_accuracy: 0.8000\n",
      "Epoch 2072/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.7838 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 2073/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4482 - accuracy: 0.7838 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 2074/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4482 - accuracy: 0.7838 - val_loss: 0.5660 - val_accuracy: 0.8000\n",
      "Epoch 2075/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4481 - accuracy: 0.7838 - val_loss: 0.5660 - val_accuracy: 0.8000\n",
      "Epoch 2076/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4481 - accuracy: 0.7838 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 2077/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4481 - accuracy: 0.7838 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 2078/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.7838 - val_loss: 0.5660 - val_accuracy: 0.8000\n",
      "Epoch 2079/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.7838 - val_loss: 0.5659 - val_accuracy: 0.8000\n",
      "Epoch 2080/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7838 - val_loss: 0.5660 - val_accuracy: 0.8000\n",
      "Epoch 2081/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4479 - accuracy: 0.7838 - val_loss: 0.5660 - val_accuracy: 0.8000\n",
      "Epoch 2082/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4479 - accuracy: 0.7838 - val_loss: 0.5661 - val_accuracy: 0.8000\n",
      "Epoch 2083/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4479 - accuracy: 0.7838 - val_loss: 0.5661 - val_accuracy: 0.8000\n",
      "Epoch 2084/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4478 - accuracy: 0.7838 - val_loss: 0.5662 - val_accuracy: 0.8000\n",
      "Epoch 2085/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7838 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 2086/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7838 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 2087/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.7838 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 2088/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4477 - accuracy: 0.7838 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 2089/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4477 - accuracy: 0.7838 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 2090/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4476 - accuracy: 0.7838 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 2091/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4476 - accuracy: 0.7838 - val_loss: 0.5664 - val_accuracy: 0.8000\n",
      "Epoch 2092/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4476 - accuracy: 0.7838 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 2093/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4475 - accuracy: 0.7838 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 2094/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4475 - accuracy: 0.7838 - val_loss: 0.5664 - val_accuracy: 0.8000\n",
      "Epoch 2095/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.7838 - val_loss: 0.5665 - val_accuracy: 0.8000\n",
      "Epoch 2096/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4475 - accuracy: 0.7838 - val_loss: 0.5665 - val_accuracy: 0.8000\n",
      "Epoch 2097/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4475 - accuracy: 0.7838 - val_loss: 0.5665 - val_accuracy: 0.8000\n",
      "Epoch 2098/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.7838 - val_loss: 0.5665 - val_accuracy: 0.8000\n",
      "Epoch 2099/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4474 - accuracy: 0.7838 - val_loss: 0.5665 - val_accuracy: 0.8000\n",
      "Epoch 2100/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4473 - accuracy: 0.7838 - val_loss: 0.5666 - val_accuracy: 0.8000\n",
      "Epoch 2101/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4473 - accuracy: 0.7838 - val_loss: 0.5667 - val_accuracy: 0.8000\n",
      "Epoch 2102/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4473 - accuracy: 0.7838 - val_loss: 0.5667 - val_accuracy: 0.8000\n",
      "Epoch 2103/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.7838 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 2104/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4472 - accuracy: 0.7838 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 2105/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4472 - accuracy: 0.7838 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 2106/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4472 - accuracy: 0.7838 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 2107/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4471 - accuracy: 0.7838 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 2108/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7838 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 2109/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4471 - accuracy: 0.7838 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 2110/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7838 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 2111/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7838 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 2112/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4470 - accuracy: 0.7838 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 2113/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7838 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 2114/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4469 - accuracy: 0.7838 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 2115/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.7838 - val_loss: 0.5670 - val_accuracy: 0.8000\n",
      "Epoch 2116/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4468 - accuracy: 0.7838 - val_loss: 0.5670 - val_accuracy: 0.8000\n",
      "Epoch 2117/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.7838 - val_loss: 0.5671 - val_accuracy: 0.8000\n",
      "Epoch 2118/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.7838 - val_loss: 0.5671 - val_accuracy: 0.8000\n",
      "Epoch 2119/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.7838 - val_loss: 0.5671 - val_accuracy: 0.8000\n",
      "Epoch 2120/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4467 - accuracy: 0.7838 - val_loss: 0.5672 - val_accuracy: 0.8000\n",
      "Epoch 2121/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4466 - accuracy: 0.7838 - val_loss: 0.5672 - val_accuracy: 0.8000\n",
      "Epoch 2122/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.7838 - val_loss: 0.5673 - val_accuracy: 0.8000\n",
      "Epoch 2123/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4466 - accuracy: 0.7838 - val_loss: 0.5673 - val_accuracy: 0.8000\n",
      "Epoch 2124/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4466 - accuracy: 0.7838 - val_loss: 0.5674 - val_accuracy: 0.8000\n",
      "Epoch 2125/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4466 - accuracy: 0.7838 - val_loss: 0.5674 - val_accuracy: 0.8000\n",
      "Epoch 2126/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4465 - accuracy: 0.7838 - val_loss: 0.5675 - val_accuracy: 0.7000\n",
      "Epoch 2127/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.7838 - val_loss: 0.5675 - val_accuracy: 0.8000\n",
      "Epoch 2128/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4465 - accuracy: 0.7838 - val_loss: 0.5675 - val_accuracy: 0.8000\n",
      "Epoch 2129/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4464 - accuracy: 0.7838 - val_loss: 0.5675 - val_accuracy: 0.8000\n",
      "Epoch 2130/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.7838 - val_loss: 0.5674 - val_accuracy: 0.8000\n",
      "Epoch 2131/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4463 - accuracy: 0.7838 - val_loss: 0.5675 - val_accuracy: 0.8000\n",
      "Epoch 2132/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4463 - accuracy: 0.7838 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 2133/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.7838 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 2134/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4463 - accuracy: 0.7838 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 2135/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4464 - accuracy: 0.7838 - val_loss: 0.5677 - val_accuracy: 0.7000\n",
      "Epoch 2136/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4462 - accuracy: 0.7838 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 2137/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4462 - accuracy: 0.7838 - val_loss: 0.5677 - val_accuracy: 0.7000\n",
      "Epoch 2138/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4462 - accuracy: 0.7838 - val_loss: 0.5677 - val_accuracy: 0.7000\n",
      "Epoch 2139/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4461 - accuracy: 0.7838 - val_loss: 0.5677 - val_accuracy: 0.7000\n",
      "Epoch 2140/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.7838 - val_loss: 0.5677 - val_accuracy: 0.7000\n",
      "Epoch 2141/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.7838 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 2142/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4461 - accuracy: 0.7838 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 2143/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4461 - accuracy: 0.7838 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 2144/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4460 - accuracy: 0.7838 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 2145/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4460 - accuracy: 0.7838 - val_loss: 0.5677 - val_accuracy: 0.7000\n",
      "Epoch 2146/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4459 - accuracy: 0.7838 - val_loss: 0.5677 - val_accuracy: 0.7000\n",
      "Epoch 2147/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4459 - accuracy: 0.7838 - val_loss: 0.5677 - val_accuracy: 0.8000\n",
      "Epoch 2148/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.7838 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 2149/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4458 - accuracy: 0.7838 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 2150/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4458 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2151/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4458 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2152/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4458 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2153/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4457 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2154/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4457 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 2155/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4457 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2156/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4456 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2157/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4456 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2158/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4455 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2159/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4455 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 2160/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4456 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 2161/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4454 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 2162/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4455 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 2163/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4454 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 2164/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4454 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2165/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4453 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.7000\n",
      "Epoch 2166/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4454 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2167/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2168/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4453 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2169/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4452 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.7000\n",
      "Epoch 2170/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4452 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.7000\n",
      "Epoch 2171/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.7000\n",
      "Epoch 2172/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.7000\n",
      "Epoch 2173/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4451 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.7000\n",
      "Epoch 2174/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4452 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2175/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4451 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2176/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4450 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.7000\n",
      "Epoch 2177/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4450 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.7000\n",
      "Epoch 2178/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4451 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.7000\n",
      "Epoch 2179/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4450 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.7000\n",
      "Epoch 2180/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4450 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.7000\n",
      "Epoch 2181/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4449 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.7000\n",
      "Epoch 2182/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4449 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
      "Epoch 2183/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4449 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
      "Epoch 2184/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4448 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2185/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4448 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2186/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2187/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4448 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2188/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4447 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2189/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2190/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4447 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2191/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4447 - accuracy: 0.7838 - val_loss: 0.5678 - val_accuracy: 0.8000\n",
      "Epoch 2192/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4447 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2193/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4446 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2194/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4446 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2195/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4445 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2196/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2197/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4445 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2198/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4445 - accuracy: 0.7838 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 2199/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2200/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4445 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2201/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4444 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
      "Epoch 2202/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4444 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2203/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5314 - accuracy: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f5ff79f96d8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 537, in __del__\n",
      "    handle=self._handle, deleter=self._deleter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1279, in delete_iterator\n",
      "    tld.op_callbacks, handle, deleter)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4444 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
      "Epoch 2204/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4443 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
      "Epoch 2205/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4443 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2206/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7838 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 2207/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4443 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
      "Epoch 2208/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4442 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2209/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4442 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2210/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4442 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2211/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7838 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 2212/5000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4441 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2213/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4441 - accuracy: 0.7838 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 2214/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4440 - accuracy: 0.7838 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 2215/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2216/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4440 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2217/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4440 - accuracy: 0.7838 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
      "Epoch 2218/5000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4440 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2219/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4439 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2220/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4439 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2221/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4438 - accuracy: 0.7838 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 2222/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4438 - accuracy: 0.7838 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 2223/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4438 - accuracy: 0.7838 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 2224/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4438 - accuracy: 0.7838 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 2225/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4438 - accuracy: 0.7838 - val_loss: 0.5684 - val_accuracy: 0.8000\n",
      "Epoch 2226/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4437 - accuracy: 0.7838 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 2227/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4437 - accuracy: 0.7838 - val_loss: 0.5684 - val_accuracy: 0.8000\n",
      "Epoch 2228/5000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.3702 - accuracy: 0.8000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-766-09902949d571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           validation_data=(test_feature, test_label))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=RMSprop(lr=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feature, train_label, \n",
    "          epochs=5000, \n",
    "          batch_size=5,\n",
    "          validation_data=(test_feature, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

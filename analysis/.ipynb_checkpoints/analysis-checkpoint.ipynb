{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project root 경로 설정\n",
    "\n",
    "import platform\n",
    "\n",
    "\n",
    "_ = '\\\\' if platform.system() == 'Windows' else '/'\n",
    "root_dir = '/home{_}gusdnd852{_}Github{_}strabismus-recognition{_}'.format(_=_)\n",
    "if root_dir[len(root_dir) - 1] != _: root_dir += _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file type에 따라 다른 데이터에 접근\n",
    "\n",
    "def load_data(classes, max_len, label, short:bool=False):\n",
    "    file_type = 'fixations' if short else 'all_gaze' \n",
    "    raw_data_dir = root_dir + 'data{_}{c}{_}'.format(_=_, c=classes)\n",
    "    listdir = [_ for _ in os.listdir(raw_data_dir) if file_type in _]\n",
    "    \n",
    "    dataset, existing_names = [], ['']\n",
    "    for filename in listdir:\n",
    "        file = pd.read_csv(raw_data_dir + filename)\n",
    "        MEDIA_ID = file['MEDIA_ID'].unique().tolist()\n",
    "\n",
    "        if len(MEDIA_ID) < 2:\n",
    "            # 적외선 필터 검사를 진행하지 않은 데이터\n",
    "            continue  # 데이터 목록에서 제외합니다.\n",
    "            \n",
    "        if filename[:3] in existing_names:\n",
    "            continue # 환자당 데이터 1개씩만 포함\n",
    "        \n",
    "        file = file[file['MEDIA_ID'] == MEDIA_ID[-1]]  \n",
    "        # 적외선 필터 데이터만 로드\n",
    "        \n",
    "        data = np.c_[file.LPCX,  file.RPCX, file.LPV, file.RPV]\n",
    "        columns = ['LPCX', 'RPCX', 'LPV', 'RPV']        \n",
    "        data = pd.DataFrame(data=data, columns=columns)\n",
    "        \n",
    "        # 데이터 전처리 작업 수행\n",
    "        label = np.array(label)\n",
    "        data_dict = {'data':data, 'label': label}\n",
    "        dataset.append(data_dict)\n",
    "        existing_names.append(filename[:3])\n",
    "        \n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = load_data('normal', max_len=1000, label=0)\n",
    "exotropia = load_data('exotropia', max_len=1000, label=1)\n",
    "# esotropia = load_data('esotropia', max_len=1000, label=2)\n",
    "# hypertropia = load_data('hypertropia', max_len=1000, label=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def preprocess(data, sampling_rate=25, outlier_threshold=0.025):\n",
    "    lpcx, rpcx = data['data']['LPCX'], data['data']['RPCX']\n",
    "    valid = data['data']['LPV'] + data['data']['RPV']\n",
    "    diff = (rpcx - lpcx).tolist()\n",
    "    mean = sum(diff) / len(diff)\n",
    "    \n",
    "    data_processed = []\n",
    "    for i, (d, v) in enumerate(zip(diff, valid)):\n",
    "        if d > mean + outlier_threshold:\n",
    "            continue\n",
    "        elif d < mean - outlier_threshold:\n",
    "            continue\n",
    "        elif v == 2:\n",
    "            data_processed.append(d)\n",
    "    \n",
    "    data_processed = np.array(data_processed)\n",
    "    mean = sum(data_processed) / (len(data_processed) + 1)\n",
    "    data_normalized = np.array([d - mean for d in data_processed])\n",
    "    \n",
    "    data_sampled, sampling = [], []\n",
    "    for i, d in enumerate(data_normalized):\n",
    "        sampling.append(d)\n",
    "        \n",
    "        if len(sampling) > sampling_rate:\n",
    "            del sampling[0]\n",
    "        \n",
    "        if i % sampling_rate == 0 and i > sampling_rate:\n",
    "               data_sampled.append((sum(sampling) / len(sampling)))\n",
    "    \n",
    "    data_sampled = np.array(data_sampled)\n",
    "    \n",
    "    return {\n",
    "        'data' : data_sampled,\n",
    "        'label' : data['label']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "outlier_threshold = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_normal = [preprocess(i) for i in normal if len(preprocess(i)['data']) != 0]\n",
    "perp_exotropia = [preprocess(i) for i in exotropia if len(preprocess(i)['data']) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 30)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prep_normal), len(perp_exotropia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prep_normal + perp_exotropia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(dataset):\n",
    "    data = [data['data'] for data in dataset]\n",
    "    max_len = len(max(data, key=len))\n",
    "    \n",
    "    result_arr = []\n",
    "    for data in dataset:\n",
    "        label = data['label']\n",
    "        data = data['data']\n",
    "        \n",
    "        zeros = np.zeros(max_len)\n",
    "        zeros[:len(data)] = data\n",
    "        result_arr.append({'data':zeros, 'label':label})\n",
    "    \n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequence(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset, ratio):\n",
    "    split_point = int(ratio * len(dataset))\n",
    "    train_dataset = dataset[:split_point]\n",
    "    test_dataset = dataset[split_point:]\n",
    "\n",
    "    train_feature, train_label = [], []\n",
    "    test_feature, test_label = [], []\n",
    "    \n",
    "    for dataset in train_dataset:\n",
    "        data = np.expand_dims(dataset['data'], axis=0)\n",
    "        label = np.expand_dims(dataset['label'], axis=0)\n",
    "        train_feature.append(data)\n",
    "        train_label.append(label)\n",
    "    \n",
    "    for dataset in test_dataset:\n",
    "        data = np.expand_dims(dataset['data'], axis=0)\n",
    "        label = np.expand_dims(dataset['label'], axis=0)\n",
    "        test_feature.append(data)\n",
    "        test_label.append(label)\n",
    "    \n",
    "    train_feature = np.concatenate(train_feature, axis=0)\n",
    "    train_label = np.concatenate(train_label, axis=0)\n",
    "    test_feature = np.concatenate(test_feature, axis=0)\n",
    "    test_label = np.concatenate(test_label, axis=0)\n",
    "    \n",
    "    return train_feature, train_label, test_feature, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1] (39, 39)\n",
      "[0 1 1 0 0 1 1 1] (8, 39)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(padded)\n",
    "\n",
    "train_feature, train_label, test_feature, test_label = \\\n",
    "    make_dataset(padded, ratio=0.85)\n",
    "\n",
    "print(train_label, train_feature.shape)\n",
    "print(test_label, test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 - 0s - loss: 9.3812 - accuracy: 0.6410 - val_loss: 6.7927 - val_accuracy: 0.6250\n",
      "Epoch 2/300\n",
      "10/10 - 0s - loss: 5.3306 - accuracy: 0.6410 - val_loss: 3.7638 - val_accuracy: 0.6250\n",
      "Epoch 3/300\n",
      "10/10 - 0s - loss: 2.9407 - accuracy: 0.6410 - val_loss: 2.0940 - val_accuracy: 0.6250\n",
      "Epoch 4/300\n",
      "10/10 - 0s - loss: 1.6768 - accuracy: 0.6410 - val_loss: 1.2672 - val_accuracy: 0.6250\n",
      "Epoch 5/300\n",
      "10/10 - 0s - loss: 1.0788 - accuracy: 0.6410 - val_loss: 0.8998 - val_accuracy: 0.6250\n",
      "Epoch 6/300\n",
      "10/10 - 0s - loss: 0.8200 - accuracy: 0.6410 - val_loss: 0.7528 - val_accuracy: 0.6250\n",
      "Epoch 7/300\n",
      "10/10 - 0s - loss: 0.7222 - accuracy: 0.6410 - val_loss: 0.6994 - val_accuracy: 0.6250\n",
      "Epoch 8/300\n",
      "10/10 - 0s - loss: 0.6845 - accuracy: 0.6410 - val_loss: 0.6807 - val_accuracy: 0.6250\n",
      "Epoch 9/300\n",
      "10/10 - 0s - loss: 0.6709 - accuracy: 0.6410 - val_loss: 0.6742 - val_accuracy: 0.6250\n",
      "Epoch 10/300\n",
      "10/10 - 0s - loss: 0.6851 - accuracy: 0.6410 - val_loss: 0.6726 - val_accuracy: 0.6250\n",
      "Epoch 11/300\n",
      "10/10 - 0s - loss: 0.6629 - accuracy: 0.6410 - val_loss: 0.6707 - val_accuracy: 0.6250\n",
      "Epoch 12/300\n",
      "10/10 - 0s - loss: 0.6638 - accuracy: 0.6410 - val_loss: 0.6709 - val_accuracy: 0.6250\n",
      "Epoch 13/300\n",
      "10/10 - 0s - loss: 0.6677 - accuracy: 0.6410 - val_loss: 0.6709 - val_accuracy: 0.6250\n",
      "Epoch 14/300\n",
      "10/10 - 0s - loss: 0.6637 - accuracy: 0.6410 - val_loss: 0.6684 - val_accuracy: 0.6250\n",
      "Epoch 15/300\n",
      "10/10 - 0s - loss: 0.6632 - accuracy: 0.6410 - val_loss: 0.6679 - val_accuracy: 0.6250\n",
      "Epoch 16/300\n",
      "10/10 - 0s - loss: 0.6611 - accuracy: 0.6410 - val_loss: 0.6675 - val_accuracy: 0.6250\n",
      "Epoch 17/300\n",
      "10/10 - 0s - loss: 0.6625 - accuracy: 0.6410 - val_loss: 0.6675 - val_accuracy: 0.6250\n",
      "Epoch 18/300\n",
      "10/10 - 0s - loss: 0.6617 - accuracy: 0.6410 - val_loss: 0.6680 - val_accuracy: 0.6250\n",
      "Epoch 19/300\n",
      "10/10 - 0s - loss: 0.6600 - accuracy: 0.6410 - val_loss: 0.6677 - val_accuracy: 0.6250\n",
      "Epoch 20/300\n",
      "10/10 - 0s - loss: 0.6599 - accuracy: 0.6410 - val_loss: 0.6670 - val_accuracy: 0.6250\n",
      "Epoch 21/300\n",
      "10/10 - 0s - loss: 0.6612 - accuracy: 0.6410 - val_loss: 0.6669 - val_accuracy: 0.6250\n",
      "Epoch 22/300\n",
      "10/10 - 0s - loss: 0.6608 - accuracy: 0.6410 - val_loss: 0.6667 - val_accuracy: 0.6250\n",
      "Epoch 23/300\n",
      "10/10 - 0s - loss: 0.6601 - accuracy: 0.6410 - val_loss: 0.6675 - val_accuracy: 0.6250\n",
      "Epoch 24/300\n",
      "10/10 - 0s - loss: 0.6596 - accuracy: 0.6410 - val_loss: 0.6664 - val_accuracy: 0.6250\n",
      "Epoch 25/300\n",
      "10/10 - 0s - loss: 0.6626 - accuracy: 0.6410 - val_loss: 0.6662 - val_accuracy: 0.6250\n",
      "Epoch 26/300\n",
      "10/10 - 0s - loss: 0.6584 - accuracy: 0.6410 - val_loss: 0.6662 - val_accuracy: 0.6250\n",
      "Epoch 27/300\n",
      "10/10 - 0s - loss: 0.6607 - accuracy: 0.6410 - val_loss: 0.6680 - val_accuracy: 0.6250\n",
      "Epoch 28/300\n",
      "10/10 - 0s - loss: 0.6591 - accuracy: 0.6410 - val_loss: 0.6661 - val_accuracy: 0.6250\n",
      "Epoch 29/300\n",
      "10/10 - 0s - loss: 0.6586 - accuracy: 0.6410 - val_loss: 0.6659 - val_accuracy: 0.6250\n",
      "Epoch 30/300\n",
      "10/10 - 0s - loss: 0.6585 - accuracy: 0.6410 - val_loss: 0.6659 - val_accuracy: 0.6250\n",
      "Epoch 31/300\n",
      "10/10 - 0s - loss: 0.6583 - accuracy: 0.6410 - val_loss: 0.6661 - val_accuracy: 0.6250\n",
      "Epoch 32/300\n",
      "10/10 - 0s - loss: 0.6583 - accuracy: 0.6410 - val_loss: 0.6658 - val_accuracy: 0.6250\n",
      "Epoch 33/300\n",
      "10/10 - 0s - loss: 0.6597 - accuracy: 0.6410 - val_loss: 0.6655 - val_accuracy: 0.6250\n",
      "Epoch 34/300\n",
      "10/10 - 0s - loss: 0.6586 - accuracy: 0.6410 - val_loss: 0.6655 - val_accuracy: 0.6250\n",
      "Epoch 35/300\n",
      "10/10 - 0s - loss: 0.6593 - accuracy: 0.6410 - val_loss: 0.6660 - val_accuracy: 0.6250\n",
      "Epoch 36/300\n",
      "10/10 - 0s - loss: 0.6599 - accuracy: 0.6410 - val_loss: 0.6652 - val_accuracy: 0.6250\n",
      "Epoch 37/300\n",
      "10/10 - 0s - loss: 0.6579 - accuracy: 0.6410 - val_loss: 0.6657 - val_accuracy: 0.6250\n",
      "Epoch 38/300\n",
      "10/10 - 0s - loss: 0.6572 - accuracy: 0.6410 - val_loss: 0.6652 - val_accuracy: 0.6250\n",
      "Epoch 39/300\n",
      "10/10 - 0s - loss: 0.6572 - accuracy: 0.6410 - val_loss: 0.6651 - val_accuracy: 0.6250\n",
      "Epoch 40/300\n",
      "10/10 - 0s - loss: 0.6572 - accuracy: 0.6410 - val_loss: 0.6652 - val_accuracy: 0.6250\n",
      "Epoch 41/300\n",
      "10/10 - 0s - loss: 0.6588 - accuracy: 0.6410 - val_loss: 0.6656 - val_accuracy: 0.6250\n",
      "Epoch 42/300\n",
      "10/10 - 0s - loss: 0.6581 - accuracy: 0.6410 - val_loss: 0.6653 - val_accuracy: 0.6250\n",
      "Epoch 43/300\n",
      "10/10 - 0s - loss: 0.6580 - accuracy: 0.6410 - val_loss: 0.6656 - val_accuracy: 0.6250\n",
      "Epoch 44/300\n",
      "10/10 - 0s - loss: 0.6581 - accuracy: 0.6410 - val_loss: 0.6647 - val_accuracy: 0.6250\n",
      "Epoch 45/300\n",
      "10/10 - 0s - loss: 0.6567 - accuracy: 0.6410 - val_loss: 0.6648 - val_accuracy: 0.6250\n",
      "Epoch 46/300\n",
      "10/10 - 0s - loss: 0.6575 - accuracy: 0.6410 - val_loss: 0.6649 - val_accuracy: 0.6250\n",
      "Epoch 47/300\n",
      "10/10 - 0s - loss: 0.6570 - accuracy: 0.6410 - val_loss: 0.6651 - val_accuracy: 0.6250\n",
      "Epoch 48/300\n",
      "10/10 - 0s - loss: 0.6568 - accuracy: 0.6410 - val_loss: 0.6647 - val_accuracy: 0.6250\n",
      "Epoch 49/300\n",
      "10/10 - 0s - loss: 0.6564 - accuracy: 0.6410 - val_loss: 0.6647 - val_accuracy: 0.6250\n",
      "Epoch 50/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6648 - val_accuracy: 0.6250\n",
      "Epoch 51/300\n",
      "10/10 - 0s - loss: 0.6567 - accuracy: 0.6410 - val_loss: 0.6647 - val_accuracy: 0.6250\n",
      "Epoch 52/300\n",
      "10/10 - 0s - loss: 0.6565 - accuracy: 0.6410 - val_loss: 0.6647 - val_accuracy: 0.6250\n",
      "Epoch 53/300\n",
      "10/10 - 0s - loss: 0.6576 - accuracy: 0.6410 - val_loss: 0.6657 - val_accuracy: 0.6250\n",
      "Epoch 54/300\n",
      "10/10 - 0s - loss: 0.6578 - accuracy: 0.6410 - val_loss: 0.6658 - val_accuracy: 0.6250\n",
      "Epoch 55/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6648 - val_accuracy: 0.6250\n",
      "Epoch 56/300\n",
      "10/10 - 0s - loss: 0.6585 - accuracy: 0.6410 - val_loss: 0.6644 - val_accuracy: 0.6250\n",
      "Epoch 57/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6642 - val_accuracy: 0.6250\n",
      "Epoch 58/300\n",
      "10/10 - 0s - loss: 0.6595 - accuracy: 0.6410 - val_loss: 0.6639 - val_accuracy: 0.6250\n",
      "Epoch 59/300\n",
      "10/10 - 0s - loss: 0.6567 - accuracy: 0.6410 - val_loss: 0.6643 - val_accuracy: 0.6250\n",
      "Epoch 60/300\n",
      "10/10 - 0s - loss: 0.6569 - accuracy: 0.6410 - val_loss: 0.6649 - val_accuracy: 0.6250\n",
      "Epoch 61/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6645 - val_accuracy: 0.6250\n",
      "Epoch 62/300\n",
      "10/10 - 0s - loss: 0.6563 - accuracy: 0.6410 - val_loss: 0.6645 - val_accuracy: 0.6250\n",
      "Epoch 63/300\n",
      "10/10 - 0s - loss: 0.6563 - accuracy: 0.6410 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
      "Epoch 64/300\n",
      "10/10 - 0s - loss: 0.6559 - accuracy: 0.6410 - val_loss: 0.6639 - val_accuracy: 0.6250\n",
      "Epoch 65/300\n",
      "10/10 - 0s - loss: 0.6566 - accuracy: 0.6410 - val_loss: 0.6643 - val_accuracy: 0.6250\n",
      "Epoch 66/300\n",
      "10/10 - 0s - loss: 0.6566 - accuracy: 0.6410 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
      "Epoch 67/300\n",
      "10/10 - 0s - loss: 0.6558 - accuracy: 0.6410 - val_loss: 0.6641 - val_accuracy: 0.6250\n",
      "Epoch 68/300\n",
      "10/10 - 0s - loss: 0.6583 - accuracy: 0.6410 - val_loss: 0.6639 - val_accuracy: 0.6250\n",
      "Epoch 69/300\n",
      "10/10 - 0s - loss: 0.6557 - accuracy: 0.6410 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
      "Epoch 70/300\n",
      "10/10 - 0s - loss: 0.6600 - accuracy: 0.6410 - val_loss: 0.6636 - val_accuracy: 0.6250\n",
      "Epoch 71/300\n",
      "10/10 - 0s - loss: 0.6555 - accuracy: 0.6410 - val_loss: 0.6642 - val_accuracy: 0.6250\n",
      "Epoch 72/300\n",
      "10/10 - 0s - loss: 0.6563 - accuracy: 0.6410 - val_loss: 0.6645 - val_accuracy: 0.6250\n",
      "Epoch 73/300\n",
      "10/10 - 0s - loss: 0.6566 - accuracy: 0.6410 - val_loss: 0.6642 - val_accuracy: 0.6250\n",
      "Epoch 74/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6642 - val_accuracy: 0.6250\n",
      "Epoch 75/300\n",
      "10/10 - 0s - loss: 0.6568 - accuracy: 0.6410 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
      "Epoch 76/300\n",
      "10/10 - 0s - loss: 0.6568 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 77/300\n",
      "10/10 - 0s - loss: 0.6569 - accuracy: 0.6410 - val_loss: 0.6643 - val_accuracy: 0.6250\n",
      "Epoch 78/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6639 - val_accuracy: 0.6250\n",
      "Epoch 79/300\n",
      "10/10 - 0s - loss: 0.6563 - accuracy: 0.6410 - val_loss: 0.6645 - val_accuracy: 0.6250\n",
      "Epoch 80/300\n",
      "10/10 - 0s - loss: 0.6556 - accuracy: 0.6410 - val_loss: 0.6645 - val_accuracy: 0.6250\n",
      "Epoch 81/300\n",
      "10/10 - 0s - loss: 0.6569 - accuracy: 0.6410 - val_loss: 0.6639 - val_accuracy: 0.6250\n",
      "Epoch 82/300\n",
      "10/10 - 0s - loss: 0.6572 - accuracy: 0.6410 - val_loss: 0.6643 - val_accuracy: 0.6250\n",
      "Epoch 83/300\n",
      "10/10 - 0s - loss: 0.6571 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 84/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6642 - val_accuracy: 0.6250\n",
      "Epoch 85/300\n",
      "10/10 - 0s - loss: 0.6594 - accuracy: 0.6410 - val_loss: 0.6634 - val_accuracy: 0.6250\n",
      "Epoch 86/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 87/300\n",
      "10/10 - 0s - loss: 0.6583 - accuracy: 0.6410 - val_loss: 0.6646 - val_accuracy: 0.6250\n",
      "Epoch 88/300\n",
      "10/10 - 0s - loss: 0.6557 - accuracy: 0.6410 - val_loss: 0.6644 - val_accuracy: 0.6250\n",
      "Epoch 89/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 90/300\n",
      "10/10 - 0s - loss: 0.6568 - accuracy: 0.6410 - val_loss: 0.6641 - val_accuracy: 0.6250\n",
      "Epoch 91/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6643 - val_accuracy: 0.6250\n",
      "Epoch 92/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 93/300\n",
      "10/10 - 0s - loss: 0.6560 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 94/300\n",
      "10/10 - 0s - loss: 0.6565 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 95/300\n",
      "10/10 - 0s - loss: 0.6558 - accuracy: 0.6410 - val_loss: 0.6633 - val_accuracy: 0.6250\n",
      "Epoch 96/300\n",
      "10/10 - 0s - loss: 0.6559 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 97/300\n",
      "10/10 - 0s - loss: 0.6553 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 98/300\n",
      "10/10 - 0s - loss: 0.6564 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 99/300\n",
      "10/10 - 0s - loss: 0.6571 - accuracy: 0.6410 - val_loss: 0.6633 - val_accuracy: 0.6250\n",
      "Epoch 100/300\n",
      "10/10 - 0s - loss: 0.6554 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 101/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
      "Epoch 102/300\n",
      "10/10 - 0s - loss: 0.6552 - accuracy: 0.6410 - val_loss: 0.6636 - val_accuracy: 0.6250\n",
      "Epoch 103/300\n",
      "10/10 - 0s - loss: 0.6560 - accuracy: 0.6410 - val_loss: 0.6632 - val_accuracy: 0.6250\n",
      "Epoch 104/300\n",
      "10/10 - 0s - loss: 0.6554 - accuracy: 0.6410 - val_loss: 0.6633 - val_accuracy: 0.6250\n",
      "Epoch 105/300\n",
      "10/10 - 0s - loss: 0.6553 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 106/300\n",
      "10/10 - 0s - loss: 0.6553 - accuracy: 0.6410 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
      "Epoch 107/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6636 - val_accuracy: 0.6250\n",
      "Epoch 108/300\n",
      "10/10 - 0s - loss: 0.6587 - accuracy: 0.6410 - val_loss: 0.6647 - val_accuracy: 0.6250\n",
      "Epoch 109/300\n",
      "10/10 - 0s - loss: 0.6559 - accuracy: 0.6410 - val_loss: 0.6634 - val_accuracy: 0.6250\n",
      "Epoch 110/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6632 - val_accuracy: 0.6250\n",
      "Epoch 111/300\n",
      "10/10 - 0s - loss: 0.6566 - accuracy: 0.6410 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      "Epoch 112/300\n",
      "10/10 - 0s - loss: 0.6549 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 113/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6642 - val_accuracy: 0.6250\n",
      "Epoch 114/300\n",
      "10/10 - 0s - loss: 0.6552 - accuracy: 0.6410 - val_loss: 0.6639 - val_accuracy: 0.6250\n",
      "Epoch 115/300\n",
      "10/10 - 0s - loss: 0.6547 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 116/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6634 - val_accuracy: 0.6250\n",
      "Epoch 117/300\n",
      "10/10 - 0s - loss: 0.6549 - accuracy: 0.6410 - val_loss: 0.6634 - val_accuracy: 0.6250\n",
      "Epoch 118/300\n",
      "10/10 - 0s - loss: 0.6548 - accuracy: 0.6410 - val_loss: 0.6632 - val_accuracy: 0.6250\n",
      "Epoch 119/300\n",
      "10/10 - 0s - loss: 0.6576 - accuracy: 0.6410 - val_loss: 0.6630 - val_accuracy: 0.6250\n",
      "Epoch 120/300\n",
      "10/10 - 0s - loss: 0.6548 - accuracy: 0.6410 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      "Epoch 121/300\n",
      "10/10 - 0s - loss: 0.6559 - accuracy: 0.6410 - val_loss: 0.6639 - val_accuracy: 0.6250\n",
      "Epoch 122/300\n",
      "10/10 - 0s - loss: 0.6550 - accuracy: 0.6410 - val_loss: 0.6638 - val_accuracy: 0.6250\n",
      "Epoch 123/300\n",
      "10/10 - 0s - loss: 0.6552 - accuracy: 0.6410 - val_loss: 0.6638 - val_accuracy: 0.6250\n",
      "Epoch 124/300\n",
      "10/10 - 0s - loss: 0.6559 - accuracy: 0.6410 - val_loss: 0.6641 - val_accuracy: 0.6250\n",
      "Epoch 125/300\n",
      "10/10 - 0s - loss: 0.6551 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 126/300\n",
      "10/10 - 0s - loss: 0.6550 - accuracy: 0.6410 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 127/300\n",
      "10/10 - 0s - loss: 0.6564 - accuracy: 0.6410 - val_loss: 0.6632 - val_accuracy: 0.6250\n",
      "Epoch 128/300\n",
      "10/10 - 0s - loss: 0.6570 - accuracy: 0.6410 - val_loss: 0.6638 - val_accuracy: 0.6250\n",
      "Epoch 129/300\n",
      "10/10 - 0s - loss: 0.6552 - accuracy: 0.6410 - val_loss: 0.6634 - val_accuracy: 0.6250\n",
      "Epoch 130/300\n",
      "10/10 - 0s - loss: 0.6551 - accuracy: 0.6410 - val_loss: 0.6634 - val_accuracy: 0.6250\n",
      "Epoch 131/300\n",
      "10/10 - 0s - loss: 0.6567 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 132/300\n",
      "10/10 - 0s - loss: 0.6548 - accuracy: 0.6410 - val_loss: 0.6636 - val_accuracy: 0.6250\n",
      "Epoch 133/300\n",
      "10/10 - 0s - loss: 0.6551 - accuracy: 0.6410 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      "Epoch 134/300\n",
      "10/10 - 0s - loss: 0.6549 - accuracy: 0.6410 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      "Epoch 135/300\n",
      "10/10 - 0s - loss: 0.6553 - accuracy: 0.6410 - val_loss: 0.6630 - val_accuracy: 0.6250\n",
      "Epoch 136/300\n",
      "10/10 - 0s - loss: 0.6548 - accuracy: 0.6410 - val_loss: 0.6632 - val_accuracy: 0.6250\n",
      "Epoch 137/300\n",
      "10/10 - 0s - loss: 0.6571 - accuracy: 0.6410 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
      "Epoch 138/300\n",
      "10/10 - 0s - loss: 0.6551 - accuracy: 0.6410 - val_loss: 0.6640 - val_accuracy: 0.6250\n",
      "Epoch 139/300\n",
      "10/10 - 0s - loss: 0.6569 - accuracy: 0.6410 - val_loss: 0.6641 - val_accuracy: 0.6250\n",
      "Epoch 140/300\n",
      "10/10 - 0s - loss: 0.6542 - accuracy: 0.6410 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      "Epoch 141/300\n",
      "10/10 - 0s - loss: 0.6552 - accuracy: 0.6410 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      "Epoch 142/300\n",
      "10/10 - 0s - loss: 0.6555 - accuracy: 0.6410 - val_loss: 0.6630 - val_accuracy: 0.6250\n",
      "Epoch 143/300\n",
      "10/10 - 0s - loss: 0.6586 - accuracy: 0.6410 - val_loss: 0.6634 - val_accuracy: 0.6250\n",
      "Epoch 144/300\n",
      "10/10 - 0s - loss: 0.6576 - accuracy: 0.6410 - val_loss: 0.6628 - val_accuracy: 0.6250\n",
      "Epoch 145/300\n",
      "10/10 - 0s - loss: 0.6561 - accuracy: 0.6410 - val_loss: 0.6629 - val_accuracy: 0.6250\n",
      "Epoch 146/300\n",
      "10/10 - 0s - loss: 0.6548 - accuracy: 0.6410 - val_loss: 0.6629 - val_accuracy: 0.6250\n",
      "Epoch 147/300\n",
      "10/10 - 0s - loss: 0.6560 - accuracy: 0.6410 - val_loss: 0.6628 - val_accuracy: 0.6250\n",
      "Epoch 148/300\n",
      "10/10 - 0s - loss: 0.6568 - accuracy: 0.6410 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      "Epoch 149/300\n",
      "10/10 - 0s - loss: 0.6555 - accuracy: 0.6410 - val_loss: 0.6630 - val_accuracy: 0.6250\n",
      "Epoch 150/300\n",
      "10/10 - 0s - loss: 0.6570 - accuracy: 0.6410 - val_loss: 0.6637 - val_accuracy: 0.6250\n",
      "Epoch 151/300\n",
      "10/10 - 0s - loss: 0.6548 - accuracy: 0.6410 - val_loss: 0.6633 - val_accuracy: 0.6250\n",
      "Epoch 152/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6629 - val_accuracy: 0.6250\n",
      "Epoch 153/300\n",
      "10/10 - 0s - loss: 0.6546 - accuracy: 0.6410 - val_loss: 0.6629 - val_accuracy: 0.6250\n",
      "Epoch 154/300\n",
      "10/10 - 0s - loss: 0.6554 - accuracy: 0.6410 - val_loss: 0.6629 - val_accuracy: 0.6250\n",
      "Epoch 155/300\n",
      "10/10 - 0s - loss: 0.6556 - accuracy: 0.6410 - val_loss: 0.6628 - val_accuracy: 0.6250\n",
      "Epoch 156/300\n",
      "10/10 - 0s - loss: 0.6545 - accuracy: 0.6410 - val_loss: 0.6632 - val_accuracy: 0.6250\n",
      "Epoch 157/300\n",
      "10/10 - 0s - loss: 0.6548 - accuracy: 0.6410 - val_loss: 0.6632 - val_accuracy: 0.6250\n",
      "Epoch 158/300\n",
      "10/10 - 0s - loss: 0.6562 - accuracy: 0.6410 - val_loss: 0.6638 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(1e-3)))\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(1e-3)))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(1e-3)))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_feature, train_label, \n",
    "          epochs=300, \n",
    "          batch_size=4,\n",
    "          verbose=2,\n",
    "          validation_data=(test_feature, test_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
